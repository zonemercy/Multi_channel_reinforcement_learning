{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[2017-03-15 16:21:47,023] Making new env: mc_mat-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_1 (Flatten)              (None, 40)            0           flatten_input_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 164)           6724        flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 164)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 150)           24750       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 150)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 4)             604         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 4)             0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 32,078\n",
      "Trainable params: 32,078\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Training for 6000 steps ...\n",
      "    1/6000: episode: 1, duration: 0.121s, episode steps: 1, steps per second: 8, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.667 [0.000, 20.180], loss: --, mean_squared_error: --, mean_q: --\n",
      "    2/6000: episode: 2, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.250 [0.000, 14.790], loss: --, mean_squared_error: --, mean_q: --\n",
      "    3/6000: episode: 3, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.978 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "    4/6000: episode: 4, duration: 0.008s, episode steps: 1, steps per second: 128, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.195 [0.000, 15.695], loss: --, mean_squared_error: --, mean_q: --\n",
      "    5/6000: episode: 5, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.832 [0.000, 14.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "    6/6000: episode: 6, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.754 [0.000, 32.830], loss: --, mean_squared_error: --, mean_q: --\n",
      "    7/6000: episode: 7, duration: 0.010s, episode steps: 1, steps per second: 102, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.407 [0.000, 18.577], loss: --, mean_squared_error: --, mean_q: --\n",
      "    8/6000: episode: 8, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.519 [0.000, 19.120], loss: --, mean_squared_error: --, mean_q: --\n",
      "   10/6000: episode: 9, duration: 0.011s, episode steps: 2, steps per second: 190, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.207 [0.000, 16.930], loss: --, mean_squared_error: --, mean_q: --\n",
      "   11/6000: episode: 10, duration: 0.009s, episode steps: 1, steps per second: 117, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.230 [0.000, 23.390], loss: --, mean_squared_error: --, mean_q: --\n",
      "   12/6000: episode: 11, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.392 [0.000, 18.100], loss: --, mean_squared_error: --, mean_q: --\n",
      "   13/6000: episode: 12, duration: 0.010s, episode steps: 1, steps per second: 101, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [0.000, 30.200], loss: --, mean_squared_error: --, mean_q: --\n",
      "   14/6000: episode: 13, duration: 0.010s, episode steps: 1, steps per second: 99, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.830 [0.000, 11.097], loss: --, mean_squared_error: --, mean_q: --\n",
      "   15/6000: episode: 14, duration: 0.010s, episode steps: 1, steps per second: 105, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.362 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "   16/6000: episode: 15, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.122 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "   17/6000: episode: 16, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.341 [0.000, 18.320], loss: --, mean_squared_error: --, mean_q: --\n",
      "   18/6000: episode: 17, duration: 0.007s, episode steps: 1, steps per second: 141, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.819 [0.000, 31.410], loss: --, mean_squared_error: --, mean_q: --\n",
      "   19/6000: episode: 18, duration: 0.007s, episode steps: 1, steps per second: 144, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.575 [0.000, 39.860], loss: --, mean_squared_error: --, mean_q: --\n",
      "   20/6000: episode: 19, duration: 0.008s, episode steps: 1, steps per second: 121, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.347 [0.000, 28.980], loss: --, mean_squared_error: --, mean_q: --\n",
      "   21/6000: episode: 20, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.166 [0.000, 14.187], loss: --, mean_squared_error: --, mean_q: --\n",
      "   22/6000: episode: 21, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.076 [0.000, 13.782], loss: --, mean_squared_error: --, mean_q: --\n",
      "   23/6000: episode: 22, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.667 [0.000, 21.930], loss: --, mean_squared_error: --, mean_q: --\n",
      "   25/6000: episode: 23, duration: 0.016s, episode steps: 2, steps per second: 129, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.662 [0.000, 36.920], loss: --, mean_squared_error: --, mean_q: --\n",
      "   26/6000: episode: 24, duration: 0.010s, episode steps: 1, steps per second: 102, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.343 [0.000, 25.640], loss: --, mean_squared_error: --, mean_q: --\n",
      "   27/6000: episode: 25, duration: 0.011s, episode steps: 1, steps per second: 95, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.058 [0.000, 15.933], loss: --, mean_squared_error: --, mean_q: --\n",
      "   28/6000: episode: 26, duration: 0.010s, episode steps: 1, steps per second: 101, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.010 [0.000, 15.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "   30/6000: episode: 27, duration: 0.021s, episode steps: 2, steps per second: 97, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.687 [0.000, 34.710], loss: --, mean_squared_error: --, mean_q: --\n",
      "   31/6000: episode: 28, duration: 0.010s, episode steps: 1, steps per second: 102, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.716 [0.000, 22.240], loss: --, mean_squared_error: --, mean_q: --\n",
      "   32/6000: episode: 29, duration: 0.008s, episode steps: 1, steps per second: 122, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.176 [0.000, 18.260], loss: --, mean_squared_error: --, mean_q: --\n",
      "   37/6000: episode: 30, duration: 0.021s, episode steps: 5, steps per second: 243, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.600 [1.000, 3.000], mean observation: 0.816 [0.000, 13.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "   38/6000: episode: 31, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [0.000, 20.860], loss: --, mean_squared_error: --, mean_q: --\n",
      "   48/6000: episode: 32, duration: 0.044s, episode steps: 10, steps per second: 229, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.100 [0.000, 1.000], mean observation: 1.482 [0.000, 26.350], loss: --, mean_squared_error: --, mean_q: --\n",
      "   49/6000: episode: 33, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.544 [0.000, 37.570], loss: --, mean_squared_error: --, mean_q: --\n",
      "   50/6000: episode: 34, duration: 0.008s, episode steps: 1, steps per second: 133, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.034 [0.000, 38.040], loss: --, mean_squared_error: --, mean_q: --\n",
      "   51/6000: episode: 35, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.061 [0.000, 15.001], loss: --, mean_squared_error: --, mean_q: --\n",
      "   52/6000: episode: 36, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.991 [0.000, 38.870], loss: --, mean_squared_error: --, mean_q: --\n",
      "   53/6000: episode: 37, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.654 [0.000, 24.790], loss: --, mean_squared_error: --, mean_q: --\n",
      "   63/6000: episode: 38, duration: 0.029s, episode steps: 10, steps per second: 340, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.301 [0.000, 33.950], loss: --, mean_squared_error: --, mean_q: --\n",
      "   64/6000: episode: 39, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.200 [0.000, 15.920], loss: --, mean_squared_error: --, mean_q: --\n",
      "   65/6000: episode: 40, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.104 [0.000, 19.822], loss: --, mean_squared_error: --, mean_q: --\n",
      "   66/6000: episode: 41, duration: 0.009s, episode steps: 1, steps per second: 117, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.687 [0.000, 34.710], loss: --, mean_squared_error: --, mean_q: --\n",
      "   67/6000: episode: 42, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.651 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "   75/6000: episode: 43, duration: 0.025s, episode steps: 8, steps per second: 322, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.125 [1.000, 2.000], mean observation: 1.722 [0.000, 29.630], loss: --, mean_squared_error: --, mean_q: --\n",
      "   76/6000: episode: 44, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.839 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "   77/6000: episode: 45, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.359 [0.000, 27.750], loss: --, mean_squared_error: --, mean_q: --\n",
      "   79/6000: episode: 46, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.104 [0.000, 18.737], loss: --, mean_squared_error: --, mean_q: --\n",
      "   80/6000: episode: 47, duration: 0.010s, episode steps: 1, steps per second: 105, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.189 [0.000, 23.220], loss: --, mean_squared_error: --, mean_q: --\n",
      "   82/6000: episode: 48, duration: 0.011s, episode steps: 2, steps per second: 177, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.654 [0.000, 36.660], loss: --, mean_squared_error: --, mean_q: --\n",
      "   83/6000: episode: 49, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.135 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "   84/6000: episode: 50, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.106 [0.000, 37.100], loss: --, mean_squared_error: --, mean_q: --\n",
      "   85/6000: episode: 51, duration: 0.010s, episode steps: 1, steps per second: 105, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.653 [0.000, 29.480], loss: --, mean_squared_error: --, mean_q: --\n",
      "   86/6000: episode: 52, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.890 [0.000, 12.310], loss: --, mean_squared_error: --, mean_q: --\n",
      "   87/6000: episode: 53, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.299 [0.000, 24.590], loss: --, mean_squared_error: --, mean_q: --\n",
      "   88/6000: episode: 54, duration: 0.007s, episode steps: 1, steps per second: 143, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.238 [0.000, 16.748], loss: --, mean_squared_error: --, mean_q: --\n",
      "   89/6000: episode: 55, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.601 [0.000, 23.070], loss: --, mean_squared_error: --, mean_q: --\n",
      "   90/6000: episode: 56, duration: 0.007s, episode steps: 1, steps per second: 144, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.517 [0.000, 33.780], loss: --, mean_squared_error: --, mean_q: --\n",
      "   91/6000: episode: 57, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.368 [0.000, 30.400], loss: --, mean_squared_error: --, mean_q: --\n",
      "   92/6000: episode: 58, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.483 [0.000, 19.699], loss: --, mean_squared_error: --, mean_q: --\n",
      "   93/6000: episode: 59, duration: 0.007s, episode steps: 1, steps per second: 144, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.480 [0.000, 37.260], loss: --, mean_squared_error: --, mean_q: --\n",
      "   94/6000: episode: 60, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.775 [0.000, 32.110], loss: --, mean_squared_error: --, mean_q: --\n",
      "   95/6000: episode: 61, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.199 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "   96/6000: episode: 62, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.193 [0.000, 19.280], loss: --, mean_squared_error: --, mean_q: --\n",
      "   97/6000: episode: 63, duration: 0.008s, episode steps: 1, steps per second: 130, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.899 [0.000, 35.210], loss: --, mean_squared_error: --, mean_q: --\n",
      "   98/6000: episode: 64, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.653 [0.000, 19.898], loss: --, mean_squared_error: --, mean_q: --\n",
      "   99/6000: episode: 65, duration: 0.007s, episode steps: 1, steps per second: 145, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.639 [0.000, 19.824], loss: --, mean_squared_error: --, mean_q: --\n",
      "  100/6000: episode: 66, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.681 [0.000, 33.020], loss: --, mean_squared_error: --, mean_q: --\n",
      "  102/6000: episode: 67, duration: 0.010s, episode steps: 2, steps per second: 198, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.367 [0.000, 31.060], loss: --, mean_squared_error: --, mean_q: --\n",
      "  103/6000: episode: 68, duration: 0.007s, episode steps: 1, steps per second: 143, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.766 [0.000, 9.980], loss: --, mean_squared_error: --, mean_q: --\n",
      "  104/6000: episode: 69, duration: 0.008s, episode steps: 1, steps per second: 119, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.725 [0.000, 39.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  105/6000: episode: 70, duration: 0.008s, episode steps: 1, steps per second: 119, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.084 [0.000, 18.509], loss: --, mean_squared_error: --, mean_q: --\n",
      "  106/6000: episode: 71, duration: 0.010s, episode steps: 1, steps per second: 99, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.356 [0.000, 23.040], loss: --, mean_squared_error: --, mean_q: --\n",
      "  107/6000: episode: 72, duration: 0.008s, episode steps: 1, steps per second: 127, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [0.000, 20.350], loss: --, mean_squared_error: --, mean_q: --\n",
      "  109/6000: episode: 73, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.384 [0.000, 23.730], loss: --, mean_squared_error: --, mean_q: --\n",
      "  110/6000: episode: 74, duration: 0.010s, episode steps: 1, steps per second: 100, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.401 [0.000, 18.135], loss: --, mean_squared_error: --, mean_q: --\n",
      "  112/6000: episode: 75, duration: 0.011s, episode steps: 2, steps per second: 190, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.498 [0.000, 26.740], loss: --, mean_squared_error: --, mean_q: --\n",
      "  122/6000: episode: 76, duration: 0.030s, episode steps: 10, steps per second: 334, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.100 [0.000, 1.000], mean observation: 1.451 [0.000, 18.706], loss: --, mean_squared_error: --, mean_q: --\n",
      "  123/6000: episode: 77, duration: 0.008s, episode steps: 1, steps per second: 123, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.700 [0.000, 19.610], loss: --, mean_squared_error: --, mean_q: --\n",
      "  124/6000: episode: 78, duration: 0.008s, episode steps: 1, steps per second: 132, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.881 [0.000, 39.430], loss: --, mean_squared_error: --, mean_q: --\n",
      "  125/6000: episode: 79, duration: 0.010s, episode steps: 1, steps per second: 99, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.088 [0.000, 15.500], loss: --, mean_squared_error: --, mean_q: --\n",
      "  126/6000: episode: 80, duration: 0.008s, episode steps: 1, steps per second: 122, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.175 [0.000, 21.360], loss: --, mean_squared_error: --, mean_q: --\n",
      "  127/6000: episode: 81, duration: 0.008s, episode steps: 1, steps per second: 133, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.642 [0.000, 34.520], loss: --, mean_squared_error: --, mean_q: --\n",
      "  128/6000: episode: 82, duration: 0.007s, episode steps: 1, steps per second: 146, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.377 [0.000, 22.150], loss: --, mean_squared_error: --, mean_q: --\n",
      "  129/6000: episode: 83, duration: 0.008s, episode steps: 1, steps per second: 128, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.183 [0.000, 38.940], loss: --, mean_squared_error: --, mean_q: --\n",
      "  131/6000: episode: 84, duration: 0.010s, episode steps: 2, steps per second: 200, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.217 [0.000, 29.230], loss: --, mean_squared_error: --, mean_q: --\n",
      "  132/6000: episode: 85, duration: 0.008s, episode steps: 1, steps per second: 119, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.581 [0.000, 19.500], loss: --, mean_squared_error: --, mean_q: --\n",
      "  133/6000: episode: 86, duration: 0.007s, episode steps: 1, steps per second: 135, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.658 [0.000, 19.811], loss: --, mean_squared_error: --, mean_q: --\n",
      "  134/6000: episode: 87, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.749 [0.000, 20.290], loss: --, mean_squared_error: --, mean_q: --\n",
      "  135/6000: episode: 88, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.791 [0.000, 36.150], loss: --, mean_squared_error: --, mean_q: --\n",
      "  136/6000: episode: 89, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.422 [0.000, 28.260], loss: --, mean_squared_error: --, mean_q: --\n",
      "  137/6000: episode: 90, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.958 [0.000, 14.838], loss: --, mean_squared_error: --, mean_q: --\n",
      "  138/6000: episode: 91, duration: 0.009s, episode steps: 1, steps per second: 117, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.742 [0.000, 19.939], loss: --, mean_squared_error: --, mean_q: --\n",
      "  139/6000: episode: 92, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.839 [0.000, 32.660], loss: --, mean_squared_error: --, mean_q: --\n",
      "  140/6000: episode: 93, duration: 0.011s, episode steps: 1, steps per second: 92, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.526 [0.000, 25.950], loss: --, mean_squared_error: --, mean_q: --\n",
      "  141/6000: episode: 94, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.532 [0.000, 27.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  142/6000: episode: 95, duration: 0.011s, episode steps: 1, steps per second: 89, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.685 [0.000, 34.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  143/6000: episode: 96, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.138 [0.000, 26.100], loss: --, mean_squared_error: --, mean_q: --\n",
      "  144/6000: episode: 97, duration: 0.010s, episode steps: 1, steps per second: 102, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.684 [0.000, 20.240], loss: --, mean_squared_error: --, mean_q: --\n",
      "  145/6000: episode: 98, duration: 0.018s, episode steps: 1, steps per second: 56, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.892 [0.000, 10.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  146/6000: episode: 99, duration: 0.014s, episode steps: 1, steps per second: 72, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.101 [0.000, 15.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  147/6000: episode: 100, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.348 [0.000, 17.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  148/6000: episode: 101, duration: 0.023s, episode steps: 1, steps per second: 44, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.649 [0.000, 30.480], loss: --, mean_squared_error: --, mean_q: --\n",
      "  149/6000: episode: 102, duration: 0.016s, episode steps: 1, steps per second: 62, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.710 [0.000, 28.520], loss: --, mean_squared_error: --, mean_q: --\n",
      "  150/6000: episode: 103, duration: 0.014s, episode steps: 1, steps per second: 73, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.396 [0.000, 17.970], loss: --, mean_squared_error: --, mean_q: --\n",
      "  151/6000: episode: 104, duration: 0.013s, episode steps: 1, steps per second: 80, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.446 [0.000, 21.920], loss: --, mean_squared_error: --, mean_q: --\n",
      "  152/6000: episode: 105, duration: 0.017s, episode steps: 1, steps per second: 60, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.433 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  153/6000: episode: 106, duration: 0.145s, episode steps: 1, steps per second: 7, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.331 [0.000, 19.062], loss: --, mean_squared_error: --, mean_q: --\n",
      "  154/6000: episode: 107, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.263 [0.000, 17.735], loss: --, mean_squared_error: --, mean_q: --\n",
      "  155/6000: episode: 108, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.127 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  165/6000: episode: 109, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.956 [0.000, 16.104], loss: --, mean_squared_error: --, mean_q: --\n",
      "  166/6000: episode: 110, duration: 0.009s, episode steps: 1, steps per second: 114, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.309 [0.000, 21.240], loss: --, mean_squared_error: --, mean_q: --\n",
      "  167/6000: episode: 111, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.366 [0.000, 18.381], loss: --, mean_squared_error: --, mean_q: --\n",
      "  168/6000: episode: 112, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.286 [0.000, 29.770], loss: --, mean_squared_error: --, mean_q: --\n",
      "  176/6000: episode: 113, duration: 0.032s, episode steps: 8, steps per second: 250, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.125 [2.000, 3.000], mean observation: 1.427 [0.000, 18.020], loss: --, mean_squared_error: --, mean_q: --\n",
      "  177/6000: episode: 114, duration: 0.008s, episode steps: 1, steps per second: 121, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.498 [0.000, 22.170], loss: --, mean_squared_error: --, mean_q: --\n",
      "  178/6000: episode: 115, duration: 0.008s, episode steps: 1, steps per second: 123, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.892 [0.000, 38.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  179/6000: episode: 116, duration: 0.008s, episode steps: 1, steps per second: 125, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.014 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  180/6000: episode: 117, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.963 [0.000, 12.858], loss: --, mean_squared_error: --, mean_q: --\n",
      "  182/6000: episode: 118, duration: 0.011s, episode steps: 2, steps per second: 190, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.563 [0.000, 29.120], loss: --, mean_squared_error: --, mean_q: --\n",
      "  183/6000: episode: 119, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.530 [0.000, 30.470], loss: --, mean_squared_error: --, mean_q: --\n",
      "  184/6000: episode: 120, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.834 [0.000, 14.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  185/6000: episode: 121, duration: 0.007s, episode steps: 1, steps per second: 135, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.571 [0.000, 33.590], loss: --, mean_squared_error: --, mean_q: --\n",
      "  186/6000: episode: 122, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.147 [0.000, 22.260], loss: --, mean_squared_error: --, mean_q: --\n",
      "  187/6000: episode: 123, duration: 0.008s, episode steps: 1, steps per second: 118, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.022 [0.000, 15.259], loss: --, mean_squared_error: --, mean_q: --\n",
      "  192/6000: episode: 124, duration: 0.017s, episode steps: 5, steps per second: 294, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.800 [2.000, 3.000], mean observation: 1.306 [0.000, 20.420], loss: --, mean_squared_error: --, mean_q: --\n",
      "  193/6000: episode: 125, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.435 [0.000, 25.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  194/6000: episode: 126, duration: 0.007s, episode steps: 1, steps per second: 144, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.251 [0.000, 18.102], loss: --, mean_squared_error: --, mean_q: --\n",
      "  195/6000: episode: 127, duration: 0.007s, episode steps: 1, steps per second: 148, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.397 [0.000, 19.486], loss: --, mean_squared_error: --, mean_q: --\n",
      "  196/6000: episode: 128, duration: 0.007s, episode steps: 1, steps per second: 143, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.613 [0.000, 37.710], loss: --, mean_squared_error: --, mean_q: --\n",
      "  197/6000: episode: 129, duration: 0.010s, episode steps: 1, steps per second: 105, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.615 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  198/6000: episode: 130, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.244 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  199/6000: episode: 131, duration: 0.009s, episode steps: 1, steps per second: 106, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.141 [0.000, 16.413], loss: --, mean_squared_error: --, mean_q: --\n",
      "  200/6000: episode: 132, duration: 0.009s, episode steps: 1, steps per second: 113, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.428 [0.000, 20.580], loss: --, mean_squared_error: --, mean_q: --\n",
      "  201/6000: episode: 133, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.287 [0.000, 18.900], loss: --, mean_squared_error: --, mean_q: --\n",
      "  202/6000: episode: 134, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.110 [0.000, 25.500], loss: --, mean_squared_error: --, mean_q: --\n",
      "  203/6000: episode: 135, duration: 0.010s, episode steps: 1, steps per second: 100, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.160 [0.000, 19.510], loss: --, mean_squared_error: --, mean_q: --\n",
      "  204/6000: episode: 136, duration: 0.011s, episode steps: 1, steps per second: 91, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.230 [0.000, 16.010], loss: --, mean_squared_error: --, mean_q: --\n",
      "  205/6000: episode: 137, duration: 0.008s, episode steps: 1, steps per second: 124, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.729 [0.000, 38.640], loss: --, mean_squared_error: --, mean_q: --\n",
      "  206/6000: episode: 138, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.208 [0.000, 18.558], loss: --, mean_squared_error: --, mean_q: --\n",
      "  207/6000: episode: 139, duration: 0.008s, episode steps: 1, steps per second: 132, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.003 [0.000, 12.980], loss: --, mean_squared_error: --, mean_q: --\n",
      "  208/6000: episode: 140, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.448 [0.000, 36.040], loss: --, mean_squared_error: --, mean_q: --\n",
      "  209/6000: episode: 141, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.897 [0.000, 19.800], loss: --, mean_squared_error: --, mean_q: --\n",
      "  210/6000: episode: 142, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.909 [0.000, 12.337], loss: --, mean_squared_error: --, mean_q: --\n",
      "  211/6000: episode: 143, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.230 [0.000, 32.010], loss: --, mean_squared_error: --, mean_q: --\n",
      "  212/6000: episode: 144, duration: 0.008s, episode steps: 1, steps per second: 130, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.116 [0.000, 16.971], loss: --, mean_squared_error: --, mean_q: --\n",
      "  213/6000: episode: 145, duration: 0.007s, episode steps: 1, steps per second: 142, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.012 [0.000, 10.804], loss: --, mean_squared_error: --, mean_q: --\n",
      "  223/6000: episode: 146, duration: 0.030s, episode steps: 10, steps per second: 335, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.766 [0.000, 31.030], loss: --, mean_squared_error: --, mean_q: --\n",
      "  224/6000: episode: 147, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.136 [0.000, 26.150], loss: --, mean_squared_error: --, mean_q: --\n",
      "  226/6000: episode: 148, duration: 0.010s, episode steps: 2, steps per second: 209, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.566 [0.000, 37.230], loss: --, mean_squared_error: --, mean_q: --\n",
      "  227/6000: episode: 149, duration: 0.007s, episode steps: 1, steps per second: 142, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.112 [0.000, 39.510], loss: --, mean_squared_error: --, mean_q: --\n",
      "  229/6000: episode: 150, duration: 0.012s, episode steps: 2, steps per second: 171, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.834 [0.000, 33.930], loss: --, mean_squared_error: --, mean_q: --\n",
      "  230/6000: episode: 151, duration: 0.011s, episode steps: 1, steps per second: 94, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.344 [0.000, 19.430], loss: --, mean_squared_error: --, mean_q: --\n",
      "  231/6000: episode: 152, duration: 0.010s, episode steps: 1, steps per second: 104, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.005 [0.000, 30.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  232/6000: episode: 153, duration: 0.011s, episode steps: 1, steps per second: 93, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.700 [0.000, 35.270], loss: --, mean_squared_error: --, mean_q: --\n",
      "  233/6000: episode: 154, duration: 0.014s, episode steps: 1, steps per second: 70, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.717 [0.000, 35.660], loss: --, mean_squared_error: --, mean_q: --\n",
      "  243/6000: episode: 155, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.722 [0.000, 29.630], loss: --, mean_squared_error: --, mean_q: --\n",
      "  244/6000: episode: 156, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.281 [0.000, 22.830], loss: --, mean_squared_error: --, mean_q: --\n",
      "  245/6000: episode: 157, duration: 0.007s, episode steps: 1, steps per second: 135, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.588 [0.000, 17.640], loss: --, mean_squared_error: --, mean_q: --\n",
      "  246/6000: episode: 158, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.397 [0.000, 18.986], loss: --, mean_squared_error: --, mean_q: --\n",
      "  256/6000: episode: 159, duration: 0.029s, episode steps: 10, steps per second: 345, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.280 [0.000, 19.819], loss: --, mean_squared_error: --, mean_q: --\n",
      "  257/6000: episode: 160, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.402 [0.000, 26.330], loss: --, mean_squared_error: --, mean_q: --\n",
      "  258/6000: episode: 161, duration: 0.007s, episode steps: 1, steps per second: 143, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.679 [0.000, 26.420], loss: --, mean_squared_error: --, mean_q: --\n",
      "  261/6000: episode: 162, duration: 0.012s, episode steps: 3, steps per second: 257, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [2.000, 3.000], mean observation: 1.198 [0.000, 14.071], loss: --, mean_squared_error: --, mean_q: --\n",
      "  262/6000: episode: 163, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.921 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  272/6000: episode: 164, duration: 0.039s, episode steps: 10, steps per second: 260, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.767 [0.000, 37.250], loss: --, mean_squared_error: --, mean_q: --\n",
      "  273/6000: episode: 165, duration: 0.010s, episode steps: 1, steps per second: 101, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.402 [0.000, 19.954], loss: --, mean_squared_error: --, mean_q: --\n",
      "  274/6000: episode: 166, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.166 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  275/6000: episode: 167, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.207 [0.000, 18.362], loss: --, mean_squared_error: --, mean_q: --\n",
      "  276/6000: episode: 168, duration: 0.010s, episode steps: 1, steps per second: 101, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.831 [0.000, 39.560], loss: --, mean_squared_error: --, mean_q: --\n",
      "  277/6000: episode: 169, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.687 [0.000, 37.200], loss: --, mean_squared_error: --, mean_q: --\n",
      "  278/6000: episode: 170, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.912 [0.000, 15.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  279/6000: episode: 171, duration: 0.007s, episode steps: 1, steps per second: 142, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.630 [0.000, 37.400], loss: --, mean_squared_error: --, mean_q: --\n",
      "  280/6000: episode: 172, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.358 [0.000, 27.140], loss: --, mean_squared_error: --, mean_q: --\n",
      "  281/6000: episode: 173, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.312 [0.000, 20.290], loss: --, mean_squared_error: --, mean_q: --\n",
      "  282/6000: episode: 174, duration: 0.008s, episode steps: 1, steps per second: 125, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.148 [0.000, 27.650], loss: --, mean_squared_error: --, mean_q: --\n",
      "  283/6000: episode: 175, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  284/6000: episode: 176, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.269 [0.000, 26.530], loss: --, mean_squared_error: --, mean_q: --\n",
      "  285/6000: episode: 177, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.711 [0.000, 27.620], loss: --, mean_squared_error: --, mean_q: --\n",
      "  286/6000: episode: 178, duration: 0.007s, episode steps: 1, steps per second: 142, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.293 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  287/6000: episode: 179, duration: 0.007s, episode steps: 1, steps per second: 144, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.464 [0.000, 25.210], loss: --, mean_squared_error: --, mean_q: --\n",
      "  288/6000: episode: 180, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.421 [0.000, 18.770], loss: --, mean_squared_error: --, mean_q: --\n",
      "  289/6000: episode: 181, duration: 0.010s, episode steps: 1, steps per second: 101, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.622 [0.000, 30.620], loss: --, mean_squared_error: --, mean_q: --\n",
      "  290/6000: episode: 182, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.251 [0.000, 19.630], loss: --, mean_squared_error: --, mean_q: --\n",
      "  300/6000: episode: 183, duration: 0.034s, episode steps: 10, steps per second: 295, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.488 [0.000, 28.750], loss: --, mean_squared_error: --, mean_q: --\n",
      "  302/6000: episode: 184, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.159 [0.000, 19.923], loss: --, mean_squared_error: --, mean_q: --\n",
      "  303/6000: episode: 185, duration: 0.009s, episode steps: 1, steps per second: 106, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.695 [0.000, 28.920], loss: --, mean_squared_error: --, mean_q: --\n",
      "  305/6000: episode: 186, duration: 0.012s, episode steps: 2, steps per second: 170, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.048 [0.000, 17.732], loss: --, mean_squared_error: --, mean_q: --\n",
      "  306/6000: episode: 187, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.630 [0.000, 29.800], loss: --, mean_squared_error: --, mean_q: --\n",
      "  307/6000: episode: 188, duration: 0.008s, episode steps: 1, steps per second: 122, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.835 [0.000, 37.990], loss: --, mean_squared_error: --, mean_q: --\n",
      "  308/6000: episode: 189, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.300 [0.000, 27.780], loss: --, mean_squared_error: --, mean_q: --\n",
      "  309/6000: episode: 190, duration: 0.007s, episode steps: 1, steps per second: 144, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.792 [0.000, 10.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  310/6000: episode: 191, duration: 0.007s, episode steps: 1, steps per second: 141, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.211 [0.000, 18.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  311/6000: episode: 192, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.476 [0.000, 36.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  312/6000: episode: 193, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.669 [0.000, 26.310], loss: --, mean_squared_error: --, mean_q: --\n",
      "  313/6000: episode: 194, duration: 0.012s, episode steps: 1, steps per second: 85, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.841 [0.000, 17.250], loss: --, mean_squared_error: --, mean_q: --\n",
      "  314/6000: episode: 195, duration: 0.008s, episode steps: 1, steps per second: 125, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.310 [0.000, 18.134], loss: --, mean_squared_error: --, mean_q: --\n",
      "  315/6000: episode: 196, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.695 [0.000, 36.690], loss: --, mean_squared_error: --, mean_q: --\n",
      "  316/6000: episode: 197, duration: 0.007s, episode steps: 1, steps per second: 147, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.494 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  317/6000: episode: 198, duration: 0.007s, episode steps: 1, steps per second: 143, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.463 [0.000, 19.445], loss: --, mean_squared_error: --, mean_q: --\n",
      "  318/6000: episode: 199, duration: 0.008s, episode steps: 1, steps per second: 133, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.350 [0.000, 19.110], loss: --, mean_squared_error: --, mean_q: --\n",
      "  319/6000: episode: 200, duration: 0.008s, episode steps: 1, steps per second: 123, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.639 [0.000, 32.070], loss: --, mean_squared_error: --, mean_q: --\n",
      "  320/6000: episode: 201, duration: 0.007s, episode steps: 1, steps per second: 146, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.395 [0.000, 23.890], loss: --, mean_squared_error: --, mean_q: --\n",
      "  321/6000: episode: 202, duration: 0.007s, episode steps: 1, steps per second: 143, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.328 [0.000, 17.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  322/6000: episode: 203, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.435 [0.000, 19.370], loss: --, mean_squared_error: --, mean_q: --\n",
      "  324/6000: episode: 204, duration: 0.010s, episode steps: 2, steps per second: 207, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.296 [0.000, 22.490], loss: --, mean_squared_error: --, mean_q: --\n",
      "  325/6000: episode: 205, duration: 0.010s, episode steps: 1, steps per second: 101, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.246 [0.000, 17.423], loss: --, mean_squared_error: --, mean_q: --\n",
      "  326/6000: episode: 206, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.159 [0.000, 32.440], loss: --, mean_squared_error: --, mean_q: --\n",
      "  327/6000: episode: 207, duration: 0.008s, episode steps: 1, steps per second: 121, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.373 [0.000, 18.359], loss: --, mean_squared_error: --, mean_q: --\n",
      "  328/6000: episode: 208, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.225 [0.000, 16.673], loss: --, mean_squared_error: --, mean_q: --\n",
      "  329/6000: episode: 209, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.389 [0.000, 27.910], loss: --, mean_squared_error: --, mean_q: --\n",
      "  330/6000: episode: 210, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.979 [0.000, 18.738], loss: --, mean_squared_error: --, mean_q: --\n",
      "  331/6000: episode: 211, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.544 [0.000, 37.570], loss: --, mean_squared_error: --, mean_q: --\n",
      "  332/6000: episode: 212, duration: 0.009s, episode steps: 1, steps per second: 113, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.742 [0.000, 26.540], loss: --, mean_squared_error: --, mean_q: --\n",
      "  333/6000: episode: 213, duration: 0.011s, episode steps: 1, steps per second: 90, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.268 [0.000, 32.510], loss: --, mean_squared_error: --, mean_q: --\n",
      "  334/6000: episode: 214, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.158 [0.000, 38.730], loss: --, mean_squared_error: --, mean_q: --\n",
      "  335/6000: episode: 215, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.927 [0.000, 15.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  336/6000: episode: 216, duration: 0.008s, episode steps: 1, steps per second: 127, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.613 [0.000, 35.780], loss: --, mean_squared_error: --, mean_q: --\n",
      "  337/6000: episode: 217, duration: 0.007s, episode steps: 1, steps per second: 135, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.021 [0.000, 38.220], loss: --, mean_squared_error: --, mean_q: --\n",
      "  340/6000: episode: 218, duration: 0.013s, episode steps: 3, steps per second: 229, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.354 [0.000, 14.873], loss: --, mean_squared_error: --, mean_q: --\n",
      "  341/6000: episode: 219, duration: 0.007s, episode steps: 1, steps per second: 143, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.007 [0.000, 16.727], loss: --, mean_squared_error: --, mean_q: --\n",
      "  342/6000: episode: 220, duration: 0.008s, episode steps: 1, steps per second: 122, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.053 [0.000, 13.913], loss: --, mean_squared_error: --, mean_q: --\n",
      "  343/6000: episode: 221, duration: 0.007s, episode steps: 1, steps per second: 135, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.771 [0.000, 31.460], loss: --, mean_squared_error: --, mean_q: --\n",
      "  344/6000: episode: 222, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.407 [0.000, 38.990], loss: --, mean_squared_error: --, mean_q: --\n",
      "  345/6000: episode: 223, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.246 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  346/6000: episode: 224, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.363 [0.000, 19.724], loss: --, mean_squared_error: --, mean_q: --\n",
      "  347/6000: episode: 225, duration: 0.007s, episode steps: 1, steps per second: 141, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.205 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  348/6000: episode: 226, duration: 0.009s, episode steps: 1, steps per second: 113, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.307 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  349/6000: episode: 227, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.714 [0.000, 31.240], loss: --, mean_squared_error: --, mean_q: --\n",
      "  350/6000: episode: 228, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.081 [0.000, 14.800], loss: --, mean_squared_error: --, mean_q: --\n",
      "  351/6000: episode: 229, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.122 [0.000, 13.246], loss: --, mean_squared_error: --, mean_q: --\n",
      "  352/6000: episode: 230, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.571 [0.000, 21.340], loss: --, mean_squared_error: --, mean_q: --\n",
      "  362/6000: episode: 231, duration: 0.034s, episode steps: 10, steps per second: 291, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.482 [0.000, 26.350], loss: --, mean_squared_error: --, mean_q: --\n",
      "  363/6000: episode: 232, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.307 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  364/6000: episode: 233, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.700 [0.000, 12.775], loss: --, mean_squared_error: --, mean_q: --\n",
      "  365/6000: episode: 234, duration: 0.011s, episode steps: 1, steps per second: 90, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.716 [0.000, 26.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  366/6000: episode: 235, duration: 0.008s, episode steps: 1, steps per second: 121, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.702 [0.000, 39.520], loss: --, mean_squared_error: --, mean_q: --\n",
      "  367/6000: episode: 236, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.650 [0.000, 24.020], loss: --, mean_squared_error: --, mean_q: --\n",
      "  368/6000: episode: 237, duration: 0.007s, episode steps: 1, steps per second: 133, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.395 [0.000, 23.920], loss: --, mean_squared_error: --, mean_q: --\n",
      "  369/6000: episode: 238, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.261 [0.000, 25.450], loss: --, mean_squared_error: --, mean_q: --\n",
      "  370/6000: episode: 239, duration: 0.007s, episode steps: 1, steps per second: 144, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.538 [0.000, 27.960], loss: --, mean_squared_error: --, mean_q: --\n",
      "  371/6000: episode: 240, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.756 [0.000, 39.020], loss: --, mean_squared_error: --, mean_q: --\n",
      "  372/6000: episode: 241, duration: 0.008s, episode steps: 1, steps per second: 119, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.390 [0.000, 25.580], loss: --, mean_squared_error: --, mean_q: --\n",
      "  373/6000: episode: 242, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.564 [0.000, 20.360], loss: --, mean_squared_error: --, mean_q: --\n",
      "  374/6000: episode: 243, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.058 [0.000, 15.004], loss: --, mean_squared_error: --, mean_q: --\n",
      "  375/6000: episode: 244, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.771 [0.000, 31.460], loss: --, mean_squared_error: --, mean_q: --\n",
      "  376/6000: episode: 245, duration: 0.008s, episode steps: 1, steps per second: 127, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.624 [0.000, 19.945], loss: --, mean_squared_error: --, mean_q: --\n",
      "  377/6000: episode: 246, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [0.000, 33.540], loss: --, mean_squared_error: --, mean_q: --\n",
      "  378/6000: episode: 247, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.460 [0.000, 27.100], loss: --, mean_squared_error: --, mean_q: --\n",
      "  379/6000: episode: 248, duration: 0.008s, episode steps: 1, steps per second: 130, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.541 [0.000, 24.570], loss: --, mean_squared_error: --, mean_q: --\n",
      "  380/6000: episode: 249, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.838 [0.000, 39.530], loss: --, mean_squared_error: --, mean_q: --\n",
      "  382/6000: episode: 250, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.943 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  383/6000: episode: 251, duration: 0.009s, episode steps: 1, steps per second: 114, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.502 [0.000, 35.910], loss: --, mean_squared_error: --, mean_q: --\n",
      "  384/6000: episode: 252, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.203 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  385/6000: episode: 253, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.292 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  386/6000: episode: 254, duration: 0.008s, episode steps: 1, steps per second: 127, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.303 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  387/6000: episode: 255, duration: 0.008s, episode steps: 1, steps per second: 118, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.725 [0.000, 39.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  388/6000: episode: 256, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.530 [0.000, 19.840], loss: --, mean_squared_error: --, mean_q: --\n",
      "  389/6000: episode: 257, duration: 0.008s, episode steps: 1, steps per second: 125, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.361 [0.000, 20.170], loss: --, mean_squared_error: --, mean_q: --\n",
      "  390/6000: episode: 258, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.487 [0.000, 18.355], loss: --, mean_squared_error: --, mean_q: --\n",
      "  400/6000: episode: 259, duration: 0.035s, episode steps: 10, steps per second: 282, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.048 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  401/6000: episode: 260, duration: 0.008s, episode steps: 1, steps per second: 123, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.536 [0.000, 23.540], loss: --, mean_squared_error: --, mean_q: --\n",
      "  402/6000: episode: 261, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.306 [0.000, 24.520], loss: --, mean_squared_error: --, mean_q: --\n",
      "  403/6000: episode: 262, duration: 0.008s, episode steps: 1, steps per second: 127, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.604 [0.000, 38.980], loss: --, mean_squared_error: --, mean_q: --\n",
      "  404/6000: episode: 263, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.176 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  414/6000: episode: 264, duration: 0.038s, episode steps: 10, steps per second: 266, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.125 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  416/6000: episode: 265, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.319 [0.000, 31.080], loss: --, mean_squared_error: --, mean_q: --\n",
      "  417/6000: episode: 266, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.982 [0.000, 15.500], loss: --, mean_squared_error: --, mean_q: --\n",
      "  418/6000: episode: 267, duration: 0.010s, episode steps: 1, steps per second: 101, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.124 [0.000, 39.120], loss: --, mean_squared_error: --, mean_q: --\n",
      "  419/6000: episode: 268, duration: 0.007s, episode steps: 1, steps per second: 142, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.144 [0.000, 17.800], loss: --, mean_squared_error: --, mean_q: --\n",
      "  420/6000: episode: 269, duration: 0.009s, episode steps: 1, steps per second: 114, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.168 [0.000, 18.420], loss: --, mean_squared_error: --, mean_q: --\n",
      "  421/6000: episode: 270, duration: 0.008s, episode steps: 1, steps per second: 121, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.653 [0.000, 36.500], loss: --, mean_squared_error: --, mean_q: --\n",
      "  422/6000: episode: 271, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.367 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  432/6000: episode: 272, duration: 0.036s, episode steps: 10, steps per second: 282, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.200 [0.000, 2.000], mean observation: 1.703 [0.000, 34.470], loss: --, mean_squared_error: --, mean_q: --\n",
      "  433/6000: episode: 273, duration: 0.010s, episode steps: 1, steps per second: 99, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.062 [0.000, 39.880], loss: --, mean_squared_error: --, mean_q: --\n",
      "  434/6000: episode: 274, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.639 [0.000, 19.824], loss: --, mean_squared_error: --, mean_q: --\n",
      "  435/6000: episode: 275, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.215 [0.000, 17.110], loss: --, mean_squared_error: --, mean_q: --\n",
      "  436/6000: episode: 276, duration: 0.008s, episode steps: 1, steps per second: 132, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.678 [0.000, 27.810], loss: --, mean_squared_error: --, mean_q: --\n",
      "  437/6000: episode: 277, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.315 [0.000, 23.490], loss: --, mean_squared_error: --, mean_q: --\n",
      "  438/6000: episode: 278, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.062 [0.000, 39.880], loss: --, mean_squared_error: --, mean_q: --\n",
      "  439/6000: episode: 279, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.807 [0.000, 36.530], loss: --, mean_squared_error: --, mean_q: --\n",
      "  440/6000: episode: 280, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [0.000, 23.340], loss: --, mean_squared_error: --, mean_q: --\n",
      "  441/6000: episode: 281, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.805 [0.000, 12.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  442/6000: episode: 282, duration: 0.008s, episode steps: 1, steps per second: 130, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.079 [0.000, 16.349], loss: --, mean_squared_error: --, mean_q: --\n",
      "  443/6000: episode: 283, duration: 0.009s, episode steps: 1, steps per second: 114, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.417 [0.000, 21.050], loss: --, mean_squared_error: --, mean_q: --\n",
      "  444/6000: episode: 284, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.240 [0.000, 19.360], loss: --, mean_squared_error: --, mean_q: --\n",
      "  446/6000: episode: 285, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.736 [0.000, 9.920], loss: --, mean_squared_error: --, mean_q: --\n",
      "  456/6000: episode: 286, duration: 0.039s, episode steps: 10, steps per second: 257, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 3.000], mean observation: 1.225 [0.000, 21.250], loss: --, mean_squared_error: --, mean_q: --\n",
      "  457/6000: episode: 287, duration: 0.008s, episode steps: 1, steps per second: 123, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.155 [0.000, 26.600], loss: --, mean_squared_error: --, mean_q: --\n",
      "  458/6000: episode: 288, duration: 0.011s, episode steps: 1, steps per second: 91, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.907 [0.000, 13.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  459/6000: episode: 289, duration: 0.010s, episode steps: 1, steps per second: 102, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.469 [0.000, 23.860], loss: --, mean_squared_error: --, mean_q: --\n",
      "  460/6000: episode: 290, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.105 [0.000, 20.790], loss: --, mean_squared_error: --, mean_q: --\n",
      "  461/6000: episode: 291, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.341 [0.000, 18.320], loss: --, mean_squared_error: --, mean_q: --\n",
      "  462/6000: episode: 292, duration: 0.008s, episode steps: 1, steps per second: 130, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.171 [0.000, 23.240], loss: --, mean_squared_error: --, mean_q: --\n",
      "  463/6000: episode: 293, duration: 0.011s, episode steps: 1, steps per second: 94, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.361 [0.000, 26.970], loss: --, mean_squared_error: --, mean_q: --\n",
      "  464/6000: episode: 294, duration: 0.007s, episode steps: 1, steps per second: 135, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.511 [0.000, 19.446], loss: --, mean_squared_error: --, mean_q: --\n",
      "  465/6000: episode: 295, duration: 0.008s, episode steps: 1, steps per second: 128, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.111 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  466/6000: episode: 296, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.595 [0.000, 34.050], loss: --, mean_squared_error: --, mean_q: --\n",
      "  467/6000: episode: 297, duration: 0.008s, episode steps: 1, steps per second: 128, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.648 [0.000, 35.480], loss: --, mean_squared_error: --, mean_q: --\n",
      "  468/6000: episode: 298, duration: 0.009s, episode steps: 1, steps per second: 114, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.891 [0.000, 14.170], loss: --, mean_squared_error: --, mean_q: --\n",
      "  469/6000: episode: 299, duration: 0.008s, episode steps: 1, steps per second: 123, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.251 [0.000, 19.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  470/6000: episode: 300, duration: 0.008s, episode steps: 1, steps per second: 132, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.202 [0.000, 19.528], loss: --, mean_squared_error: --, mean_q: --\n",
      "  471/6000: episode: 301, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.401 [0.000, 29.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  472/6000: episode: 302, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.465 [0.000, 21.590], loss: --, mean_squared_error: --, mean_q: --\n",
      "  473/6000: episode: 303, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.749 [0.000, 36.150], loss: --, mean_squared_error: --, mean_q: --\n",
      "  483/6000: episode: 304, duration: 0.034s, episode steps: 10, steps per second: 293, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.017 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  484/6000: episode: 305, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.132 [0.000, 18.512], loss: --, mean_squared_error: --, mean_q: --\n",
      "  485/6000: episode: 306, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.453 [0.000, 21.220], loss: --, mean_squared_error: --, mean_q: --\n",
      "  486/6000: episode: 307, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.229 [0.000, 15.051], loss: --, mean_squared_error: --, mean_q: --\n",
      "  487/6000: episode: 308, duration: 0.009s, episode steps: 1, steps per second: 105, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.854 [0.000, 35.360], loss: --, mean_squared_error: --, mean_q: --\n",
      "  488/6000: episode: 309, duration: 0.008s, episode steps: 1, steps per second: 128, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.124 [0.000, 13.890], loss: --, mean_squared_error: --, mean_q: --\n",
      "  489/6000: episode: 310, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.407 [0.000, 19.480], loss: --, mean_squared_error: --, mean_q: --\n",
      "  490/6000: episode: 311, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.445 [0.000, 26.870], loss: --, mean_squared_error: --, mean_q: --\n",
      "  491/6000: episode: 312, duration: 0.010s, episode steps: 1, steps per second: 98, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.771 [0.000, 34.970], loss: --, mean_squared_error: --, mean_q: --\n",
      "  492/6000: episode: 313, duration: 0.010s, episode steps: 1, steps per second: 101, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.346 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  493/6000: episode: 314, duration: 0.010s, episode steps: 1, steps per second: 104, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.446 [0.000, 34.900], loss: --, mean_squared_error: --, mean_q: --\n",
      "  494/6000: episode: 315, duration: 0.008s, episode steps: 1, steps per second: 118, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.641 [0.000, 19.150], loss: --, mean_squared_error: --, mean_q: --\n",
      "  495/6000: episode: 316, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.231 [0.000, 16.178], loss: --, mean_squared_error: --, mean_q: --\n",
      "  496/6000: episode: 317, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.267 [0.000, 23.980], loss: --, mean_squared_error: --, mean_q: --\n",
      "  497/6000: episode: 318, duration: 0.008s, episode steps: 1, steps per second: 128, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.075 [0.000, 16.097], loss: --, mean_squared_error: --, mean_q: --\n",
      "  499/6000: episode: 319, duration: 0.011s, episode steps: 2, steps per second: 184, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.218 [0.000, 14.967], loss: --, mean_squared_error: --, mean_q: --\n",
      "  501/6000: episode: 320, duration: 0.010s, episode steps: 2, steps per second: 204, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.574 [0.000, 20.350], loss: --, mean_squared_error: --, mean_q: --\n",
      "  502/6000: episode: 321, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.958 [0.000, 14.838], loss: --, mean_squared_error: --, mean_q: --\n",
      "  503/6000: episode: 322, duration: 0.008s, episode steps: 1, steps per second: 128, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.563 [0.000, 34.190], loss: --, mean_squared_error: --, mean_q: --\n",
      "  504/6000: episode: 323, duration: 0.007s, episode steps: 1, steps per second: 135, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.014 [0.000, 14.190], loss: --, mean_squared_error: --, mean_q: --\n",
      "  505/6000: episode: 324, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.591 [0.000, 29.560], loss: --, mean_squared_error: --, mean_q: --\n",
      "  506/6000: episode: 325, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.958 [0.000, 33.630], loss: --, mean_squared_error: --, mean_q: --\n",
      "  508/6000: episode: 326, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.257 [0.000, 21.140], loss: --, mean_squared_error: --, mean_q: --\n",
      "  509/6000: episode: 327, duration: 0.010s, episode steps: 1, steps per second: 99, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.948 [0.000, 14.519], loss: --, mean_squared_error: --, mean_q: --\n",
      "  510/6000: episode: 328, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.744 [0.000, 32.540], loss: --, mean_squared_error: --, mean_q: --\n",
      "  511/6000: episode: 329, duration: 0.011s, episode steps: 1, steps per second: 95, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.401 [0.000, 29.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  512/6000: episode: 330, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.907 [0.000, 15.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  513/6000: episode: 331, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.993 [0.000, 14.700], loss: --, mean_squared_error: --, mean_q: --\n",
      "  514/6000: episode: 332, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.490 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  515/6000: episode: 333, duration: 0.007s, episode steps: 1, steps per second: 135, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.691 [0.000, 33.920], loss: --, mean_squared_error: --, mean_q: --\n",
      "  516/6000: episode: 334, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.399 [0.000, 36.480], loss: --, mean_squared_error: --, mean_q: --\n",
      "  517/6000: episode: 335, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.899 [0.000, 39.030], loss: --, mean_squared_error: --, mean_q: --\n",
      "  518/6000: episode: 336, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.658 [0.000, 32.600], loss: --, mean_squared_error: --, mean_q: --\n",
      "  519/6000: episode: 337, duration: 0.011s, episode steps: 1, steps per second: 88, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.111 [0.000, 19.514], loss: --, mean_squared_error: --, mean_q: --\n",
      "  521/6000: episode: 338, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.258 [0.000, 27.590], loss: --, mean_squared_error: --, mean_q: --\n",
      "  522/6000: episode: 339, duration: 0.010s, episode steps: 1, steps per second: 105, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [0.000, 27.410], loss: --, mean_squared_error: --, mean_q: --\n",
      "  523/6000: episode: 340, duration: 0.008s, episode steps: 1, steps per second: 130, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.679 [0.000, 33.010], loss: --, mean_squared_error: --, mean_q: --\n",
      "  524/6000: episode: 341, duration: 0.008s, episode steps: 1, steps per second: 128, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.481 [0.000, 30.850], loss: --, mean_squared_error: --, mean_q: --\n",
      "  526/6000: episode: 342, duration: 0.010s, episode steps: 2, steps per second: 195, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.736 [0.000, 39.750], loss: --, mean_squared_error: --, mean_q: --\n",
      "  527/6000: episode: 343, duration: 0.007s, episode steps: 1, steps per second: 141, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.512 [0.000, 22.700], loss: --, mean_squared_error: --, mean_q: --\n",
      "  528/6000: episode: 344, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.625 [0.000, 30.370], loss: --, mean_squared_error: --, mean_q: --\n",
      "  529/6000: episode: 345, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  530/6000: episode: 346, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.224 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  531/6000: episode: 347, duration: 0.008s, episode steps: 1, steps per second: 121, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.084 [0.000, 17.310], loss: --, mean_squared_error: --, mean_q: --\n",
      "  532/6000: episode: 348, duration: 0.009s, episode steps: 1, steps per second: 117, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.493 [0.000, 39.770], loss: --, mean_squared_error: --, mean_q: --\n",
      "  533/6000: episode: 349, duration: 0.008s, episode steps: 1, steps per second: 123, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.295 [0.000, 18.568], loss: --, mean_squared_error: --, mean_q: --\n",
      "  534/6000: episode: 350, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.116 [0.000, 22.090], loss: --, mean_squared_error: --, mean_q: --\n",
      "  535/6000: episode: 351, duration: 0.009s, episode steps: 1, steps per second: 113, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.196 [0.000, 21.890], loss: --, mean_squared_error: --, mean_q: --\n",
      "  536/6000: episode: 352, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.399 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  537/6000: episode: 353, duration: 0.009s, episode steps: 1, steps per second: 113, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.498 [0.000, 27.720], loss: --, mean_squared_error: --, mean_q: --\n",
      "  538/6000: episode: 354, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.275 [0.000, 17.980], loss: --, mean_squared_error: --, mean_q: --\n",
      "  539/6000: episode: 355, duration: 0.010s, episode steps: 1, steps per second: 102, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.053 [0.000, 13.113], loss: --, mean_squared_error: --, mean_q: --\n",
      "  540/6000: episode: 356, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.198 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  541/6000: episode: 357, duration: 0.011s, episode steps: 1, steps per second: 90, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.080 [0.000, 14.385], loss: --, mean_squared_error: --, mean_q: --\n",
      "  542/6000: episode: 358, duration: 0.011s, episode steps: 1, steps per second: 93, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.189 [0.000, 25.290], loss: --, mean_squared_error: --, mean_q: --\n",
      "  543/6000: episode: 359, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.516 [0.000, 24.410], loss: --, mean_squared_error: --, mean_q: --\n",
      "  544/6000: episode: 360, duration: 0.011s, episode steps: 1, steps per second: 88, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.554 [0.000, 21.410], loss: --, mean_squared_error: --, mean_q: --\n",
      "  545/6000: episode: 361, duration: 0.010s, episode steps: 1, steps per second: 101, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.176 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  546/6000: episode: 362, duration: 0.008s, episode steps: 1, steps per second: 122, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.469 [0.000, 27.610], loss: --, mean_squared_error: --, mean_q: --\n",
      "  547/6000: episode: 363, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.744 [0.000, 39.900], loss: --, mean_squared_error: --, mean_q: --\n",
      "  548/6000: episode: 364, duration: 0.007s, episode steps: 1, steps per second: 137, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.230 [0.000, 32.010], loss: --, mean_squared_error: --, mean_q: --\n",
      "  549/6000: episode: 365, duration: 0.007s, episode steps: 1, steps per second: 147, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.227 [0.000, 18.527], loss: --, mean_squared_error: --, mean_q: --\n",
      "  550/6000: episode: 366, duration: 0.008s, episode steps: 1, steps per second: 132, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.749 [0.000, 24.170], loss: --, mean_squared_error: --, mean_q: --\n",
      "  551/6000: episode: 367, duration: 0.007s, episode steps: 1, steps per second: 144, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.790 [0.000, 36.170], loss: --, mean_squared_error: --, mean_q: --\n",
      "  552/6000: episode: 368, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.641 [0.000, 36.780], loss: --, mean_squared_error: --, mean_q: --\n",
      "  553/6000: episode: 369, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.277 [0.000, 17.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  554/6000: episode: 370, duration: 0.008s, episode steps: 1, steps per second: 118, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.279 [0.000, 19.078], loss: --, mean_squared_error: --, mean_q: --\n",
      "  555/6000: episode: 371, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.132 [0.000, 19.180], loss: --, mean_squared_error: --, mean_q: --\n",
      "  556/6000: episode: 372, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.002 [0.000, 14.744], loss: --, mean_squared_error: --, mean_q: --\n",
      "  557/6000: episode: 373, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.724 [0.000, 23.680], loss: --, mean_squared_error: --, mean_q: --\n",
      "  558/6000: episode: 374, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.369 [0.000, 28.880], loss: --, mean_squared_error: --, mean_q: --\n",
      "  559/6000: episode: 375, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.298 [0.000, 22.460], loss: --, mean_squared_error: --, mean_q: --\n",
      "  560/6000: episode: 376, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.517 [0.000, 29.290], loss: --, mean_squared_error: --, mean_q: --\n",
      "  561/6000: episode: 377, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.646 [0.000, 22.370], loss: --, mean_squared_error: --, mean_q: --\n",
      "  562/6000: episode: 378, duration: 0.011s, episode steps: 1, steps per second: 95, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.236 [0.000, 21.290], loss: --, mean_squared_error: --, mean_q: --\n",
      "  563/6000: episode: 379, duration: 0.009s, episode steps: 1, steps per second: 106, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.461 [0.000, 34.010], loss: --, mean_squared_error: --, mean_q: --\n",
      "  565/6000: episode: 380, duration: 0.012s, episode steps: 2, steps per second: 167, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 0.841 [0.000, 17.250], loss: --, mean_squared_error: --, mean_q: --\n",
      "  566/6000: episode: 381, duration: 0.010s, episode steps: 1, steps per second: 97, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.322 [0.000, 23.390], loss: --, mean_squared_error: --, mean_q: --\n",
      "  567/6000: episode: 382, duration: 0.011s, episode steps: 1, steps per second: 91, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.204 [0.000, 17.070], loss: --, mean_squared_error: --, mean_q: --\n",
      "  568/6000: episode: 383, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.284 [0.000, 19.104], loss: --, mean_squared_error: --, mean_q: --\n",
      "  569/6000: episode: 384, duration: 0.007s, episode steps: 1, steps per second: 146, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.259 [0.000, 21.480], loss: --, mean_squared_error: --, mean_q: --\n",
      "  576/6000: episode: 385, duration: 0.022s, episode steps: 7, steps per second: 315, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.143 [1.000, 2.000], mean observation: 1.061 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  577/6000: episode: 386, duration: 0.008s, episode steps: 1, steps per second: 128, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.311 [0.000, 34.880], loss: --, mean_squared_error: --, mean_q: --\n",
      "  578/6000: episode: 387, duration: 0.007s, episode steps: 1, steps per second: 146, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.931 [0.000, 37.320], loss: --, mean_squared_error: --, mean_q: --\n",
      "  579/6000: episode: 388, duration: 0.008s, episode steps: 1, steps per second: 130, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.030 [0.000, 14.420], loss: --, mean_squared_error: --, mean_q: --\n",
      "  580/6000: episode: 389, duration: 0.011s, episode steps: 1, steps per second: 94, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.077 [0.000, 17.540], loss: --, mean_squared_error: --, mean_q: --\n",
      "  581/6000: episode: 390, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.124 [0.000, 24.440], loss: --, mean_squared_error: --, mean_q: --\n",
      "  582/6000: episode: 391, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.709 [0.000, 38.750], loss: --, mean_squared_error: --, mean_q: --\n",
      "  583/6000: episode: 392, duration: 0.009s, episode steps: 1, steps per second: 106, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.261 [0.000, 26.490], loss: --, mean_squared_error: --, mean_q: --\n",
      "  584/6000: episode: 393, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.383 [0.000, 30.490], loss: --, mean_squared_error: --, mean_q: --\n",
      "  585/6000: episode: 394, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.699 [0.000, 33.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  586/6000: episode: 395, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.053 [0.000, 15.596], loss: --, mean_squared_error: --, mean_q: --\n",
      "  587/6000: episode: 396, duration: 0.011s, episode steps: 1, steps per second: 93, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.950 [0.000, 15.060], loss: --, mean_squared_error: --, mean_q: --\n",
      "  588/6000: episode: 397, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.445 [0.000, 39.110], loss: --, mean_squared_error: --, mean_q: --\n",
      "  589/6000: episode: 398, duration: 0.010s, episode steps: 1, steps per second: 100, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.065 [0.000, 14.409], loss: --, mean_squared_error: --, mean_q: --\n",
      "  590/6000: episode: 399, duration: 0.011s, episode steps: 1, steps per second: 89, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.496 [0.000, 27.110], loss: --, mean_squared_error: --, mean_q: --\n",
      "  591/6000: episode: 400, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.626 [0.000, 27.590], loss: --, mean_squared_error: --, mean_q: --\n",
      "  592/6000: episode: 401, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.246 [0.000, 17.020], loss: --, mean_squared_error: --, mean_q: --\n",
      "  593/6000: episode: 402, duration: 0.011s, episode steps: 1, steps per second: 87, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.073 [0.000, 17.240], loss: --, mean_squared_error: --, mean_q: --\n",
      "  594/6000: episode: 403, duration: 0.008s, episode steps: 1, steps per second: 132, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.614 [0.000, 31.650], loss: --, mean_squared_error: --, mean_q: --\n",
      "  595/6000: episode: 404, duration: 0.008s, episode steps: 1, steps per second: 123, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.624 [0.000, 27.240], loss: --, mean_squared_error: --, mean_q: --\n",
      "  596/6000: episode: 405, duration: 0.007s, episode steps: 1, steps per second: 145, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.275 [0.000, 15.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  598/6000: episode: 406, duration: 0.009s, episode steps: 2, steps per second: 219, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.003 [0.000, 12.980], loss: --, mean_squared_error: --, mean_q: --\n",
      "  600/6000: episode: 407, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.028 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  601/6000: episode: 408, duration: 0.008s, episode steps: 1, steps per second: 124, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.687 [0.000, 39.780], loss: --, mean_squared_error: --, mean_q: --\n",
      "  602/6000: episode: 409, duration: 0.010s, episode steps: 1, steps per second: 98, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.745 [0.000, 36.290], loss: --, mean_squared_error: --, mean_q: --\n",
      "  603/6000: episode: 410, duration: 0.011s, episode steps: 1, steps per second: 89, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.809 [0.000, 36.560], loss: --, mean_squared_error: --, mean_q: --\n",
      "  604/6000: episode: 411, duration: 0.011s, episode steps: 1, steps per second: 88, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.691 [0.000, 11.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  605/6000: episode: 412, duration: 0.010s, episode steps: 1, steps per second: 97, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.043 [0.000, 36.030], loss: --, mean_squared_error: --, mean_q: --\n",
      "  606/6000: episode: 413, duration: 0.011s, episode steps: 1, steps per second: 89, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.999 [0.000, 37.310], loss: --, mean_squared_error: --, mean_q: --\n",
      "  607/6000: episode: 414, duration: 0.012s, episode steps: 1, steps per second: 86, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.301 [0.000, 18.750], loss: --, mean_squared_error: --, mean_q: --\n",
      "  608/6000: episode: 415, duration: 0.014s, episode steps: 1, steps per second: 74, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.814 [0.000, 25.390], loss: --, mean_squared_error: --, mean_q: --\n",
      "  609/6000: episode: 416, duration: 0.011s, episode steps: 1, steps per second: 88, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.900 [0.000, 34.890], loss: --, mean_squared_error: --, mean_q: --\n",
      "  611/6000: episode: 417, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.295 [0.000, 20.690], loss: --, mean_squared_error: --, mean_q: --\n",
      "  612/6000: episode: 418, duration: 0.012s, episode steps: 1, steps per second: 87, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.277 [0.000, 24.270], loss: --, mean_squared_error: --, mean_q: --\n",
      "  613/6000: episode: 419, duration: 0.012s, episode steps: 1, steps per second: 85, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.899 [0.000, 28.500], loss: --, mean_squared_error: --, mean_q: --\n",
      "  614/6000: episode: 420, duration: 0.012s, episode steps: 1, steps per second: 86, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.404 [0.000, 22.730], loss: --, mean_squared_error: --, mean_q: --\n",
      "  616/6000: episode: 421, duration: 0.015s, episode steps: 2, steps per second: 133, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 0.854 [0.000, 14.523], loss: --, mean_squared_error: --, mean_q: --\n",
      "  617/6000: episode: 422, duration: 0.011s, episode steps: 1, steps per second: 91, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.267 [0.000, 30.230], loss: --, mean_squared_error: --, mean_q: --\n",
      "  618/6000: episode: 423, duration: 0.012s, episode steps: 1, steps per second: 84, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [0.000, 19.081], loss: --, mean_squared_error: --, mean_q: --\n",
      "  619/6000: episode: 424, duration: 0.014s, episode steps: 1, steps per second: 71, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.771 [0.000, 30.020], loss: --, mean_squared_error: --, mean_q: --\n",
      "  620/6000: episode: 425, duration: 0.015s, episode steps: 1, steps per second: 66, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.521 [0.000, 38.880], loss: --, mean_squared_error: --, mean_q: --\n",
      "  630/6000: episode: 426, duration: 0.038s, episode steps: 10, steps per second: 264, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.934 [0.000, 17.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  631/6000: episode: 427, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.397 [0.000, 28.990], loss: --, mean_squared_error: --, mean_q: --\n",
      "  632/6000: episode: 428, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.801 [0.000, 35.870], loss: --, mean_squared_error: --, mean_q: --\n",
      "  633/6000: episode: 429, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.168 [0.000, 19.849], loss: --, mean_squared_error: --, mean_q: --\n",
      "  634/6000: episode: 430, duration: 0.008s, episode steps: 1, steps per second: 131, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.457 [0.000, 22.670], loss: --, mean_squared_error: --, mean_q: --\n",
      "  636/6000: episode: 431, duration: 0.010s, episode steps: 2, steps per second: 198, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.421 [0.000, 37.040], loss: --, mean_squared_error: --, mean_q: --\n",
      "  638/6000: episode: 432, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.377 [0.000, 31.970], loss: --, mean_squared_error: --, mean_q: --\n",
      "  639/6000: episode: 433, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.355 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  649/6000: episode: 434, duration: 0.035s, episode steps: 10, steps per second: 285, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.521 [0.000, 27.580], loss: --, mean_squared_error: --, mean_q: --\n",
      "  650/6000: episode: 435, duration: 0.008s, episode steps: 1, steps per second: 125, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.225 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  651/6000: episode: 436, duration: 0.009s, episode steps: 1, steps per second: 114, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.790 [0.000, 30.940], loss: --, mean_squared_error: --, mean_q: --\n",
      "  652/6000: episode: 437, duration: 0.008s, episode steps: 1, steps per second: 122, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.698 [0.000, 33.970], loss: --, mean_squared_error: --, mean_q: --\n",
      "  654/6000: episode: 438, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.707 [0.000, 38.320], loss: --, mean_squared_error: --, mean_q: --\n",
      "  655/6000: episode: 439, duration: 0.008s, episode steps: 1, steps per second: 126, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.384 [0.000, 27.880], loss: --, mean_squared_error: --, mean_q: --\n",
      "  656/6000: episode: 440, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.008 [0.000, 18.251], loss: --, mean_squared_error: --, mean_q: --\n",
      "  657/6000: episode: 441, duration: 0.012s, episode steps: 1, steps per second: 84, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.508 [0.000, 34.350], loss: --, mean_squared_error: --, mean_q: --\n",
      "  658/6000: episode: 442, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.723 [0.000, 10.430], loss: --, mean_squared_error: --, mean_q: --\n",
      "  659/6000: episode: 443, duration: 0.011s, episode steps: 1, steps per second: 92, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.335 [0.000, 16.344], loss: --, mean_squared_error: --, mean_q: --\n",
      "  660/6000: episode: 444, duration: 0.014s, episode steps: 1, steps per second: 72, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.975 [0.000, 24.430], loss: --, mean_squared_error: --, mean_q: --\n",
      "  661/6000: episode: 445, duration: 0.010s, episode steps: 1, steps per second: 96, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.495 [0.000, 36.440], loss: --, mean_squared_error: --, mean_q: --\n",
      "  662/6000: episode: 446, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.000 [0.000, 16.951], loss: --, mean_squared_error: --, mean_q: --\n",
      "  663/6000: episode: 447, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.372 [0.000, 19.718], loss: --, mean_squared_error: --, mean_q: --\n",
      "  664/6000: episode: 448, duration: 0.010s, episode steps: 1, steps per second: 104, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.757 [0.000, 31.550], loss: --, mean_squared_error: --, mean_q: --\n",
      "  665/6000: episode: 449, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.699 [0.000, 33.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  666/6000: episode: 450, duration: 0.010s, episode steps: 1, steps per second: 98, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.124 [0.000, 39.120], loss: --, mean_squared_error: --, mean_q: --\n",
      "  667/6000: episode: 451, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.235 [0.000, 15.892], loss: --, mean_squared_error: --, mean_q: --\n",
      "  668/6000: episode: 452, duration: 0.008s, episode steps: 1, steps per second: 125, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.376 [0.000, 34.420], loss: --, mean_squared_error: --, mean_q: --\n",
      "  669/6000: episode: 453, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.688 [0.000, 19.062], loss: --, mean_squared_error: --, mean_q: --\n",
      "  670/6000: episode: 454, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.727 [0.000, 39.240], loss: --, mean_squared_error: --, mean_q: --\n",
      "  671/6000: episode: 455, duration: 0.009s, episode steps: 1, steps per second: 114, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.757 [0.000, 36.410], loss: --, mean_squared_error: --, mean_q: --\n",
      "  672/6000: episode: 456, duration: 0.010s, episode steps: 1, steps per second: 104, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.867 [0.000, 38.630], loss: --, mean_squared_error: --, mean_q: --\n",
      "  673/6000: episode: 457, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.598 [0.000, 19.978], loss: --, mean_squared_error: --, mean_q: --\n",
      "  674/6000: episode: 458, duration: 0.011s, episode steps: 1, steps per second: 94, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.539 [0.000, 29.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  676/6000: episode: 459, duration: 0.011s, episode steps: 2, steps per second: 182, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.282 [0.000, 19.040], loss: --, mean_squared_error: --, mean_q: --\n",
      "  677/6000: episode: 460, duration: 0.008s, episode steps: 1, steps per second: 133, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.494 [0.000, 35.260], loss: --, mean_squared_error: --, mean_q: --\n",
      "  678/6000: episode: 461, duration: 0.009s, episode steps: 1, steps per second: 106, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.522 [0.000, 21.370], loss: --, mean_squared_error: --, mean_q: --\n",
      "  679/6000: episode: 462, duration: 0.010s, episode steps: 1, steps per second: 104, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.468 [0.000, 30.590], loss: --, mean_squared_error: --, mean_q: --\n",
      "  680/6000: episode: 463, duration: 0.011s, episode steps: 1, steps per second: 93, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.931 [0.000, 13.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  681/6000: episode: 464, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.363 [0.000, 21.770], loss: --, mean_squared_error: --, mean_q: --\n",
      "  682/6000: episode: 465, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.381 [0.000, 32.450], loss: --, mean_squared_error: --, mean_q: --\n",
      "  692/6000: episode: 466, duration: 0.034s, episode steps: 10, steps per second: 294, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.306 [0.000, 20.420], loss: --, mean_squared_error: --, mean_q: --\n",
      "  693/6000: episode: 467, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.998 [0.000, 14.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  694/6000: episode: 468, duration: 0.009s, episode steps: 1, steps per second: 113, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.729 [0.000, 36.380], loss: --, mean_squared_error: --, mean_q: --\n",
      "  695/6000: episode: 469, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.370 [0.000, 21.680], loss: --, mean_squared_error: --, mean_q: --\n",
      "  696/6000: episode: 470, duration: 0.008s, episode steps: 1, steps per second: 118, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.622 [0.000, 34.410], loss: --, mean_squared_error: --, mean_q: --\n",
      "  697/6000: episode: 471, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.251 [0.000, 19.630], loss: --, mean_squared_error: --, mean_q: --\n",
      "  698/6000: episode: 472, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.566 [0.000, 24.440], loss: --, mean_squared_error: --, mean_q: --\n",
      "  699/6000: episode: 473, duration: 0.011s, episode steps: 1, steps per second: 91, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.816 [0.000, 38.270], loss: --, mean_squared_error: --, mean_q: --\n",
      "  700/6000: episode: 474, duration: 0.011s, episode steps: 1, steps per second: 92, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.491 [0.000, 23.310], loss: --, mean_squared_error: --, mean_q: --\n",
      "  701/6000: episode: 475, duration: 0.010s, episode steps: 1, steps per second: 100, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.636 [0.000, 22.170], loss: --, mean_squared_error: --, mean_q: --\n",
      "  702/6000: episode: 476, duration: 0.011s, episode steps: 1, steps per second: 95, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.766 [0.000, 9.980], loss: --, mean_squared_error: --, mean_q: --\n",
      "  703/6000: episode: 477, duration: 0.008s, episode steps: 1, steps per second: 127, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.120 [0.000, 14.941], loss: --, mean_squared_error: --, mean_q: --\n",
      "  704/6000: episode: 478, duration: 0.009s, episode steps: 1, steps per second: 117, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.754 [0.000, 32.830], loss: --, mean_squared_error: --, mean_q: --\n",
      "  705/6000: episode: 479, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.748 [0.000, 33.950], loss: --, mean_squared_error: --, mean_q: --\n",
      "  706/6000: episode: 480, duration: 0.013s, episode steps: 1, steps per second: 80, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.118 [0.000, 22.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  707/6000: episode: 481, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.570 [0.000, 29.630], loss: --, mean_squared_error: --, mean_q: --\n",
      "  708/6000: episode: 482, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.235 [0.000, 15.916], loss: --, mean_squared_error: --, mean_q: --\n",
      "  718/6000: episode: 483, duration: 0.034s, episode steps: 10, steps per second: 292, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [0.000, 16.439], loss: --, mean_squared_error: --, mean_q: --\n",
      "  719/6000: episode: 484, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.803 [0.000, 39.850], loss: --, mean_squared_error: --, mean_q: --\n",
      "  720/6000: episode: 485, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.398 [0.000, 27.350], loss: --, mean_squared_error: --, mean_q: --\n",
      "  722/6000: episode: 486, duration: 0.011s, episode steps: 2, steps per second: 186, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.698 [0.000, 19.102], loss: --, mean_squared_error: --, mean_q: --\n",
      "  723/6000: episode: 487, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.669 [0.000, 34.050], loss: --, mean_squared_error: --, mean_q: --\n",
      "  733/6000: episode: 488, duration: 0.034s, episode steps: 10, steps per second: 296, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.100 [0.000, 1.000], mean observation: 1.398 [0.000, 21.900], loss: --, mean_squared_error: --, mean_q: --\n",
      "  734/6000: episode: 489, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.464 [0.000, 33.720], loss: --, mean_squared_error: --, mean_q: --\n",
      "  735/6000: episode: 490, duration: 0.011s, episode steps: 1, steps per second: 89, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.341 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  736/6000: episode: 491, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.297 [0.000, 26.470], loss: --, mean_squared_error: --, mean_q: --\n",
      "  737/6000: episode: 492, duration: 0.008s, episode steps: 1, steps per second: 124, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.460 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  738/6000: episode: 493, duration: 0.007s, episode steps: 1, steps per second: 142, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.297 [0.000, 17.375], loss: --, mean_squared_error: --, mean_q: --\n",
      "  748/6000: episode: 494, duration: 0.042s, episode steps: 10, steps per second: 238, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.165 [0.000, 17.848], loss: --, mean_squared_error: --, mean_q: --\n",
      "  750/6000: episode: 495, duration: 0.011s, episode steps: 2, steps per second: 183, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.526 [0.000, 33.370], loss: --, mean_squared_error: --, mean_q: --\n",
      "  751/6000: episode: 496, duration: 0.008s, episode steps: 1, steps per second: 120, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.019 [0.000, 14.544], loss: --, mean_squared_error: --, mean_q: --\n",
      "  752/6000: episode: 497, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.362 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  753/6000: episode: 498, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.186 [0.000, 19.400], loss: --, mean_squared_error: --, mean_q: --\n",
      "  758/6000: episode: 499, duration: 0.020s, episode steps: 5, steps per second: 253, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.800 [0.000, 1.000], mean observation: 1.389 [0.000, 39.170], loss: --, mean_squared_error: --, mean_q: --\n",
      "  759/6000: episode: 500, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.526 [0.000, 20.870], loss: --, mean_squared_error: --, mean_q: --\n",
      "  760/6000: episode: 501, duration: 0.009s, episode steps: 1, steps per second: 114, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.061 [0.000, 15.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  761/6000: episode: 502, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.330 [0.000, 18.350], loss: --, mean_squared_error: --, mean_q: --\n",
      "  763/6000: episode: 503, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.211 [0.000, 19.910], loss: --, mean_squared_error: --, mean_q: --\n",
      "  764/6000: episode: 504, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.201 [0.000, 17.003], loss: --, mean_squared_error: --, mean_q: --\n",
      "  765/6000: episode: 505, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.894 [0.000, 15.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  766/6000: episode: 506, duration: 0.011s, episode steps: 1, steps per second: 94, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.602 [0.000, 35.770], loss: --, mean_squared_error: --, mean_q: --\n",
      "  767/6000: episode: 507, duration: 0.008s, episode steps: 1, steps per second: 125, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.047 [0.000, 17.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  768/6000: episode: 508, duration: 0.008s, episode steps: 1, steps per second: 125, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.416 [0.000, 24.390], loss: --, mean_squared_error: --, mean_q: --\n",
      "  769/6000: episode: 509, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.525 [0.000, 25.080], loss: --, mean_squared_error: --, mean_q: --\n",
      "  770/6000: episode: 510, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.203 [0.000, 19.850], loss: --, mean_squared_error: --, mean_q: --\n",
      "  771/6000: episode: 511, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.336 [0.000, 21.520], loss: --, mean_squared_error: --, mean_q: --\n",
      "  772/6000: episode: 512, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.790 [0.000, 11.319], loss: --, mean_squared_error: --, mean_q: --\n",
      "  773/6000: episode: 513, duration: 0.007s, episode steps: 1, steps per second: 136, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.298 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  774/6000: episode: 514, duration: 0.007s, episode steps: 1, steps per second: 138, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.565 [0.000, 26.630], loss: --, mean_squared_error: --, mean_q: --\n",
      "  784/6000: episode: 515, duration: 0.035s, episode steps: 10, steps per second: 286, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.724 [0.000, 34.930], loss: --, mean_squared_error: --, mean_q: --\n",
      "  785/6000: episode: 516, duration: 0.009s, episode steps: 1, steps per second: 107, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.169 [0.000, 19.091], loss: --, mean_squared_error: --, mean_q: --\n",
      "  786/6000: episode: 517, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.904 [0.000, 36.960], loss: --, mean_squared_error: --, mean_q: --\n",
      "  787/6000: episode: 518, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.003 [0.000, 20.390], loss: --, mean_squared_error: --, mean_q: --\n",
      "  788/6000: episode: 519, duration: 0.007s, episode steps: 1, steps per second: 139, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.473 [0.000, 19.509], loss: --, mean_squared_error: --, mean_q: --\n",
      "  789/6000: episode: 520, duration: 0.013s, episode steps: 1, steps per second: 79, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.855 [0.000, 35.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  790/6000: episode: 521, duration: 0.010s, episode steps: 1, steps per second: 99, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.536 [0.000, 23.540], loss: --, mean_squared_error: --, mean_q: --\n",
      "  791/6000: episode: 522, duration: 0.009s, episode steps: 1, steps per second: 112, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.389 [0.000, 33.890], loss: --, mean_squared_error: --, mean_q: --\n",
      "  792/6000: episode: 523, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.815 [0.000, 9.559], loss: --, mean_squared_error: --, mean_q: --\n",
      "  793/6000: episode: 524, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [0.000, 21.710], loss: --, mean_squared_error: --, mean_q: --\n",
      "  794/6000: episode: 525, duration: 0.008s, episode steps: 1, steps per second: 121, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.106 [0.000, 23.610], loss: --, mean_squared_error: --, mean_q: --\n",
      "  795/6000: episode: 526, duration: 0.009s, episode steps: 1, steps per second: 106, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.282 [0.000, 19.040], loss: --, mean_squared_error: --, mean_q: --\n",
      "  796/6000: episode: 527, duration: 0.011s, episode steps: 1, steps per second: 91, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.975 [0.000, 13.507], loss: --, mean_squared_error: --, mean_q: --\n",
      "  797/6000: episode: 528, duration: 0.011s, episode steps: 1, steps per second: 93, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.609 [0.000, 29.700], loss: --, mean_squared_error: --, mean_q: --\n",
      "  798/6000: episode: 529, duration: 0.018s, episode steps: 1, steps per second: 56, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.846 [0.000, 29.910], loss: --, mean_squared_error: --, mean_q: --\n",
      "  799/6000: episode: 530, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.828 [0.000, 34.030], loss: --, mean_squared_error: --, mean_q: --\n",
      "  800/6000: episode: 531, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.483 [0.000, 23.430], loss: --, mean_squared_error: --, mean_q: --\n",
      "  801/6000: episode: 532, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.626 [0.000, 33.280], loss: --, mean_squared_error: --, mean_q: --\n",
      "  802/6000: episode: 533, duration: 0.007s, episode steps: 1, steps per second: 144, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.010 [0.000, 15.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  812/6000: episode: 534, duration: 0.035s, episode steps: 10, steps per second: 289, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.521 [0.000, 27.580], loss: --, mean_squared_error: --, mean_q: --\n",
      "  813/6000: episode: 535, duration: 0.008s, episode steps: 1, steps per second: 118, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.860 [0.000, 39.720], loss: --, mean_squared_error: --, mean_q: --\n",
      "  814/6000: episode: 536, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.132 [0.000, 18.512], loss: --, mean_squared_error: --, mean_q: --\n",
      "  816/6000: episode: 537, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.727 [0.000, 33.110], loss: --, mean_squared_error: --, mean_q: --\n",
      "  826/6000: episode: 538, duration: 0.035s, episode steps: 10, steps per second: 282, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.800 [1.000, 3.000], mean observation: 1.416 [0.000, 17.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  827/6000: episode: 539, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.186 [0.000, 34.620], loss: --, mean_squared_error: --, mean_q: --\n",
      "  828/6000: episode: 540, duration: 0.010s, episode steps: 1, steps per second: 104, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.699 [0.000, 33.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  829/6000: episode: 541, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.590 [0.000, 38.050], loss: --, mean_squared_error: --, mean_q: --\n",
      "  839/6000: episode: 542, duration: 0.039s, episode steps: 10, steps per second: 258, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.219 [0.000, 18.140], loss: --, mean_squared_error: --, mean_q: --\n",
      "  840/6000: episode: 543, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.675 [0.000, 22.580], loss: --, mean_squared_error: --, mean_q: --\n",
      "  841/6000: episode: 544, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.375 [0.000, 18.345], loss: --, mean_squared_error: --, mean_q: --\n",
      "  842/6000: episode: 545, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.494 [0.000, 24.630], loss: --, mean_squared_error: --, mean_q: --\n",
      "  843/6000: episode: 546, duration: 0.011s, episode steps: 1, steps per second: 91, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.500 [0.000, 31.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  844/6000: episode: 547, duration: 0.008s, episode steps: 1, steps per second: 122, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.137 [0.000, 17.970], loss: --, mean_squared_error: --, mean_q: --\n",
      "  845/6000: episode: 548, duration: 0.007s, episode steps: 1, steps per second: 135, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.697 [0.000, 30.230], loss: --, mean_squared_error: --, mean_q: --\n",
      "  855/6000: episode: 549, duration: 0.038s, episode steps: 10, steps per second: 266, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.114 [0.000, 16.650], loss: --, mean_squared_error: --, mean_q: --\n",
      "  856/6000: episode: 550, duration: 0.009s, episode steps: 1, steps per second: 106, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.737 [0.000, 26.120], loss: --, mean_squared_error: --, mean_q: --\n",
      "  857/6000: episode: 551, duration: 0.010s, episode steps: 1, steps per second: 96, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.613 [0.000, 28.040], loss: --, mean_squared_error: --, mean_q: --\n",
      "  858/6000: episode: 552, duration: 0.008s, episode steps: 1, steps per second: 129, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.110 [0.000, 19.355], loss: --, mean_squared_error: --, mean_q: --\n",
      "  859/6000: episode: 553, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.822 [0.000, 12.034], loss: --, mean_squared_error: --, mean_q: --\n",
      "  869/6000: episode: 554, duration: 0.041s, episode steps: 10, steps per second: 244, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 3.000], mean observation: 1.795 [0.000, 34.780], loss: --, mean_squared_error: --, mean_q: --\n",
      "  870/6000: episode: 555, duration: 0.011s, episode steps: 1, steps per second: 87, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.382 [0.000, 19.190], loss: --, mean_squared_error: --, mean_q: --\n",
      "  872/6000: episode: 556, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 0.982 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  873/6000: episode: 557, duration: 0.023s, episode steps: 1, steps per second: 44, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.676 [0.000, 36.940], loss: --, mean_squared_error: --, mean_q: --\n",
      "  881/6000: episode: 558, duration: 0.030s, episode steps: 8, steps per second: 269, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.875 [0.000, 1.000], mean observation: 1.381 [0.000, 31.280], loss: --, mean_squared_error: --, mean_q: --\n",
      "  882/6000: episode: 559, duration: 0.008s, episode steps: 1, steps per second: 122, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.883 [0.000, 32.640], loss: --, mean_squared_error: --, mean_q: --\n",
      "  883/6000: episode: 560, duration: 0.008s, episode steps: 1, steps per second: 123, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.649 [0.000, 18.770], loss: --, mean_squared_error: --, mean_q: --\n",
      "  884/6000: episode: 561, duration: 0.011s, episode steps: 1, steps per second: 88, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.062 [0.000, 16.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  885/6000: episode: 562, duration: 0.008s, episode steps: 1, steps per second: 124, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.611 [0.000, 29.870], loss: --, mean_squared_error: --, mean_q: --\n",
      "  886/6000: episode: 563, duration: 0.010s, episode steps: 1, steps per second: 104, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.406 [0.000, 21.650], loss: --, mean_squared_error: --, mean_q: --\n",
      "  887/6000: episode: 564, duration: 0.008s, episode steps: 1, steps per second: 124, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.964 [0.000, 14.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  888/6000: episode: 565, duration: 0.009s, episode steps: 1, steps per second: 114, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.976 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  889/6000: episode: 566, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.771 [0.000, 31.460], loss: --, mean_squared_error: --, mean_q: --\n",
      "  890/6000: episode: 567, duration: 0.009s, episode steps: 1, steps per second: 108, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.009 [0.000, 13.477], loss: --, mean_squared_error: --, mean_q: --\n",
      "  891/6000: episode: 568, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.646 [0.000, 22.370], loss: --, mean_squared_error: --, mean_q: --\n",
      "  892/6000: episode: 569, duration: 0.009s, episode steps: 1, steps per second: 113, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.945 [0.000, 33.900], loss: --, mean_squared_error: --, mean_q: --\n",
      "  893/6000: episode: 570, duration: 0.011s, episode steps: 1, steps per second: 92, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.576 [0.000, 22.750], loss: --, mean_squared_error: --, mean_q: --\n",
      "  894/6000: episode: 571, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.499 [0.000, 27.930], loss: --, mean_squared_error: --, mean_q: --\n",
      "  895/6000: episode: 572, duration: 0.010s, episode steps: 1, steps per second: 102, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.737 [0.000, 36.210], loss: --, mean_squared_error: --, mean_q: --\n",
      "  896/6000: episode: 573, duration: 0.010s, episode steps: 1, steps per second: 103, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.469 [0.000, 27.580], loss: --, mean_squared_error: --, mean_q: --\n",
      "  897/6000: episode: 574, duration: 0.008s, episode steps: 1, steps per second: 125, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.364 [0.000, 37.270], loss: --, mean_squared_error: --, mean_q: --\n",
      "  898/6000: episode: 575, duration: 0.009s, episode steps: 1, steps per second: 106, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.649 [0.000, 19.120], loss: --, mean_squared_error: --, mean_q: --\n",
      "  899/6000: episode: 576, duration: 0.010s, episode steps: 1, steps per second: 97, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.548 [0.000, 35.450], loss: --, mean_squared_error: --, mean_q: --\n",
      "  900/6000: episode: 577, duration: 0.012s, episode steps: 1, steps per second: 83, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.414 [0.000, 17.610], loss: --, mean_squared_error: --, mean_q: --\n",
      "  901/6000: episode: 578, duration: 0.010s, episode steps: 1, steps per second: 100, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.461 [0.000, 34.010], loss: --, mean_squared_error: --, mean_q: --\n",
      "  902/6000: episode: 579, duration: 0.011s, episode steps: 1, steps per second: 87, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.810 [0.000, 28.070], loss: --, mean_squared_error: --, mean_q: --\n",
      "  903/6000: episode: 580, duration: 0.009s, episode steps: 1, steps per second: 110, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.182 [0.000, 29.870], loss: --, mean_squared_error: --, mean_q: --\n",
      "  904/6000: episode: 581, duration: 0.010s, episode steps: 1, steps per second: 105, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.210 [0.000, 25.200], loss: --, mean_squared_error: --, mean_q: --\n",
      "  905/6000: episode: 582, duration: 0.011s, episode steps: 1, steps per second: 90, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.358 [0.000, 18.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  906/6000: episode: 583, duration: 0.012s, episode steps: 1, steps per second: 84, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.320 [0.000, 30.590], loss: --, mean_squared_error: --, mean_q: --\n",
      "  908/6000: episode: 584, duration: 0.014s, episode steps: 2, steps per second: 138, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.276 [0.000, 15.724], loss: --, mean_squared_error: --, mean_q: --\n",
      "  909/6000: episode: 585, duration: 0.010s, episode steps: 1, steps per second: 104, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.582 [0.000, 32.820], loss: --, mean_squared_error: --, mean_q: --\n",
      "  916/6000: episode: 586, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 0.429 [0.000, 3.000], mean observation: 1.224 [0.000, 17.428], loss: --, mean_squared_error: --, mean_q: --\n",
      "  918/6000: episode: 587, duration: 0.018s, episode steps: 2, steps per second: 113, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.938 [0.000, 24.300], loss: --, mean_squared_error: --, mean_q: --\n",
      "  919/6000: episode: 588, duration: 0.010s, episode steps: 1, steps per second: 96, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [0.000, 27.540], loss: --, mean_squared_error: --, mean_q: --\n",
      "  920/6000: episode: 589, duration: 0.011s, episode steps: 1, steps per second: 93, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.743 [0.000, 39.670], loss: --, mean_squared_error: --, mean_q: --\n",
      "  921/6000: episode: 590, duration: 0.009s, episode steps: 1, steps per second: 109, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.081 [0.000, 15.775], loss: --, mean_squared_error: --, mean_q: --\n",
      "  922/6000: episode: 591, duration: 0.011s, episode steps: 1, steps per second: 95, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.274 [0.000, 17.530], loss: --, mean_squared_error: --, mean_q: --\n",
      "  923/6000: episode: 592, duration: 0.011s, episode steps: 1, steps per second: 89, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.280 [0.000, 19.147], loss: --, mean_squared_error: --, mean_q: --\n",
      "  924/6000: episode: 593, duration: 0.010s, episode steps: 1, steps per second: 104, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.329 [0.000, 18.340], loss: --, mean_squared_error: --, mean_q: --\n",
      "  925/6000: episode: 594, duration: 0.015s, episode steps: 1, steps per second: 66, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.399 [0.000, 19.140], loss: --, mean_squared_error: --, mean_q: --\n",
      "  926/6000: episode: 595, duration: 0.013s, episode steps: 1, steps per second: 77, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.880 [0.000, 34.580], loss: --, mean_squared_error: --, mean_q: --\n",
      "  927/6000: episode: 596, duration: 0.013s, episode steps: 1, steps per second: 78, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.394 [0.000, 23.520], loss: --, mean_squared_error: --, mean_q: --\n",
      "  928/6000: episode: 597, duration: 0.012s, episode steps: 1, steps per second: 80, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.279 [0.000, 17.570], loss: --, mean_squared_error: --, mean_q: --\n",
      "  929/6000: episode: 598, duration: 0.011s, episode steps: 1, steps per second: 90, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.388 [0.000, 29.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  931/6000: episode: 599, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.103 [0.000, 16.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  932/6000: episode: 600, duration: 0.016s, episode steps: 1, steps per second: 61, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.081 [0.000, 16.242], loss: --, mean_squared_error: --, mean_q: --\n",
      "  933/6000: episode: 601, duration: 0.013s, episode steps: 1, steps per second: 75, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.256 [0.000, 17.910], loss: --, mean_squared_error: --, mean_q: --\n",
      "  934/6000: episode: 602, duration: 0.013s, episode steps: 1, steps per second: 75, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.880 [0.000, 34.580], loss: --, mean_squared_error: --, mean_q: --\n",
      "  935/6000: episode: 603, duration: 0.019s, episode steps: 1, steps per second: 52, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.225 [0.000, 19.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  945/6000: episode: 604, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.100 [1.000, 2.000], mean observation: 1.229 [0.000, 19.668], loss: --, mean_squared_error: --, mean_q: --\n",
      "  946/6000: episode: 605, duration: 0.011s, episode steps: 1, steps per second: 90, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.249 [0.000, 15.979], loss: --, mean_squared_error: --, mean_q: --\n",
      "  947/6000: episode: 606, duration: 0.011s, episode steps: 1, steps per second: 93, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.169 [0.000, 18.241], loss: --, mean_squared_error: --, mean_q: --\n",
      "  948/6000: episode: 607, duration: 0.008s, episode steps: 1, steps per second: 119, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.298 [0.000, 24.180], loss: --, mean_squared_error: --, mean_q: --\n",
      "  949/6000: episode: 608, duration: 0.008s, episode steps: 1, steps per second: 119, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.881 [0.000, 29.020], loss: --, mean_squared_error: --, mean_q: --\n",
      "  950/6000: episode: 609, duration: 0.012s, episode steps: 1, steps per second: 87, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.697 [0.000, 18.732], loss: --, mean_squared_error: --, mean_q: --\n",
      "  952/6000: episode: 610, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.401 [0.000, 19.353], loss: --, mean_squared_error: --, mean_q: --\n",
      "  953/6000: episode: 611, duration: 0.011s, episode steps: 1, steps per second: 88, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.539 [0.000, 31.350], loss: --, mean_squared_error: --, mean_q: --\n",
      "  963/6000: episode: 612, duration: 0.044s, episode steps: 10, steps per second: 228, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.147 [0.000, 20.040], loss: --, mean_squared_error: --, mean_q: --\n",
      "  964/6000: episode: 613, duration: 0.009s, episode steps: 1, steps per second: 115, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.580 [0.000, 35.150], loss: --, mean_squared_error: --, mean_q: --\n",
      "  974/6000: episode: 614, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.100 [0.000, 1.000], mean observation: 1.303 [0.000, 17.517], loss: --, mean_squared_error: --, mean_q: --\n",
      "  975/6000: episode: 615, duration: 0.012s, episode steps: 1, steps per second: 82, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.126 [0.000, 26.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  976/6000: episode: 616, duration: 0.013s, episode steps: 1, steps per second: 74, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.450 [0.000, 29.160], loss: --, mean_squared_error: --, mean_q: --\n",
      "  977/6000: episode: 617, duration: 0.010s, episode steps: 1, steps per second: 97, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [0.000, 30.510], loss: --, mean_squared_error: --, mean_q: --\n",
      "  987/6000: episode: 618, duration: 0.039s, episode steps: 10, steps per second: 260, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.300 [0.000, 2.000], mean observation: 1.421 [0.000, 15.580], loss: --, mean_squared_error: --, mean_q: --\n",
      "  989/6000: episode: 619, duration: 0.018s, episode steps: 2, steps per second: 113, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.564 [0.000, 25.790], loss: --, mean_squared_error: --, mean_q: --\n",
      "  990/6000: episode: 620, duration: 0.009s, episode steps: 1, steps per second: 116, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.143 [0.000, 14.000], loss: --, mean_squared_error: --, mean_q: --\n",
      "  991/6000: episode: 621, duration: 0.010s, episode steps: 1, steps per second: 99, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.379 [0.000, 29.980], loss: --, mean_squared_error: --, mean_q: --\n",
      "  992/6000: episode: 622, duration: 0.008s, episode steps: 1, steps per second: 121, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.858 [0.000, 14.201], loss: --, mean_squared_error: --, mean_q: --\n",
      "  994/6000: episode: 623, duration: 0.011s, episode steps: 2, steps per second: 190, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.973 [0.000, 39.620], loss: --, mean_squared_error: --, mean_q: --\n",
      "  995/6000: episode: 624, duration: 0.010s, episode steps: 1, steps per second: 105, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.675 [0.000, 39.890], loss: --, mean_squared_error: --, mean_q: --\n",
      "  997/6000: episode: 625, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.399 [0.000, 17.946], loss: --, mean_squared_error: --, mean_q: --\n",
      "  998/6000: episode: 626, duration: 0.007s, episode steps: 1, steps per second: 134, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.673 [0.000, 36.430], loss: --, mean_squared_error: --, mean_q: --\n",
      "  999/6000: episode: 627, duration: 0.009s, episode steps: 1, steps per second: 111, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.110 [0.000, 15.470], loss: --, mean_squared_error: --, mean_q: --\n",
      " 1000/6000: episode: 628, duration: 0.007s, episode steps: 1, steps per second: 140, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.606 [0.000, 25.650], loss: --, mean_squared_error: --, mean_q: --\n",
      " 1002/6000: episode: 629, duration: 1.025s, episode steps: 2, steps per second: 2, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.222 [0.000, 20.010], loss: 25.285744, mean_squared_error: 12.663737, mean_q: 0.163858\n",
      " 1004/6000: episode: 630, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 0.957 [0.000, 17.984], loss: 27.370499, mean_squared_error: 13.787287, mean_q: 0.547097\n",
      " 1005/6000: episode: 631, duration: 0.022s, episode steps: 1, steps per second: 45, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.886 [0.000, 39.950], loss: 23.240915, mean_squared_error: 11.975082, mean_q: 1.015334\n",
      " 1015/6000: episode: 632, duration: 0.120s, episode steps: 10, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.512 [0.000, 27.840], loss: 20.311846, mean_squared_error: 12.131052, mean_q: 2.430411\n",
      " 1025/6000: episode: 633, duration: 0.145s, episode steps: 10, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.087 [0.000, 13.623], loss: 14.751961, mean_squared_error: 16.063177, mean_q: 5.048772\n",
      " 1035/6000: episode: 634, duration: 0.156s, episode steps: 10, steps per second: 64, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.499 [0.000, 36.260], loss: 10.450506, mean_squared_error: 23.063099, mean_q: 6.770732\n",
      " 1036/6000: episode: 635, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.130 [0.000, 18.000], loss: 9.078552, mean_squared_error: 26.375120, mean_q: 7.024590\n",
      " 1043/6000: episode: 636, duration: 0.113s, episode steps: 7, steps per second: 62, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 0.143 [0.000, 1.000], mean observation: 1.513 [0.000, 27.610], loss: 9.015075, mean_squared_error: 26.129217, mean_q: 6.734334\n",
      " 1044/6000: episode: 637, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [0.000, 17.998], loss: 8.931616, mean_squared_error: 29.224186, mean_q: 7.326554\n",
      " 1047/6000: episode: 638, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 2.000], mean observation: 1.110 [0.000, 15.470], loss: 8.122108, mean_squared_error: 28.502947, mean_q: 6.683849\n",
      " 1048/6000: episode: 639, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.289 [0.000, 28.660], loss: 7.981764, mean_squared_error: 29.457443, mean_q: 6.699355\n",
      " 1049/6000: episode: 640, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.292 [0.000, 18.000], loss: 7.689253, mean_squared_error: 28.724371, mean_q: 6.682918\n",
      " 1050/6000: episode: 641, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.870 [0.000, 39.410], loss: 8.888833, mean_squared_error: 32.749378, mean_q: 7.121168\n",
      " 1051/6000: episode: 642, duration: 0.023s, episode steps: 1, steps per second: 44, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.648 [0.000, 37.360], loss: 8.088163, mean_squared_error: 28.988928, mean_q: 6.391433\n",
      " 1061/6000: episode: 643, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.700 [0.000, 3.000], mean observation: 1.133 [0.000, 13.960], loss: 6.443163, mean_squared_error: 30.842371, mean_q: 6.904738\n",
      " 1063/6000: episode: 644, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.897 [0.000, 13.097], loss: 5.686568, mean_squared_error: 33.647202, mean_q: 7.175323\n",
      " 1067/6000: episode: 645, duration: 0.057s, episode steps: 4, steps per second: 70, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.750 [2.000, 3.000], mean observation: 1.150 [0.000, 16.364], loss: 5.868496, mean_squared_error: 34.611465, mean_q: 7.190236\n",
      " 1068/6000: episode: 646, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [0.000, 21.850], loss: 5.198358, mean_squared_error: 31.755814, mean_q: 7.287460\n",
      " 1069/6000: episode: 647, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.376 [0.000, 34.060], loss: 5.077554, mean_squared_error: 31.447702, mean_q: 7.198275\n",
      " 1070/6000: episode: 648, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.181 [0.000, 24.920], loss: 4.475157, mean_squared_error: 30.640072, mean_q: 7.076235\n",
      " 1071/6000: episode: 649, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.462 [0.000, 19.080], loss: 4.766104, mean_squared_error: 34.058147, mean_q: 7.493155\n",
      " 1074/6000: episode: 650, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.239 [0.000, 20.450], loss: 5.001315, mean_squared_error: 34.790348, mean_q: 7.485697\n",
      " 1075/6000: episode: 651, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.565 [0.000, 32.420], loss: 4.154574, mean_squared_error: 30.333584, mean_q: 6.961750\n",
      " 1082/6000: episode: 652, duration: 0.101s, episode steps: 7, steps per second: 69, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.504 [0.000, 31.200], loss: 4.599090, mean_squared_error: 32.722630, mean_q: 7.219450\n",
      " 1083/6000: episode: 653, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.353 [0.000, 23.070], loss: 3.933300, mean_squared_error: 36.096024, mean_q: 7.825562\n",
      " 1086/6000: episode: 654, duration: 0.077s, episode steps: 3, steps per second: 39, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.830 [0.000, 34.900], loss: 3.641715, mean_squared_error: 33.139271, mean_q: 7.675222\n",
      " 1096/6000: episode: 655, duration: 0.148s, episode steps: 10, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.466 [0.000, 36.660], loss: 3.755501, mean_squared_error: 37.693142, mean_q: 8.114947\n",
      " 1097/6000: episode: 656, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.470 [0.000, 21.430], loss: 3.451773, mean_squared_error: 35.189644, mean_q: 7.803048\n",
      " 1098/6000: episode: 657, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.629 [0.000, 36.060], loss: 3.385300, mean_squared_error: 34.674355, mean_q: 7.847054\n",
      " 1103/6000: episode: 658, duration: 0.079s, episode steps: 5, steps per second: 64, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [1.000, 2.000], mean observation: 1.477 [0.000, 26.330], loss: 3.224421, mean_squared_error: 37.216675, mean_q: 7.946363\n",
      " 1104/6000: episode: 659, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.712 [0.000, 25.390], loss: 3.496665, mean_squared_error: 41.056335, mean_q: 8.579268\n",
      " 1107/6000: episode: 660, duration: 0.053s, episode steps: 3, steps per second: 56, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 1.010 [0.000, 15.430], loss: 2.828234, mean_squared_error: 38.419338, mean_q: 8.205688\n",
      " 1115/6000: episode: 661, duration: 0.115s, episode steps: 8, steps per second: 70, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.250 [1.000, 3.000], mean observation: 1.379 [0.000, 23.360], loss: 2.566717, mean_squared_error: 38.748032, mean_q: 8.235942\n",
      " 1125/6000: episode: 662, duration: 0.155s, episode steps: 10, steps per second: 64, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 3.000], mean observation: 1.077 [0.000, 18.490], loss: 2.449509, mean_squared_error: 41.812874, mean_q: 8.481814\n",
      " 1129/6000: episode: 663, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [1.000, 3.000], mean observation: 1.194 [0.000, 17.830], loss: 2.823619, mean_squared_error: 41.600449, mean_q: 8.389490\n",
      " 1130/6000: episode: 664, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.351 [0.000, 20.470], loss: 1.284301, mean_squared_error: 45.193436, mean_q: 9.006737\n",
      " 1139/6000: episode: 665, duration: 0.109s, episode steps: 9, steps per second: 82, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.010 [0.000, 15.000], loss: 2.104800, mean_squared_error: 42.220047, mean_q: 8.574018\n",
      " 1140/6000: episode: 666, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.042 [0.000, 18.930], loss: 2.226390, mean_squared_error: 38.791821, mean_q: 8.292410\n",
      " 1141/6000: episode: 667, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.298 [0.000, 17.486], loss: 2.941829, mean_squared_error: 37.964897, mean_q: 8.059669\n",
      " 1147/6000: episode: 668, duration: 0.116s, episode steps: 6, steps per second: 52, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.667 [0.000, 2.000], mean observation: 1.593 [0.000, 22.970], loss: 1.539798, mean_squared_error: 43.005783, mean_q: 8.739987\n",
      " 1149/6000: episode: 669, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.312 [0.000, 16.795], loss: 2.427908, mean_squared_error: 40.483047, mean_q: 8.235460\n",
      " 1159/6000: episode: 670, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.100 [1.000, 2.000], mean observation: 1.144 [0.000, 17.800], loss: 1.659447, mean_squared_error: 45.354145, mean_q: 8.961286\n",
      " 1164/6000: episode: 671, duration: 0.063s, episode steps: 5, steps per second: 79, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [0.000, 3.000], mean observation: 1.630 [0.000, 39.190], loss: 1.437593, mean_squared_error: 48.956490, mean_q: 9.228201\n",
      " 1165/6000: episode: 672, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.842 [0.000, 31.810], loss: 1.394534, mean_squared_error: 47.975533, mean_q: 9.169443\n",
      " 1174/6000: episode: 673, duration: 0.120s, episode steps: 9, steps per second: 75, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 2.333 [0.000, 3.000], mean observation: 1.550 [0.000, 16.880], loss: 1.218427, mean_squared_error: 45.181187, mean_q: 8.919212\n",
      " 1184/6000: episode: 674, duration: 0.147s, episode steps: 10, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 3.000], mean observation: 1.526 [0.000, 38.520], loss: 1.251894, mean_squared_error: 46.015789, mean_q: 8.952623\n",
      " 1188/6000: episode: 675, duration: 0.063s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.750 [1.000, 2.000], mean observation: 0.826 [0.000, 9.910], loss: 1.267834, mean_squared_error: 46.774582, mean_q: 8.989397\n",
      " 1198/6000: episode: 676, duration: 0.129s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.279 [0.000, 17.570], loss: 1.064965, mean_squared_error: 48.997673, mean_q: 9.179885\n",
      " 1208/6000: episode: 677, duration: 0.141s, episode steps: 10, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.100 [1.000, 2.000], mean observation: 1.379 [0.000, 27.510], loss: 1.108433, mean_squared_error: 49.320549, mean_q: 9.153990\n",
      " 1210/6000: episode: 678, duration: 0.040s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.293 [0.000, 26.510], loss: 0.864509, mean_squared_error: 52.502563, mean_q: 9.581727\n",
      " 1220/6000: episode: 679, duration: 0.144s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.160 [0.000, 16.354], loss: 1.445133, mean_squared_error: 47.799507, mean_q: 9.093554\n",
      " 1221/6000: episode: 680, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.265 [0.000, 19.000], loss: 1.827075, mean_squared_error: 51.738064, mean_q: 9.289823\n",
      " 1222/6000: episode: 681, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.784 [0.000, 39.220], loss: 0.358058, mean_squared_error: 53.388210, mean_q: 9.373086\n",
      " 1223/6000: episode: 682, duration: 0.023s, episode steps: 1, steps per second: 43, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.466 [0.000, 31.070], loss: 0.419015, mean_squared_error: 50.245529, mean_q: 9.228727\n",
      " 1225/6000: episode: 683, duration: 0.035s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.423 [0.000, 35.720], loss: 0.711960, mean_squared_error: 52.948887, mean_q: 9.535000\n",
      " 1226/6000: episode: 684, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.383 [0.000, 27.750], loss: 1.668152, mean_squared_error: 50.233059, mean_q: 9.221207\n",
      " 1235/6000: episode: 685, duration: 0.125s, episode steps: 9, steps per second: 72, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 2.222 [0.000, 3.000], mean observation: 1.491 [0.000, 29.020], loss: 0.988633, mean_squared_error: 48.093376, mean_q: 9.062872\n",
      " 1236/6000: episode: 686, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.050 [0.000, 23.970], loss: 0.450810, mean_squared_error: 54.486923, mean_q: 9.655270\n",
      " 1246/6000: episode: 687, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.796 [0.000, 11.840], loss: 1.047189, mean_squared_error: 52.369823, mean_q: 9.412169\n",
      " 1247/6000: episode: 688, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.106 [0.000, 21.370], loss: 0.853378, mean_squared_error: 53.446064, mean_q: 9.287741\n",
      " 1257/6000: episode: 689, duration: 0.135s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 3.000], mean observation: 1.611 [0.000, 34.070], loss: 1.153029, mean_squared_error: 51.597633, mean_q: 9.290294\n",
      " 1258/6000: episode: 690, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.748 [0.000, 35.670], loss: 0.726550, mean_squared_error: 50.753422, mean_q: 9.196100\n",
      " 1260/6000: episode: 691, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.334 [0.000, 32.210], loss: 0.584483, mean_squared_error: 51.249146, mean_q: 9.094281\n",
      " 1262/6000: episode: 692, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.649 [0.000, 26.920], loss: 0.858352, mean_squared_error: 50.819153, mean_q: 9.223434\n",
      " 1264/6000: episode: 693, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.819 [0.000, 38.310], loss: 1.088788, mean_squared_error: 51.158669, mean_q: 9.114239\n",
      " 1265/6000: episode: 694, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.568 [0.000, 38.920], loss: 0.373189, mean_squared_error: 52.768120, mean_q: 9.445961\n",
      " 1266/6000: episode: 695, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.667 [0.000, 35.240], loss: 0.896750, mean_squared_error: 55.022743, mean_q: 9.489883\n",
      " 1267/6000: episode: 696, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.219 [0.000, 18.140], loss: 1.135487, mean_squared_error: 48.733383, mean_q: 8.959517\n",
      " 1268/6000: episode: 697, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.334 [0.000, 14.825], loss: 1.134311, mean_squared_error: 51.625111, mean_q: 9.176830\n",
      " 1273/6000: episode: 698, duration: 0.070s, episode steps: 5, steps per second: 71, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.800 [0.000, 1.000], mean observation: 1.607 [0.000, 24.700], loss: 0.945621, mean_squared_error: 55.070778, mean_q: 9.457151\n",
      " 1274/6000: episode: 699, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.273 [0.000, 31.440], loss: 2.246150, mean_squared_error: 59.763958, mean_q: 9.651301\n",
      " 1275/6000: episode: 700, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.247 [0.000, 27.500], loss: 1.889274, mean_squared_error: 54.118919, mean_q: 9.351536\n",
      " 1285/6000: episode: 701, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.800 [1.000, 3.000], mean observation: 0.998 [0.000, 13.000], loss: 0.783085, mean_squared_error: 55.095909, mean_q: 9.482272\n",
      " 1292/6000: episode: 702, duration: 0.097s, episode steps: 7, steps per second: 72, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.857 [0.000, 3.000], mean observation: 1.010 [0.000, 17.000], loss: 0.951244, mean_squared_error: 54.872139, mean_q: 9.391938\n",
      " 1293/6000: episode: 703, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.959 [0.000, 12.000], loss: 2.166995, mean_squared_error: 62.327095, mean_q: 10.100702\n",
      " 1303/6000: episode: 704, duration: 0.136s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.575 [0.000, 24.480], loss: 1.636780, mean_squared_error: 53.808006, mean_q: 9.354533\n",
      " 1304/6000: episode: 705, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.366 [0.000, 17.478], loss: 1.809339, mean_squared_error: 57.019913, mean_q: 9.501127\n",
      " 1307/6000: episode: 706, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.418 [0.000, 18.409], loss: 1.253255, mean_squared_error: 53.832279, mean_q: 9.309916\n",
      " 1308/6000: episode: 707, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [0.000, 19.763], loss: 1.614810, mean_squared_error: 55.315086, mean_q: 9.519930\n",
      " 1309/6000: episode: 708, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.547 [0.000, 38.720], loss: 0.937018, mean_squared_error: 52.581009, mean_q: 9.240761\n",
      " 1310/6000: episode: 709, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.940 [0.000, 14.886], loss: 3.548876, mean_squared_error: 57.320900, mean_q: 9.509974\n",
      " 1312/6000: episode: 710, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.365 [0.000, 17.728], loss: 1.032459, mean_squared_error: 54.293381, mean_q: 9.419402\n",
      " 1313/6000: episode: 711, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.068 [0.000, 19.890], loss: 0.177867, mean_squared_error: 55.582447, mean_q: 9.463795\n",
      " 1314/6000: episode: 712, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.479 [0.000, 27.100], loss: 2.258824, mean_squared_error: 56.560570, mean_q: 9.465754\n",
      " 1315/6000: episode: 713, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.169 [0.000, 26.270], loss: 1.850497, mean_squared_error: 56.668541, mean_q: 9.564585\n",
      " 1316/6000: episode: 714, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.014 [0.000, 16.140], loss: 0.450566, mean_squared_error: 50.723717, mean_q: 9.238289\n",
      " 1326/6000: episode: 715, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 0.200 [0.000, 2.000], mean observation: 1.035 [0.000, 15.727], loss: 0.806211, mean_squared_error: 57.176178, mean_q: 9.547797\n",
      " 1327/6000: episode: 716, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.452 [0.000, 18.622], loss: 0.214238, mean_squared_error: 55.772606, mean_q: 9.387197\n",
      " 1337/6000: episode: 717, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 1.000], mean observation: 1.257 [0.000, 18.950], loss: 1.429562, mean_squared_error: 55.487488, mean_q: 9.455600\n",
      " 1338/6000: episode: 718, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.025 [0.000, 21.370], loss: 2.637070, mean_squared_error: 58.216709, mean_q: 9.494251\n",
      " 1339/6000: episode: 719, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.294 [0.000, 28.220], loss: 0.213816, mean_squared_error: 57.045227, mean_q: 9.420157\n",
      " 1340/6000: episode: 720, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.623 [0.000, 31.600], loss: 0.363348, mean_squared_error: 52.640808, mean_q: 9.115458\n",
      " 1341/6000: episode: 721, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.659 [0.000, 33.490], loss: 0.367956, mean_squared_error: 56.745819, mean_q: 9.575239\n",
      " 1342/6000: episode: 722, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.873 [0.000, 39.360], loss: 0.850410, mean_squared_error: 60.719738, mean_q: 9.493042\n",
      " 1352/6000: episode: 723, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.700 [1.000, 2.000], mean observation: 1.085 [0.000, 18.000], loss: 1.367530, mean_squared_error: 57.921032, mean_q: 9.507128\n",
      " 1353/6000: episode: 724, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.255 [0.000, 25.060], loss: 0.188672, mean_squared_error: 64.075287, mean_q: 9.988255\n",
      " 1354/6000: episode: 725, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.514 [0.000, 28.410], loss: 2.688161, mean_squared_error: 60.153767, mean_q: 9.756311\n",
      " 1359/6000: episode: 726, duration: 0.081s, episode steps: 5, steps per second: 62, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.200 [0.000, 1.000], mean observation: 1.378 [0.000, 32.930], loss: 1.205723, mean_squared_error: 56.353680, mean_q: 9.419847\n",
      " 1366/6000: episode: 727, duration: 0.100s, episode steps: 7, steps per second: 70, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.571 [0.000, 3.000], mean observation: 1.369 [0.000, 18.000], loss: 1.530277, mean_squared_error: 57.992165, mean_q: 9.525551\n",
      " 1367/6000: episode: 728, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.649 [0.000, 30.480], loss: 1.035135, mean_squared_error: 58.544720, mean_q: 9.664473\n",
      " 1377/6000: episode: 729, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.093 [0.000, 14.970], loss: 1.568769, mean_squared_error: 58.858814, mean_q: 9.595993\n",
      " 1387/6000: episode: 730, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.600 [0.000, 2.000], mean observation: 0.952 [0.000, 17.285], loss: 1.753320, mean_squared_error: 58.182903, mean_q: 9.500008\n",
      " 1392/6000: episode: 731, duration: 0.071s, episode steps: 5, steps per second: 70, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.800 [0.000, 3.000], mean observation: 1.335 [0.000, 19.000], loss: 1.065319, mean_squared_error: 58.327393, mean_q: 9.447313\n",
      " 1400/6000: episode: 732, duration: 0.113s, episode steps: 8, steps per second: 71, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.625 [0.000, 3.000], mean observation: 1.712 [0.000, 21.540], loss: 0.940567, mean_squared_error: 61.250565, mean_q: 9.689423\n",
      " 1402/6000: episode: 733, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.221 [0.000, 18.643], loss: 1.616264, mean_squared_error: 60.258789, mean_q: 9.524824\n",
      " 1403/6000: episode: 734, duration: 0.021s, episode steps: 1, steps per second: 49, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.895 [0.000, 35.090], loss: 0.337029, mean_squared_error: 59.191833, mean_q: 9.516540\n",
      " 1405/6000: episode: 735, duration: 0.033s, episode steps: 2, steps per second: 61, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.732 [0.000, 31.220], loss: 3.142416, mean_squared_error: 61.902794, mean_q: 9.615284\n",
      " 1415/6000: episode: 736, duration: 0.146s, episode steps: 10, steps per second: 68, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.700 [1.000, 3.000], mean observation: 1.081 [0.000, 15.775], loss: 0.725600, mean_squared_error: 61.220722, mean_q: 9.748461\n",
      " 1416/6000: episode: 737, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.335 [0.000, 24.000], loss: 2.316758, mean_squared_error: 64.089111, mean_q: 9.731226\n",
      " 1424/6000: episode: 738, duration: 0.109s, episode steps: 8, steps per second: 73, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.500 [0.000, 3.000], mean observation: 1.208 [0.000, 16.000], loss: 0.766523, mean_squared_error: 61.588226, mean_q: 9.691047\n",
      " 1425/6000: episode: 739, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.742 [0.000, 30.110], loss: 0.189637, mean_squared_error: 61.952095, mean_q: 9.698984\n",
      " 1435/6000: episode: 740, duration: 0.137s, episode steps: 10, steps per second: 73, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.100 [1.000, 2.000], mean observation: 1.322 [0.000, 16.670], loss: 1.006845, mean_squared_error: 62.400074, mean_q: 9.672106\n",
      " 1436/6000: episode: 741, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.347 [0.000, 32.680], loss: 1.135541, mean_squared_error: 62.082935, mean_q: 9.570619\n",
      " 1439/6000: episode: 742, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [1.000, 2.000], mean observation: 1.105 [0.000, 20.170], loss: 1.453388, mean_squared_error: 61.852726, mean_q: 9.638803\n",
      " 1440/6000: episode: 743, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.473 [0.000, 26.370], loss: 2.334509, mean_squared_error: 61.596359, mean_q: 9.671256\n",
      " 1441/6000: episode: 744, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.311 [0.000, 27.540], loss: 1.457221, mean_squared_error: 59.430244, mean_q: 9.358802\n",
      " 1442/6000: episode: 745, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.030 [0.000, 19.276], loss: 1.297104, mean_squared_error: 61.150711, mean_q: 9.657724\n",
      " 1443/6000: episode: 746, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.498 [0.000, 33.570], loss: 0.963064, mean_squared_error: 62.423870, mean_q: 9.788584\n",
      " 1448/6000: episode: 747, duration: 0.079s, episode steps: 5, steps per second: 63, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.400 [0.000, 3.000], mean observation: 1.733 [0.000, 19.280], loss: 1.627115, mean_squared_error: 62.988441, mean_q: 9.703491\n",
      " 1449/6000: episode: 748, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.709 [0.000, 31.310], loss: 1.273277, mean_squared_error: 60.445019, mean_q: 9.705196\n",
      " 1455/6000: episode: 749, duration: 0.084s, episode steps: 6, steps per second: 71, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.500 [0.000, 3.000], mean observation: 1.326 [0.000, 18.864], loss: 1.050361, mean_squared_error: 63.614044, mean_q: 9.818308\n",
      " 1465/6000: episode: 750, duration: 0.138s, episode steps: 10, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [0.000, 3.000], mean observation: 0.950 [0.000, 14.136], loss: 1.284440, mean_squared_error: 60.336418, mean_q: 9.554514\n",
      " 1467/6000: episode: 751, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.261 [0.000, 25.450], loss: 0.296001, mean_squared_error: 62.824245, mean_q: 9.752634\n",
      " 1468/6000: episode: 752, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.339 [0.000, 27.200], loss: 1.481641, mean_squared_error: 64.143349, mean_q: 9.955091\n",
      " 1469/6000: episode: 753, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.611 [0.000, 28.010], loss: 2.658539, mean_squared_error: 67.551971, mean_q: 9.950182\n",
      " 1473/6000: episode: 754, duration: 0.062s, episode steps: 4, steps per second: 65, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.250 [0.000, 1.000], mean observation: 1.189 [0.000, 23.220], loss: 2.690224, mean_squared_error: 58.397343, mean_q: 9.337654\n",
      " 1474/6000: episode: 755, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.105 [0.000, 20.170], loss: 1.739206, mean_squared_error: 59.411163, mean_q: 9.582375\n",
      " 1477/6000: episode: 756, duration: 0.056s, episode steps: 3, steps per second: 53, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [2.000, 3.000], mean observation: 1.108 [0.000, 14.000], loss: 1.254033, mean_squared_error: 60.724598, mean_q: 9.682293\n",
      " 1478/6000: episode: 757, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.257 [0.000, 26.000], loss: 1.357192, mean_squared_error: 65.195023, mean_q: 9.903608\n",
      " 1484/6000: episode: 758, duration: 0.091s, episode steps: 6, steps per second: 66, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.500 [0.000, 3.000], mean observation: 1.593 [0.000, 22.970], loss: 1.097656, mean_squared_error: 62.375744, mean_q: 9.742517\n",
      " 1485/6000: episode: 759, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.117 [0.000, 22.090], loss: 0.305323, mean_squared_error: 56.873878, mean_q: 9.231142\n",
      " 1495/6000: episode: 760, duration: 0.136s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.300 [0.000, 2.000], mean observation: 1.354 [0.000, 18.000], loss: 1.684366, mean_squared_error: 62.150013, mean_q: 9.690020\n",
      " 1496/6000: episode: 761, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.092 [0.000, 18.505], loss: 0.157823, mean_squared_error: 62.322617, mean_q: 9.630449\n",
      " 1497/6000: episode: 762, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.657 [0.000, 37.940], loss: 0.153282, mean_squared_error: 66.649597, mean_q: 9.986526\n",
      " 1498/6000: episode: 763, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.761 [0.000, 33.350], loss: 2.049994, mean_squared_error: 59.766022, mean_q: 9.617761\n",
      " 1499/6000: episode: 764, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.377 [0.000, 25.290], loss: 2.614272, mean_squared_error: 63.327919, mean_q: 9.554775\n",
      " 1500/6000: episode: 765, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.117 [0.000, 17.960], loss: 2.516914, mean_squared_error: 64.833336, mean_q: 9.847904\n",
      " 1501/6000: episode: 766, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.623 [0.000, 33.120], loss: 2.612655, mean_squared_error: 62.858494, mean_q: 9.702110\n",
      " 1506/6000: episode: 767, duration: 0.071s, episode steps: 5, steps per second: 70, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.200 [2.000, 3.000], mean observation: 1.542 [0.000, 20.810], loss: 0.830604, mean_squared_error: 64.141815, mean_q: 9.874809\n",
      " 1507/6000: episode: 768, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.441 [0.000, 18.619], loss: 0.329055, mean_squared_error: 59.972694, mean_q: 9.504028\n",
      " 1517/6000: episode: 769, duration: 0.136s, episode steps: 10, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.100 [2.000, 3.000], mean observation: 1.432 [0.000, 29.460], loss: 0.380123, mean_squared_error: 63.999046, mean_q: 9.795753\n",
      " 1524/6000: episode: 770, duration: 0.094s, episode steps: 7, steps per second: 74, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.893 [0.000, 37.240], loss: 1.615876, mean_squared_error: 62.359524, mean_q: 9.644185\n",
      " 1525/6000: episode: 771, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.003 [0.000, 14.000], loss: 0.341776, mean_squared_error: 60.645630, mean_q: 9.532462\n",
      " 1535/6000: episode: 772, duration: 0.145s, episode steps: 10, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.800 [1.000, 2.000], mean observation: 1.645 [0.000, 33.200], loss: 1.697796, mean_squared_error: 62.058197, mean_q: 9.622434\n",
      " 1536/6000: episode: 773, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.309 [0.000, 17.250], loss: 1.090728, mean_squared_error: 64.852570, mean_q: 9.770847\n",
      " 1546/6000: episode: 774, duration: 0.142s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.544 [0.000, 22.900], loss: 0.616730, mean_squared_error: 65.210716, mean_q: 9.886823\n",
      " 1547/6000: episode: 775, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.297 [0.000, 30.280], loss: 3.242691, mean_squared_error: 60.527546, mean_q: 9.321963\n",
      " 1548/6000: episode: 776, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.629 [0.000, 31.890], loss: 0.299310, mean_squared_error: 61.659393, mean_q: 9.591251\n",
      " 1550/6000: episode: 777, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.176 [0.000, 29.470], loss: 0.785941, mean_squared_error: 66.572357, mean_q: 9.963928\n",
      " 1551/6000: episode: 778, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.179 [0.000, 20.020], loss: 0.142320, mean_squared_error: 58.398563, mean_q: 9.582555\n",
      " 1552/6000: episode: 779, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.653 [0.000, 18.394], loss: 1.315901, mean_squared_error: 63.496597, mean_q: 9.785967\n",
      " 1553/6000: episode: 780, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.991 [0.000, 38.870], loss: 2.225940, mean_squared_error: 62.994354, mean_q: 9.712421\n",
      " 1555/6000: episode: 781, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.608 [0.000, 32.950], loss: 1.842654, mean_squared_error: 59.801575, mean_q: 9.432863\n",
      " 1564/6000: episode: 782, duration: 0.122s, episode steps: 9, steps per second: 74, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.889 [0.000, 1.000], mean observation: 0.975 [0.000, 24.430], loss: 1.251789, mean_squared_error: 64.194756, mean_q: 9.746754\n",
      " 1572/6000: episode: 783, duration: 0.109s, episode steps: 8, steps per second: 73, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.375 [0.000, 3.000], mean observation: 1.630 [0.000, 33.880], loss: 1.685296, mean_squared_error: 62.932411, mean_q: 9.641058\n",
      " 1574/6000: episode: 784, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.209 [0.000, 18.850], loss: 1.044020, mean_squared_error: 65.308289, mean_q: 9.839500\n",
      " 1575/6000: episode: 785, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.228 [0.000, 19.998], loss: 0.953341, mean_squared_error: 64.698326, mean_q: 9.766787\n",
      " 1576/6000: episode: 786, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.287 [0.000, 16.154], loss: 3.835861, mean_squared_error: 67.490341, mean_q: 9.852034\n",
      " 1577/6000: episode: 787, duration: 0.033s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.429 [0.000, 23.270], loss: 3.758980, mean_squared_error: 65.411011, mean_q: 9.870752\n",
      " 1580/6000: episode: 788, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.111 [0.000, 19.263], loss: 1.698819, mean_squared_error: 62.291363, mean_q: 9.707601\n",
      " 1581/6000: episode: 789, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.356 [0.000, 19.842], loss: 1.288854, mean_squared_error: 60.832386, mean_q: 9.535742\n",
      " 1584/6000: episode: 790, duration: 0.053s, episode steps: 3, steps per second: 57, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.255 [0.000, 25.060], loss: 0.161956, mean_squared_error: 65.141136, mean_q: 9.935267\n",
      " 1594/6000: episode: 791, duration: 0.131s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.800 [0.000, 3.000], mean observation: 1.194 [0.000, 19.210], loss: 1.328076, mean_squared_error: 64.195457, mean_q: 9.747617\n",
      " 1602/6000: episode: 792, duration: 0.105s, episode steps: 8, steps per second: 76, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.875 [0.000, 1.000], mean observation: 0.953 [0.000, 22.190], loss: 0.533379, mean_squared_error: 65.841049, mean_q: 9.885859\n",
      " 1604/6000: episode: 793, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.304 [0.000, 17.000], loss: 0.853219, mean_squared_error: 65.144630, mean_q: 9.779985\n",
      " 1605/6000: episode: 794, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.902 [0.000, 33.320], loss: 0.934721, mean_squared_error: 67.321602, mean_q: 10.058713\n",
      " 1606/6000: episode: 795, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.665 [0.000, 28.940], loss: 1.397541, mean_squared_error: 62.176094, mean_q: 9.538658\n",
      " 1609/6000: episode: 796, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [1.000, 3.000], mean observation: 0.790 [0.000, 11.319], loss: 2.061677, mean_squared_error: 62.235630, mean_q: 9.589961\n",
      " 1614/6000: episode: 797, duration: 0.092s, episode steps: 5, steps per second: 54, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.800 [0.000, 3.000], mean observation: 0.679 [0.000, 11.009], loss: 1.585351, mean_squared_error: 64.911148, mean_q: 9.767171\n",
      " 1615/6000: episode: 798, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.234 [0.000, 18.379], loss: 4.989664, mean_squared_error: 61.992489, mean_q: 9.439363\n",
      " 1616/6000: episode: 799, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.324 [0.000, 22.600], loss: 1.360980, mean_squared_error: 60.752182, mean_q: 9.689746\n",
      " 1617/6000: episode: 800, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.353 [0.000, 19.985], loss: 0.220051, mean_squared_error: 60.804256, mean_q: 9.535246\n",
      " 1618/6000: episode: 801, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.935 [0.000, 35.940], loss: 0.186477, mean_squared_error: 61.395836, mean_q: 9.604259\n",
      " 1619/6000: episode: 802, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.201 [0.000, 17.003], loss: 1.833436, mean_squared_error: 67.155090, mean_q: 9.848150\n",
      " 1620/6000: episode: 803, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.319 [0.000, 18.108], loss: 0.146477, mean_squared_error: 62.041683, mean_q: 9.977875\n",
      " 1623/6000: episode: 804, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 0.877 [0.000, 14.000], loss: 0.374037, mean_squared_error: 64.395325, mean_q: 9.766145\n",
      " 1624/6000: episode: 805, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.180 [0.000, 14.961], loss: 2.418372, mean_squared_error: 62.514797, mean_q: 9.437363\n",
      " 1627/6000: episode: 806, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [0.000, 3.000], mean observation: 1.182 [0.000, 18.240], loss: 1.635253, mean_squared_error: 62.960693, mean_q: 9.623929\n",
      " 1631/6000: episode: 807, duration: 0.062s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 2.000], mean observation: 1.332 [0.000, 20.840], loss: 0.864054, mean_squared_error: 61.883938, mean_q: 9.617996\n",
      " 1632/6000: episode: 808, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.531 [0.000, 35.570], loss: 0.112305, mean_squared_error: 61.740494, mean_q: 9.534620\n",
      " 1633/6000: episode: 809, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.761 [0.000, 33.350], loss: 3.012582, mean_squared_error: 68.985458, mean_q: 9.999603\n",
      " 1636/6000: episode: 810, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [1.000, 2.000], mean observation: 1.081 [0.000, 19.627], loss: 1.312975, mean_squared_error: 61.861038, mean_q: 9.713696\n",
      " 1637/6000: episode: 811, duration: 0.023s, episode steps: 1, steps per second: 43, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.130 [0.000, 17.187], loss: 0.821802, mean_squared_error: 62.332825, mean_q: 10.026010\n",
      " 1638/6000: episode: 812, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.004 [0.000, 14.280], loss: 4.063627, mean_squared_error: 62.021988, mean_q: 9.340290\n",
      " 1639/6000: episode: 813, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.372 [0.000, 19.718], loss: 3.311085, mean_squared_error: 63.891678, mean_q: 9.614402\n",
      " 1640/6000: episode: 814, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.299 [0.000, 18.846], loss: 2.088255, mean_squared_error: 63.544067, mean_q: 9.884017\n",
      " 1642/6000: episode: 815, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.193 [0.000, 17.000], loss: 1.251840, mean_squared_error: 66.740761, mean_q: 9.968975\n",
      " 1652/6000: episode: 816, duration: 0.142s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.800 [0.000, 2.000], mean observation: 1.028 [0.000, 13.000], loss: 1.077821, mean_squared_error: 61.412788, mean_q: 9.698983\n",
      " 1653/6000: episode: 817, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.145 [0.000, 24.970], loss: 0.231215, mean_squared_error: 59.058392, mean_q: 9.265505\n",
      " 1663/6000: episode: 818, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.128 [0.000, 27.010], loss: 1.585250, mean_squared_error: 63.038094, mean_q: 9.621162\n",
      " 1664/6000: episode: 819, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.336 [0.000, 21.520], loss: 2.645745, mean_squared_error: 57.746220, mean_q: 9.309722\n",
      " 1665/6000: episode: 820, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.074 [0.000, 17.355], loss: 1.524169, mean_squared_error: 65.958694, mean_q: 9.862219\n",
      " 1666/6000: episode: 821, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.379 [0.000, 29.650], loss: 0.263009, mean_squared_error: 59.821732, mean_q: 9.527261\n",
      " 1667/6000: episode: 822, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.005 [0.000, 16.000], loss: 0.156838, mean_squared_error: 59.145679, mean_q: 9.516664\n",
      " 1671/6000: episode: 823, duration: 0.058s, episode steps: 4, steps per second: 69, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 2.000], mean observation: 1.993 [0.000, 36.430], loss: 0.771031, mean_squared_error: 64.100006, mean_q: 9.779920\n",
      " 1672/6000: episode: 824, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.774 [0.000, 10.745], loss: 0.778105, mean_squared_error: 68.987000, mean_q: 9.974937\n",
      " 1673/6000: episode: 825, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.412 [0.000, 19.000], loss: 1.048346, mean_squared_error: 67.463486, mean_q: 9.900459\n",
      " 1674/6000: episode: 826, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.904 [0.000, 11.461], loss: 0.202310, mean_squared_error: 63.834187, mean_q: 9.732309\n",
      " 1675/6000: episode: 827, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.674 [0.000, 19.000], loss: 1.353248, mean_squared_error: 63.710373, mean_q: 9.766176\n",
      " 1677/6000: episode: 828, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.432 [0.000, 18.443], loss: 1.263259, mean_squared_error: 64.160812, mean_q: 9.708635\n",
      " 1687/6000: episode: 829, duration: 0.136s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.600 [0.000, 3.000], mean observation: 1.238 [0.000, 17.860], loss: 1.422925, mean_squared_error: 62.453979, mean_q: 9.651359\n",
      " 1688/6000: episode: 830, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.731 [0.000, 31.150], loss: 0.070614, mean_squared_error: 61.970757, mean_q: 9.696319\n",
      " 1689/6000: episode: 831, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.607 [0.000, 30.160], loss: 2.336916, mean_squared_error: 62.707607, mean_q: 9.581310\n",
      " 1690/6000: episode: 832, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.389 [0.000, 39.170], loss: 0.128419, mean_squared_error: 64.465637, mean_q: 9.940577\n",
      " 1691/6000: episode: 833, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.819 [0.000, 35.040], loss: 0.161873, mean_squared_error: 58.588982, mean_q: 9.379040\n",
      " 1692/6000: episode: 834, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.607 [0.000, 39.400], loss: 1.437482, mean_squared_error: 66.765785, mean_q: 9.956196\n",
      " 1693/6000: episode: 835, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.222 [0.000, 28.770], loss: 1.142379, mean_squared_error: 69.519958, mean_q: 10.168965\n",
      " 1694/6000: episode: 836, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.066 [0.000, 17.690], loss: 1.362297, mean_squared_error: 62.113605, mean_q: 9.568873\n",
      " 1695/6000: episode: 837, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.364 [0.000, 37.270], loss: 2.234603, mean_squared_error: 64.712677, mean_q: 9.623652\n",
      " 1696/6000: episode: 838, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.528 [0.000, 18.339], loss: 2.137815, mean_squared_error: 63.265640, mean_q: 9.636801\n",
      " 1697/6000: episode: 839, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.186 [0.000, 34.620], loss: 2.306750, mean_squared_error: 65.988068, mean_q: 10.021646\n",
      " 1698/6000: episode: 840, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.839 [0.000, 32.490], loss: 1.405680, mean_squared_error: 60.230705, mean_q: 9.338326\n",
      " 1699/6000: episode: 841, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.495 [0.000, 36.440], loss: 0.103139, mean_squared_error: 64.984406, mean_q: 9.784977\n",
      " 1701/6000: episode: 842, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 0.982 [0.000, 15.500], loss: 0.777538, mean_squared_error: 66.248764, mean_q: 9.839094\n",
      " 1702/6000: episode: 843, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.475 [0.000, 28.830], loss: 0.142635, mean_squared_error: 64.078339, mean_q: 9.794205\n",
      " 1703/6000: episode: 844, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.417 [0.000, 26.670], loss: 2.605462, mean_squared_error: 64.099960, mean_q: 9.690259\n",
      " 1704/6000: episode: 845, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.656 [0.000, 31.240], loss: 0.983183, mean_squared_error: 67.089424, mean_q: 9.990255\n",
      " 1714/6000: episode: 846, duration: 0.129s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.300 [1.000, 3.000], mean observation: 1.136 [0.000, 19.000], loss: 1.528728, mean_squared_error: 62.464394, mean_q: 9.583509\n",
      " 1715/6000: episode: 847, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.038 [0.000, 14.000], loss: 1.379012, mean_squared_error: 63.935345, mean_q: 9.729807\n",
      " 1722/6000: episode: 848, duration: 0.102s, episode steps: 7, steps per second: 69, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 2.571 [0.000, 3.000], mean observation: 1.696 [0.000, 30.690], loss: 0.835363, mean_squared_error: 63.645222, mean_q: 9.772421\n",
      " 1732/6000: episode: 849, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.800 [0.000, 3.000], mean observation: 1.529 [0.000, 28.090], loss: 1.727980, mean_squared_error: 62.179993, mean_q: 9.668841\n",
      " 1734/6000: episode: 850, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.869 [0.000, 13.450], loss: 1.389296, mean_squared_error: 63.505901, mean_q: 9.774603\n",
      " 1735/6000: episode: 851, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.480 [0.000, 26.180], loss: 2.220224, mean_squared_error: 61.469612, mean_q: 9.675688\n",
      " 1736/6000: episode: 852, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.010 [0.000, 15.000], loss: 1.456599, mean_squared_error: 65.529190, mean_q: 9.781794\n",
      " 1746/6000: episode: 853, duration: 0.135s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.120 [0.000, 19.000], loss: 0.627028, mean_squared_error: 65.928947, mean_q: 9.842290\n",
      " 1747/6000: episode: 854, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.749 [0.000, 11.810], loss: 1.764901, mean_squared_error: 67.753166, mean_q: 9.873953\n",
      " 1748/6000: episode: 855, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.371 [0.000, 37.260], loss: 3.706015, mean_squared_error: 65.233391, mean_q: 9.708597\n",
      " 1749/6000: episode: 856, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.806 [0.000, 15.660], loss: 4.093127, mean_squared_error: 63.957428, mean_q: 9.558330\n",
      " 1758/6000: episode: 857, duration: 0.119s, episode steps: 9, steps per second: 76, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.556 [1.000, 3.000], mean observation: 1.284 [0.000, 16.010], loss: 1.860170, mean_squared_error: 61.652493, mean_q: 9.489032\n",
      " 1760/6000: episode: 858, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.279 [0.000, 19.078], loss: 1.954811, mean_squared_error: 63.026833, mean_q: 9.687858\n",
      " 1770/6000: episode: 859, duration: 0.128s, episode steps: 10, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.100 [2.000, 3.000], mean observation: 1.284 [0.000, 21.860], loss: 0.929355, mean_squared_error: 64.245949, mean_q: 9.775622\n",
      " 1772/6000: episode: 860, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.280 [0.000, 19.147], loss: 0.129895, mean_squared_error: 66.627136, mean_q: 9.907125\n",
      " 1773/6000: episode: 861, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.445 [0.000, 18.870], loss: 0.185001, mean_squared_error: 63.936855, mean_q: 9.832866\n",
      " 1783/6000: episode: 862, duration: 0.131s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.502 [0.000, 35.700], loss: 0.595648, mean_squared_error: 64.393745, mean_q: 9.766764\n",
      " 1784/6000: episode: 863, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.722 [0.000, 38.510], loss: 1.042081, mean_squared_error: 68.333344, mean_q: 10.006567\n",
      " 1788/6000: episode: 864, duration: 0.070s, episode steps: 4, steps per second: 57, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [2.000, 3.000], mean observation: 1.470 [0.000, 19.010], loss: 0.981018, mean_squared_error: 63.971161, mean_q: 9.754443\n",
      " 1789/6000: episode: 865, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.992 [0.000, 17.998], loss: 0.169499, mean_squared_error: 62.618156, mean_q: 9.650785\n",
      " 1799/6000: episode: 866, duration: 0.139s, episode steps: 10, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.800 [0.000, 1.000], mean observation: 1.497 [0.000, 24.540], loss: 1.434913, mean_squared_error: 63.496601, mean_q: 9.663839\n",
      " 1800/6000: episode: 867, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.490 [0.000, 36.060], loss: 2.432011, mean_squared_error: 64.953140, mean_q: 9.782142\n",
      " 1801/6000: episode: 868, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.398 [0.000, 18.757], loss: 0.173965, mean_squared_error: 56.241676, mean_q: 9.375030\n",
      " 1803/6000: episode: 869, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.286 [0.000, 29.770], loss: 3.054516, mean_squared_error: 60.948578, mean_q: 9.514227\n",
      " 1807/6000: episode: 870, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.000 [0.000, 3.000], mean observation: 1.543 [0.000, 19.630], loss: 0.773321, mean_squared_error: 63.083817, mean_q: 9.712145\n",
      " 1808/6000: episode: 871, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.394 [0.000, 35.560], loss: 1.536746, mean_squared_error: 62.047920, mean_q: 9.596420\n",
      " 1809/6000: episode: 872, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.931 [0.000, 13.000], loss: 0.066973, mean_squared_error: 68.282455, mean_q: 9.981462\n",
      " 1810/6000: episode: 873, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.896 [0.000, 38.780], loss: 0.183307, mean_squared_error: 59.958614, mean_q: 9.446161\n",
      " 1811/6000: episode: 874, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.793 [0.000, 11.697], loss: 0.106180, mean_squared_error: 61.101772, mean_q: 9.630100\n",
      " 1812/6000: episode: 875, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.883 [0.000, 15.210], loss: 0.893829, mean_squared_error: 63.263577, mean_q: 9.758388\n",
      " 1814/6000: episode: 876, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.489 [0.000, 35.290], loss: 1.283098, mean_squared_error: 62.881470, mean_q: 9.597134\n",
      " 1816/6000: episode: 877, duration: 0.040s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.533 [0.000, 31.620], loss: 0.710530, mean_squared_error: 66.893112, mean_q: 9.893365\n",
      " 1817/6000: episode: 878, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.570 [0.000, 29.630], loss: 0.076283, mean_squared_error: 65.555679, mean_q: 10.054192\n",
      " 1818/6000: episode: 879, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.118 [0.000, 22.160], loss: 1.499183, mean_squared_error: 64.709534, mean_q: 9.738451\n",
      " 1819/6000: episode: 880, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.058 [0.000, 13.460], loss: 2.657156, mean_squared_error: 67.626419, mean_q: 9.968546\n",
      " 1820/6000: episode: 881, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.639 [0.000, 32.070], loss: 1.321885, mean_squared_error: 68.462669, mean_q: 9.947827\n",
      " 1824/6000: episode: 882, duration: 0.058s, episode steps: 4, steps per second: 69, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 2.000], mean observation: 1.261 [0.000, 26.490], loss: 1.816368, mean_squared_error: 60.039631, mean_q: 9.414853\n",
      " 1825/6000: episode: 883, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.526 [0.000, 30.290], loss: 1.028396, mean_squared_error: 65.452469, mean_q: 9.831450\n",
      " 1835/6000: episode: 884, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.396 [0.000, 18.036], loss: 1.954058, mean_squared_error: 61.382984, mean_q: 9.540524\n",
      " 1836/6000: episode: 885, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.454 [0.000, 31.850], loss: 2.509465, mean_squared_error: 63.079815, mean_q: 9.671768\n",
      " 1838/6000: episode: 886, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.066 [0.000, 17.690], loss: 1.142992, mean_squared_error: 59.908730, mean_q: 9.429560\n",
      " 1848/6000: episode: 887, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.500 [1.000, 3.000], mean observation: 1.722 [0.000, 31.540], loss: 1.224932, mean_squared_error: 64.355751, mean_q: 9.714407\n",
      " 1849/6000: episode: 888, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.003 [0.000, 14.000], loss: 1.309168, mean_squared_error: 62.209129, mean_q: 9.567408\n",
      " 1850/6000: episode: 889, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.385 [0.000, 20.470], loss: 1.246808, mean_squared_error: 64.256340, mean_q: 9.793083\n",
      " 1851/6000: episode: 890, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.130 [0.000, 18.000], loss: 1.046152, mean_squared_error: 59.892406, mean_q: 9.397755\n",
      " 1857/6000: episode: 891, duration: 0.082s, episode steps: 6, steps per second: 73, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.833 [0.000, 3.000], mean observation: 1.799 [0.000, 29.440], loss: 1.289483, mean_squared_error: 63.569386, mean_q: 9.694669\n",
      " 1860/6000: episode: 892, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [0.000, 3.000], mean observation: 1.420 [0.000, 25.930], loss: 1.888347, mean_squared_error: 61.609787, mean_q: 9.505084\n",
      " 1862/6000: episode: 893, duration: 0.047s, episode steps: 2, steps per second: 42, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 0.822 [0.000, 12.034], loss: 1.617928, mean_squared_error: 57.524166, mean_q: 9.325518\n",
      " 1863/6000: episode: 894, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.264 [0.000, 32.060], loss: 3.855009, mean_squared_error: 64.607384, mean_q: 9.699561\n",
      " 1873/6000: episode: 895, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.085 [0.000, 18.146], loss: 1.479045, mean_squared_error: 62.775459, mean_q: 9.702481\n",
      " 1879/6000: episode: 896, duration: 0.079s, episode steps: 6, steps per second: 76, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.167 [0.000, 3.000], mean observation: 1.430 [0.000, 18.387], loss: 2.598260, mean_squared_error: 60.430965, mean_q: 9.416470\n",
      " 1880/6000: episode: 897, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.081 [0.000, 16.879], loss: 0.301886, mean_squared_error: 60.130383, mean_q: 9.586434\n",
      " 1881/6000: episode: 898, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.060 [0.000, 13.833], loss: 1.186450, mean_squared_error: 59.659088, mean_q: 9.477394\n",
      " 1882/6000: episode: 899, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [0.000, 20.960], loss: 2.639987, mean_squared_error: 64.179642, mean_q: 9.703110\n",
      " 1892/6000: episode: 900, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.600 [0.000, 3.000], mean observation: 1.549 [0.000, 21.150], loss: 1.847921, mean_squared_error: 62.264271, mean_q: 9.626628\n",
      " 1900/6000: episode: 901, duration: 0.103s, episode steps: 8, steps per second: 78, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.125 [0.000, 2.000], mean observation: 1.375 [0.000, 18.345], loss: 1.168584, mean_squared_error: 64.003616, mean_q: 9.773799\n",
      " 1910/6000: episode: 902, duration: 0.136s, episode steps: 10, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 3.000], mean observation: 1.379 [0.000, 27.510], loss: 1.353158, mean_squared_error: 61.479088, mean_q: 9.611679\n",
      " 1911/6000: episode: 903, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.546 [0.000, 28.980], loss: 1.709159, mean_squared_error: 63.544632, mean_q: 9.655886\n",
      " 1912/6000: episode: 904, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.159 [0.000, 23.810], loss: 1.428573, mean_squared_error: 62.045105, mean_q: 9.531384\n",
      " 1913/6000: episode: 905, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.617 [0.000, 22.290], loss: 0.184358, mean_squared_error: 60.177109, mean_q: 9.489690\n",
      " 1915/6000: episode: 906, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.120 [0.000, 19.381], loss: 1.459418, mean_squared_error: 65.031494, mean_q: 9.818676\n",
      " 1916/6000: episode: 907, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.064 [0.000, 18.000], loss: 3.624203, mean_squared_error: 64.686356, mean_q: 9.770509\n",
      " 1917/6000: episode: 908, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.965 [0.000, 38.290], loss: 1.208193, mean_squared_error: 65.286194, mean_q: 9.774689\n",
      " 1918/6000: episode: 909, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.156 [0.000, 16.700], loss: 2.529736, mean_squared_error: 60.158218, mean_q: 9.374932\n",
      " 1922/6000: episode: 910, duration: 0.059s, episode steps: 4, steps per second: 68, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [0.000, 3.000], mean observation: 1.286 [0.000, 16.919], loss: 2.822643, mean_squared_error: 59.715164, mean_q: 9.456210\n",
      " 1924/6000: episode: 911, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.265 [0.000, 19.000], loss: 0.238892, mean_squared_error: 59.001686, mean_q: 9.517848\n",
      " 1925/6000: episode: 912, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.839 [0.000, 32.960], loss: 1.102118, mean_squared_error: 56.962502, mean_q: 9.510721\n",
      " 1927/6000: episode: 913, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.828 [0.000, 34.650], loss: 1.596357, mean_squared_error: 62.275436, mean_q: 9.580458\n",
      " 1928/6000: episode: 914, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.664 [0.000, 9.000], loss: 0.936251, mean_squared_error: 58.939487, mean_q: 9.527352\n",
      " 1929/6000: episode: 915, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.410 [0.000, 19.848], loss: 0.086290, mean_squared_error: 64.467224, mean_q: 9.919079\n",
      " 1931/6000: episode: 916, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.665 [0.000, 36.760], loss: 1.046025, mean_squared_error: 59.613430, mean_q: 9.409662\n",
      " 1932/6000: episode: 917, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.014 [0.000, 17.613], loss: 1.570279, mean_squared_error: 56.927628, mean_q: 9.336391\n",
      " 1936/6000: episode: 918, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.289 [0.000, 17.000], loss: 1.555924, mean_squared_error: 62.124374, mean_q: 9.575460\n",
      " 1937/6000: episode: 919, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.337 [0.000, 18.750], loss: 0.437807, mean_squared_error: 55.636993, mean_q: 9.177566\n",
      " 1938/6000: episode: 920, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.541 [0.000, 28.750], loss: 3.572604, mean_squared_error: 62.973171, mean_q: 9.666944\n",
      " 1939/6000: episode: 921, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.264 [0.000, 19.440], loss: 2.910839, mean_squared_error: 58.392044, mean_q: 9.378168\n",
      " 1940/6000: episode: 922, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.918 [0.000, 15.000], loss: 4.596037, mean_squared_error: 60.446941, mean_q: 9.375456\n",
      " 1943/6000: episode: 923, duration: 0.058s, episode steps: 3, steps per second: 52, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.302 [0.000, 19.904], loss: 0.191209, mean_squared_error: 62.472229, mean_q: 9.700047\n",
      " 1944/6000: episode: 924, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.331 [0.000, 20.500], loss: 0.195453, mean_squared_error: 60.263866, mean_q: 9.478480\n",
      " 1945/6000: episode: 925, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.273 [0.000, 27.800], loss: 1.237593, mean_squared_error: 62.996613, mean_q: 9.752872\n",
      " 1946/6000: episode: 926, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.130 [0.000, 38.340], loss: 3.269759, mean_squared_error: 62.963394, mean_q: 9.574636\n",
      " 1954/6000: episode: 927, duration: 0.106s, episode steps: 8, steps per second: 76, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.875 [0.000, 1.000], mean observation: 1.335 [0.000, 24.000], loss: 0.836837, mean_squared_error: 63.310844, mean_q: 9.727547\n",
      " 1955/6000: episode: 928, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.328 [0.000, 18.290], loss: 1.991138, mean_squared_error: 62.180367, mean_q: 9.679905\n",
      " 1956/6000: episode: 929, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.393 [0.000, 23.300], loss: 1.713482, mean_squared_error: 66.405884, mean_q: 9.961432\n",
      " 1957/6000: episode: 930, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.734 [0.000, 30.230], loss: 3.242652, mean_squared_error: 63.534874, mean_q: 9.862056\n",
      " 1958/6000: episode: 931, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.456 [0.000, 19.000], loss: 3.061065, mean_squared_error: 57.845848, mean_q: 9.494469\n",
      " 1959/6000: episode: 932, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.612 [0.000, 19.232], loss: 0.170719, mean_squared_error: 60.589867, mean_q: 9.690941\n",
      " 1960/6000: episode: 933, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.713 [0.000, 24.500], loss: 0.105281, mean_squared_error: 63.602024, mean_q: 9.823890\n",
      " 1961/6000: episode: 934, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.788 [0.000, 38.320], loss: 1.006670, mean_squared_error: 60.136848, mean_q: 9.473537\n",
      " 1971/6000: episode: 935, duration: 0.126s, episode steps: 10, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.400 [1.000, 2.000], mean observation: 1.154 [0.000, 14.160], loss: 0.984170, mean_squared_error: 61.787647, mean_q: 9.677173\n",
      " 1972/6000: episode: 936, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.357 [0.000, 35.240], loss: 1.537356, mean_squared_error: 59.866211, mean_q: 9.365995\n",
      " 1974/6000: episode: 937, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.352 [0.000, 33.170], loss: 0.776009, mean_squared_error: 61.911880, mean_q: 9.671549\n",
      " 1975/6000: episode: 938, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.601 [0.000, 19.940], loss: 2.130215, mean_squared_error: 59.349640, mean_q: 9.427945\n",
      " 1976/6000: episode: 939, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.299 [0.000, 18.846], loss: 1.988623, mean_squared_error: 57.165764, mean_q: 9.129253\n",
      " 1977/6000: episode: 940, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.096 [0.000, 23.670], loss: 0.317361, mean_squared_error: 59.176346, mean_q: 9.693489\n",
      " 1987/6000: episode: 941, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.500 [0.000, 3.000], mean observation: 1.442 [0.000, 33.730], loss: 1.419952, mean_squared_error: 59.456612, mean_q: 9.481595\n",
      " 1988/6000: episode: 942, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.346 [0.000, 17.610], loss: 0.092135, mean_squared_error: 61.056591, mean_q: 9.778851\n",
      " 1991/6000: episode: 943, duration: 0.044s, episode steps: 3, steps per second: 69, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.667 [2.000, 3.000], mean observation: 1.124 [0.000, 19.310], loss: 0.539201, mean_squared_error: 60.713161, mean_q: 9.544164\n",
      " 1992/6000: episode: 944, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.786 [0.000, 11.860], loss: 2.575165, mean_squared_error: 55.643654, mean_q: 9.256864\n",
      " 1993/6000: episode: 945, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.347 [0.000, 27.950], loss: 0.125284, mean_squared_error: 63.434830, mean_q: 9.908765\n",
      " 1994/6000: episode: 946, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.495 [0.000, 36.440], loss: 0.927878, mean_squared_error: 56.558479, mean_q: 9.506710\n",
      " 1995/6000: episode: 947, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.318 [0.000, 18.464], loss: 3.415761, mean_squared_error: 58.935936, mean_q: 9.357023\n",
      " 1996/6000: episode: 948, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.298 [0.000, 18.539], loss: 1.595225, mean_squared_error: 58.590260, mean_q: 9.320104\n",
      " 1997/6000: episode: 949, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.654 [0.000, 36.660], loss: 0.099020, mean_squared_error: 62.124931, mean_q: 9.635046\n",
      " 1998/6000: episode: 950, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.407 [0.000, 29.460], loss: 1.943438, mean_squared_error: 59.148483, mean_q: 9.396904\n",
      " 1999/6000: episode: 951, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.961 [0.000, 31.300], loss: 0.950297, mean_squared_error: 54.979851, mean_q: 9.411825\n",
      " 2003/6000: episode: 952, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.072 [0.000, 15.952], loss: 1.433275, mean_squared_error: 58.732735, mean_q: 9.403915\n",
      " 2009/6000: episode: 953, duration: 0.088s, episode steps: 6, steps per second: 68, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 0.167 [0.000, 1.000], mean observation: 1.543 [0.000, 30.500], loss: 1.725481, mean_squared_error: 64.155907, mean_q: 9.776132\n",
      " 2010/6000: episode: 954, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [0.000, 35.590], loss: 0.957806, mean_squared_error: 58.707722, mean_q: 9.320663\n",
      " 2011/6000: episode: 955, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.085 [0.000, 18.000], loss: 1.429590, mean_squared_error: 60.280144, mean_q: 9.538157\n",
      " 2012/6000: episode: 956, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.394 [0.000, 35.560], loss: 2.377404, mean_squared_error: 64.036201, mean_q: 9.722761\n",
      " 2022/6000: episode: 957, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.800 [1.000, 3.000], mean observation: 1.946 [0.000, 35.520], loss: 1.197332, mean_squared_error: 61.193840, mean_q: 9.595644\n",
      " 2026/6000: episode: 958, duration: 0.066s, episode steps: 4, steps per second: 61, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.382 [0.000, 18.810], loss: 0.885353, mean_squared_error: 62.184799, mean_q: 9.689960\n",
      " 2027/6000: episode: 959, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.979 [0.000, 13.455], loss: 2.477181, mean_squared_error: 58.224770, mean_q: 9.335037\n",
      " 2037/6000: episode: 960, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.400 [1.000, 3.000], mean observation: 1.678 [0.000, 27.810], loss: 1.790715, mean_squared_error: 60.936241, mean_q: 9.534350\n",
      " 2038/6000: episode: 961, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.213 [0.000, 24.650], loss: 0.181382, mean_squared_error: 60.702164, mean_q: 9.672976\n",
      " 2045/6000: episode: 962, duration: 0.111s, episode steps: 7, steps per second: 63, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.857 [0.000, 3.000], mean observation: 1.660 [0.000, 30.760], loss: 1.352638, mean_squared_error: 61.717567, mean_q: 9.606849\n",
      " 2046/6000: episode: 963, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.929 [0.000, 19.690], loss: 2.630341, mean_squared_error: 65.927277, mean_q: 9.877876\n",
      " 2047/6000: episode: 964, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.818 [0.000, 33.660], loss: 1.223018, mean_squared_error: 58.493332, mean_q: 9.469643\n",
      " 2056/6000: episode: 965, duration: 0.121s, episode steps: 9, steps per second: 74, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.778 [0.000, 2.000], mean observation: 1.186 [0.000, 19.400], loss: 1.696950, mean_squared_error: 61.493279, mean_q: 9.573303\n",
      " 2057/6000: episode: 966, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.181 [0.000, 17.017], loss: 3.290385, mean_squared_error: 59.394890, mean_q: 9.341335\n",
      " 2062/6000: episode: 967, duration: 0.067s, episode steps: 5, steps per second: 74, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.198 [0.000, 21.230], loss: 1.751386, mean_squared_error: 61.430321, mean_q: 9.511441\n",
      " 2063/6000: episode: 968, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.055 [0.000, 16.854], loss: 1.347075, mean_squared_error: 59.010429, mean_q: 9.414474\n",
      " 2064/6000: episode: 969, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.001 [0.000, 14.396], loss: 0.140270, mean_squared_error: 62.022095, mean_q: 9.598125\n",
      " 2065/6000: episode: 970, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.366 [0.000, 20.560], loss: 1.527340, mean_squared_error: 58.473442, mean_q: 9.409151\n",
      " 2066/6000: episode: 971, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.643 [0.000, 39.250], loss: 0.165743, mean_squared_error: 60.941509, mean_q: 9.665939\n",
      " 2067/6000: episode: 972, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.527 [0.000, 19.096], loss: 0.898055, mean_squared_error: 58.168503, mean_q: 9.594803\n",
      " 2077/6000: episode: 973, duration: 0.118s, episode steps: 10, steps per second: 85, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 2.900 [2.000, 3.000], mean observation: 1.345 [0.000, 21.980], loss: 1.666882, mean_squared_error: 59.899498, mean_q: 9.482037\n",
      " 2078/6000: episode: 974, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.478 [0.000, 33.780], loss: 0.475451, mean_squared_error: 53.382549, mean_q: 9.013817\n",
      " 2084/6000: episode: 975, duration: 0.083s, episode steps: 6, steps per second: 72, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.167 [0.000, 2.000], mean observation: 1.602 [0.000, 37.380], loss: 1.192507, mean_squared_error: 62.780746, mean_q: 9.781348\n",
      " 2086/6000: episode: 976, duration: 0.035s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.721 [0.000, 18.866], loss: 2.490227, mean_squared_error: 61.125088, mean_q: 9.583595\n",
      " 2087/6000: episode: 977, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.855 [0.000, 28.680], loss: 3.741662, mean_squared_error: 57.664345, mean_q: 9.629053\n",
      " 2094/6000: episode: 978, duration: 0.098s, episode steps: 7, steps per second: 72, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.714 [1.000, 3.000], mean observation: 1.081 [0.000, 19.627], loss: 1.474022, mean_squared_error: 59.381641, mean_q: 9.571310\n",
      " 2095/6000: episode: 979, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.023 [0.000, 15.931], loss: 0.128470, mean_squared_error: 62.071106, mean_q: 9.742043\n",
      " 2097/6000: episode: 980, duration: 0.044s, episode steps: 2, steps per second: 45, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 0.906 [0.000, 18.320], loss: 2.514775, mean_squared_error: 54.660515, mean_q: 8.980304\n",
      " 2098/6000: episode: 981, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.175 [0.000, 18.371], loss: 1.015203, mean_squared_error: 62.916431, mean_q: 9.773985\n",
      " 2102/6000: episode: 982, duration: 0.068s, episode steps: 4, steps per second: 59, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [0.000, 3.000], mean observation: 0.889 [0.000, 16.000], loss: 2.504053, mean_squared_error: 62.182652, mean_q: 9.586512\n",
      " 2112/6000: episode: 983, duration: 0.123s, episode steps: 10, steps per second: 81, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.169 [0.000, 18.140], loss: 0.622441, mean_squared_error: 62.809650, mean_q: 9.742460\n",
      " 2113/6000: episode: 984, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.410 [0.000, 22.480], loss: 0.102481, mean_squared_error: 63.891308, mean_q: 9.715868\n",
      " 2114/6000: episode: 985, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.492 [0.000, 28.120], loss: 1.366168, mean_squared_error: 60.448025, mean_q: 9.463287\n",
      " 2116/6000: episode: 986, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.505 [0.000, 23.420], loss: 2.931113, mean_squared_error: 64.060921, mean_q: 9.714091\n",
      " 2125/6000: episode: 987, duration: 0.117s, episode steps: 9, steps per second: 77, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.778 [1.000, 3.000], mean observation: 1.320 [0.000, 20.840], loss: 2.128450, mean_squared_error: 58.850971, mean_q: 9.447683\n",
      " 2126/6000: episode: 988, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.203 [0.000, 17.618], loss: 2.139874, mean_squared_error: 60.585945, mean_q: 9.685884\n",
      " 2129/6000: episode: 989, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.667 [2.000, 3.000], mean observation: 1.177 [0.000, 18.746], loss: 1.403714, mean_squared_error: 60.559948, mean_q: 9.619151\n",
      " 2130/6000: episode: 990, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.966 [0.000, 37.640], loss: 0.139500, mean_squared_error: 60.618584, mean_q: 9.600469\n",
      " 2131/6000: episode: 991, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.174 [0.000, 18.177], loss: 1.859646, mean_squared_error: 64.089272, mean_q: 9.809647\n",
      " 2141/6000: episode: 992, duration: 0.131s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.800 [2.000, 3.000], mean observation: 1.353 [0.000, 18.187], loss: 1.128090, mean_squared_error: 62.357491, mean_q: 9.721684\n",
      " 2145/6000: episode: 993, duration: 0.068s, episode steps: 4, steps per second: 59, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.883 [0.000, 38.280], loss: 1.712587, mean_squared_error: 59.765213, mean_q: 9.564815\n",
      " 2146/6000: episode: 994, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.297 [0.000, 16.300], loss: 1.230697, mean_squared_error: 57.997375, mean_q: 9.241083\n",
      " 2147/6000: episode: 995, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.265 [0.000, 19.000], loss: 0.082774, mean_squared_error: 63.995296, mean_q: 9.808445\n",
      " 2148/6000: episode: 996, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.969 [0.000, 36.870], loss: 0.187052, mean_squared_error: 64.267433, mean_q: 9.916596\n",
      " 2158/6000: episode: 997, duration: 0.138s, episode steps: 10, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.100 [2.000, 3.000], mean observation: 1.951 [0.000, 35.630], loss: 1.547818, mean_squared_error: 61.507774, mean_q: 9.579053\n",
      " 2159/6000: episode: 998, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.594 [0.000, 23.280], loss: 0.169954, mean_squared_error: 60.610050, mean_q: 9.581360\n",
      " 2160/6000: episode: 999, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.465 [0.000, 30.410], loss: 2.890249, mean_squared_error: 62.499191, mean_q: 9.619246\n",
      " 2170/6000: episode: 1000, duration: 0.129s, episode steps: 10, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.454 [0.000, 31.080], loss: 1.885828, mean_squared_error: 58.143959, mean_q: 9.424157\n",
      " 2172/6000: episode: 1001, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.159 [0.000, 19.923], loss: 1.210025, mean_squared_error: 62.029530, mean_q: 9.657391\n",
      " 2182/6000: episode: 1002, duration: 0.129s, episode steps: 10, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.472 [0.000, 22.450], loss: 1.642027, mean_squared_error: 59.541557, mean_q: 9.511962\n",
      " 2183/6000: episode: 1003, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.511 [0.000, 19.446], loss: 2.985417, mean_squared_error: 64.886276, mean_q: 9.846129\n",
      " 2190/6000: episode: 1004, duration: 0.105s, episode steps: 7, steps per second: 67, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 0.857 [0.000, 3.000], mean observation: 1.721 [0.000, 36.090], loss: 1.281980, mean_squared_error: 62.082939, mean_q: 9.700507\n",
      " 2191/6000: episode: 1005, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.555 [0.000, 33.540], loss: 0.080759, mean_squared_error: 66.519058, mean_q: 10.065077\n",
      " 2193/6000: episode: 1006, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.186 [0.000, 16.260], loss: 1.008058, mean_squared_error: 56.676414, mean_q: 9.339837\n",
      " 2194/6000: episode: 1007, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.698 [0.000, 39.610], loss: 0.170177, mean_squared_error: 61.884586, mean_q: 9.789398\n",
      " 2197/6000: episode: 1008, duration: 0.046s, episode steps: 3, steps per second: 66, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.512 [0.000, 27.840], loss: 0.967137, mean_squared_error: 61.328419, mean_q: 9.610169\n",
      " 2198/6000: episode: 1009, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.030 [0.000, 38.550], loss: 0.122667, mean_squared_error: 62.728065, mean_q: 9.825837\n",
      " 2199/6000: episode: 1010, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.653 [0.000, 18.394], loss: 1.222193, mean_squared_error: 60.016022, mean_q: 9.611601\n",
      " 2200/6000: episode: 1011, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.071 [0.000, 23.010], loss: 2.217974, mean_squared_error: 59.619987, mean_q: 9.334810\n",
      " 2202/6000: episode: 1012, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.179 [0.000, 17.139], loss: 1.673946, mean_squared_error: 61.728439, mean_q: 9.711189\n",
      " 2203/6000: episode: 1013, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.803 [0.000, 32.900], loss: 3.195311, mean_squared_error: 59.324059, mean_q: 9.443232\n",
      " 2204/6000: episode: 1014, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.372 [0.000, 20.350], loss: 0.494637, mean_squared_error: 57.204185, mean_q: 9.483230\n",
      " 2205/6000: episode: 1015, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.485 [0.000, 32.710], loss: 1.416341, mean_squared_error: 62.366940, mean_q: 9.733288\n",
      " 2206/6000: episode: 1016, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.377 [0.000, 22.150], loss: 1.168004, mean_squared_error: 61.049915, mean_q: 9.527647\n",
      " 2210/6000: episode: 1017, duration: 0.057s, episode steps: 4, steps per second: 70, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 2.000], mean observation: 1.326 [0.000, 18.134], loss: 2.291177, mean_squared_error: 59.092175, mean_q: 9.471546\n",
      " 2211/6000: episode: 1018, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.474 [0.000, 37.490], loss: 1.504587, mean_squared_error: 64.355408, mean_q: 9.866919\n",
      " 2220/6000: episode: 1019, duration: 0.123s, episode steps: 9, steps per second: 73, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.889 [0.000, 1.000], mean observation: 1.345 [0.000, 32.320], loss: 1.475491, mean_squared_error: 60.725620, mean_q: 9.573362\n",
      " 2221/6000: episode: 1020, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.908 [0.000, 26.990], loss: 0.186622, mean_squared_error: 60.838764, mean_q: 9.595991\n",
      " 2223/6000: episode: 1021, duration: 0.040s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.189 [0.000, 23.220], loss: 0.697158, mean_squared_error: 62.240158, mean_q: 9.709938\n",
      " 2224/6000: episode: 1022, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.781 [0.000, 38.980], loss: 1.609203, mean_squared_error: 60.366962, mean_q: 9.599840\n",
      " 2225/6000: episode: 1023, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.656 [0.000, 27.140], loss: 2.791752, mean_squared_error: 57.741051, mean_q: 9.213695\n",
      " 2235/6000: episode: 1024, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.700 [0.000, 3.000], mean observation: 1.749 [0.000, 35.360], loss: 1.745874, mean_squared_error: 60.366894, mean_q: 9.596445\n",
      " 2245/6000: episode: 1025, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.973 [0.000, 38.590], loss: 1.722492, mean_squared_error: 59.613728, mean_q: 9.512523\n",
      " 2246/6000: episode: 1026, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.869 [0.000, 13.450], loss: 1.335092, mean_squared_error: 60.289112, mean_q: 9.542987\n",
      " 2251/6000: episode: 1027, duration: 0.070s, episode steps: 5, steps per second: 71, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.400 [0.000, 2.000], mean observation: 1.567 [0.000, 34.650], loss: 1.423023, mean_squared_error: 63.334312, mean_q: 9.792764\n",
      " 2252/6000: episode: 1028, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.601 [0.000, 19.940], loss: 2.140684, mean_squared_error: 56.800850, mean_q: 9.272130\n",
      " 2254/6000: episode: 1029, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.479 [0.000, 29.890], loss: 2.800882, mean_squared_error: 59.064713, mean_q: 9.434029\n",
      " 2264/6000: episode: 1030, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.100 [1.000, 2.000], mean observation: 1.116 [0.000, 16.835], loss: 0.937530, mean_squared_error: 59.796185, mean_q: 9.514822\n",
      " 2267/6000: episode: 1031, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 1.695 [0.000, 32.010], loss: 0.615698, mean_squared_error: 63.125275, mean_q: 9.810884\n",
      " 2268/6000: episode: 1032, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.715 [0.000, 31.880], loss: 1.433146, mean_squared_error: 57.073170, mean_q: 9.279867\n",
      " 2270/6000: episode: 1033, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.473 [0.000, 19.000], loss: 1.272660, mean_squared_error: 63.296509, mean_q: 9.767047\n",
      " 2275/6000: episode: 1034, duration: 0.076s, episode steps: 5, steps per second: 65, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.082 [0.000, 19.000], loss: 0.753902, mean_squared_error: 60.765003, mean_q: 9.658175\n",
      " 2276/6000: episode: 1035, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.320 [0.000, 26.510], loss: 0.212870, mean_squared_error: 61.654831, mean_q: 9.589277\n",
      " 2278/6000: episode: 1036, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.640 [0.000, 29.090], loss: 2.699061, mean_squared_error: 59.076939, mean_q: 9.324947\n",
      " 2279/6000: episode: 1037, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.265 [0.000, 19.000], loss: 1.647761, mean_squared_error: 58.973827, mean_q: 9.750776\n",
      " 2281/6000: episode: 1038, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.896 [0.000, 38.780], loss: 1.501578, mean_squared_error: 63.884109, mean_q: 9.836668\n",
      " 2282/6000: episode: 1039, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.882 [0.000, 33.170], loss: 0.172583, mean_squared_error: 61.144577, mean_q: 9.665718\n",
      " 2283/6000: episode: 1040, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.077 [0.000, 17.540], loss: 0.235101, mean_squared_error: 60.539543, mean_q: 9.572969\n",
      " 2284/6000: episode: 1041, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.763 [0.000, 26.010], loss: 2.163814, mean_squared_error: 60.477230, mean_q: 9.600996\n",
      " 2285/6000: episode: 1042, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.976 [0.000, 16.000], loss: 1.199550, mean_squared_error: 63.244747, mean_q: 9.785378\n",
      " 2286/6000: episode: 1043, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.206 [0.000, 19.272], loss: 1.406140, mean_squared_error: 61.888538, mean_q: 9.767198\n",
      " 2287/6000: episode: 1044, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.492 [0.000, 24.590], loss: 2.411189, mean_squared_error: 59.238750, mean_q: 9.375415\n",
      " 2288/6000: episode: 1045, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.201 [0.000, 30.650], loss: 2.922699, mean_squared_error: 62.089588, mean_q: 9.594334\n",
      " 2289/6000: episode: 1046, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.306 [0.000, 35.760], loss: 2.866381, mean_squared_error: 62.317062, mean_q: 9.666979\n",
      " 2290/6000: episode: 1047, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.956 [0.000, 33.920], loss: 4.640076, mean_squared_error: 58.271923, mean_q: 9.321746\n",
      " 2291/6000: episode: 1048, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.931 [0.000, 13.000], loss: 0.272702, mean_squared_error: 57.302700, mean_q: 9.395305\n",
      " 2292/6000: episode: 1049, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.494 [0.000, 35.260], loss: 0.087117, mean_squared_error: 60.349834, mean_q: 9.710422\n",
      " 2296/6000: episode: 1050, duration: 0.063s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.328 [0.000, 17.300], loss: 1.032570, mean_squared_error: 62.305935, mean_q: 9.616564\n",
      " 2301/6000: episode: 1051, duration: 0.073s, episode steps: 5, steps per second: 69, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [0.000, 2.000], mean observation: 1.666 [0.000, 27.490], loss: 1.922990, mean_squared_error: 61.316040, mean_q: 9.539377\n",
      " 2304/6000: episode: 1052, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [0.000, 3.000], mean observation: 1.039 [0.000, 16.069], loss: 1.230291, mean_squared_error: 61.263950, mean_q: 9.647588\n",
      " 2305/6000: episode: 1053, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.224 [0.000, 16.860], loss: 1.147528, mean_squared_error: 59.784138, mean_q: 9.467232\n",
      " 2309/6000: episode: 1054, duration: 0.062s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 1.000], mean observation: 0.869 [0.000, 11.410], loss: 1.886361, mean_squared_error: 60.764908, mean_q: 9.568759\n",
      " 2310/6000: episode: 1055, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.494 [0.000, 35.350], loss: 4.087211, mean_squared_error: 65.235077, mean_q: 9.762871\n",
      " 2311/6000: episode: 1056, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.207 [0.000, 24.450], loss: 1.939671, mean_squared_error: 56.221249, mean_q: 9.256693\n",
      " 2312/6000: episode: 1057, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.287 [0.000, 27.540], loss: 1.086380, mean_squared_error: 55.384609, mean_q: 9.186194\n",
      " 2322/6000: episode: 1058, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.600 [2.000, 3.000], mean observation: 0.830 [0.000, 11.097], loss: 1.053713, mean_squared_error: 61.795357, mean_q: 9.619737\n",
      " 2329/6000: episode: 1059, duration: 0.089s, episode steps: 7, steps per second: 78, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.857 [0.000, 3.000], mean observation: 1.457 [0.000, 21.090], loss: 1.398742, mean_squared_error: 60.390217, mean_q: 9.629888\n",
      " 2333/6000: episode: 1060, duration: 0.062s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 2.000], mean observation: 0.973 [0.000, 10.000], loss: 1.923573, mean_squared_error: 58.918537, mean_q: 9.515853\n",
      " 2341/6000: episode: 1061, duration: 0.128s, episode steps: 8, steps per second: 63, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.875 [0.000, 1.000], mean observation: 1.247 [0.000, 17.970], loss: 1.827381, mean_squared_error: 59.433922, mean_q: 9.490391\n",
      " 2342/6000: episode: 1062, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.751 [0.000, 35.210], loss: 0.914950, mean_squared_error: 58.065510, mean_q: 9.332071\n",
      " 2343/6000: episode: 1063, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.270 [0.000, 18.177], loss: 1.898901, mean_squared_error: 65.990509, mean_q: 9.821190\n",
      " 2344/6000: episode: 1064, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.308 [0.000, 16.080], loss: 4.095481, mean_squared_error: 65.018105, mean_q: 9.723493\n",
      " 2345/6000: episode: 1065, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.346 [0.000, 17.610], loss: 2.308954, mean_squared_error: 57.647968, mean_q: 9.225480\n",
      " 2355/6000: episode: 1066, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 0.700 [0.000, 3.000], mean observation: 1.500 [0.000, 31.750], loss: 1.727666, mean_squared_error: 61.691772, mean_q: 9.721221\n",
      " 2357/6000: episode: 1067, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.282 [0.000, 19.137], loss: 2.450366, mean_squared_error: 59.225281, mean_q: 9.489606\n",
      " 2358/6000: episode: 1068, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.350 [0.000, 31.460], loss: 1.335766, mean_squared_error: 60.428661, mean_q: 9.575716\n",
      " 2360/6000: episode: 1069, duration: 0.042s, episode steps: 2, steps per second: 47, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.926 [0.000, 34.160], loss: 1.195794, mean_squared_error: 62.317177, mean_q: 9.739608\n",
      " 2361/6000: episode: 1070, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.739 [0.000, 34.110], loss: 0.254889, mean_squared_error: 58.936543, mean_q: 9.457514\n",
      " 2363/6000: episode: 1071, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.780 [0.000, 33.460], loss: 2.103345, mean_squared_error: 61.387230, mean_q: 9.645405\n",
      " 2364/6000: episode: 1072, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.283 [0.000, 35.330], loss: 6.192132, mean_squared_error: 59.799847, mean_q: 9.238918\n",
      " 2365/6000: episode: 1073, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.028 [0.000, 19.280], loss: 1.641625, mean_squared_error: 61.410828, mean_q: 9.796795\n",
      " 2366/6000: episode: 1074, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.531 [0.000, 33.660], loss: 1.070244, mean_squared_error: 62.734432, mean_q: 9.809500\n",
      " 2376/6000: episode: 1075, duration: 0.125s, episode steps: 10, steps per second: 80, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 0.400 [0.000, 3.000], mean observation: 1.113 [0.000, 15.878], loss: 1.724921, mean_squared_error: 59.996918, mean_q: 9.559872\n",
      " 2377/6000: episode: 1076, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.636 [0.000, 21.390], loss: 1.082914, mean_squared_error: 52.051407, mean_q: 8.980782\n",
      " 2386/6000: episode: 1077, duration: 0.117s, episode steps: 9, steps per second: 77, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.111 [0.000, 1.000], mean observation: 1.446 [0.000, 21.920], loss: 0.885460, mean_squared_error: 61.623093, mean_q: 9.625601\n",
      " 2387/6000: episode: 1078, duration: 0.033s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.523 [0.000, 29.750], loss: 1.524397, mean_squared_error: 65.732178, mean_q: 9.822527\n",
      " 2389/6000: episode: 1079, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.110 [0.000, 12.864], loss: 3.643422, mean_squared_error: 60.565834, mean_q: 9.461119\n",
      " 2399/6000: episode: 1080, duration: 0.139s, episode steps: 10, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.406 [0.000, 20.390], loss: 1.265371, mean_squared_error: 62.502266, mean_q: 9.667142\n",
      " 2400/6000: episode: 1081, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.341 [0.000, 18.283], loss: 1.520552, mean_squared_error: 59.872280, mean_q: 9.397099\n",
      " 2401/6000: episode: 1082, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.753 [0.000, 12.164], loss: 1.080384, mean_squared_error: 61.116089, mean_q: 9.713252\n",
      " 2402/6000: episode: 1083, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.673 [0.000, 34.800], loss: 0.376326, mean_squared_error: 60.641731, mean_q: 9.537903\n",
      " 2403/6000: episode: 1084, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.726 [0.000, 38.760], loss: 0.781331, mean_squared_error: 61.600338, mean_q: 9.625560\n",
      " 2405/6000: episode: 1085, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.113 [0.000, 15.878], loss: 2.413884, mean_squared_error: 62.409874, mean_q: 9.610781\n",
      " 2406/6000: episode: 1086, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.061 [0.000, 16.330], loss: 1.541572, mean_squared_error: 66.055618, mean_q: 10.078918\n",
      " 2408/6000: episode: 1087, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.233 [0.000, 17.110], loss: 1.959673, mean_squared_error: 58.257244, mean_q: 9.454161\n",
      " 2409/6000: episode: 1088, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.236 [0.000, 20.330], loss: 0.366924, mean_squared_error: 59.535114, mean_q: 9.439955\n",
      " 2410/6000: episode: 1089, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.151 [0.000, 23.370], loss: 1.243871, mean_squared_error: 62.770180, mean_q: 9.665305\n",
      " 2411/6000: episode: 1090, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.105 [0.000, 22.340], loss: 0.249465, mean_squared_error: 59.284401, mean_q: 9.715009\n",
      " 2412/6000: episode: 1091, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.019 [0.000, 13.388], loss: 4.627711, mean_squared_error: 70.192902, mean_q: 10.267762\n",
      " 2413/6000: episode: 1092, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.594 [0.000, 28.200], loss: 1.175674, mean_squared_error: 56.967358, mean_q: 9.186121\n",
      " 2414/6000: episode: 1093, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.206 [0.000, 19.272], loss: 1.236478, mean_squared_error: 60.781570, mean_q: 9.507366\n",
      " 2415/6000: episode: 1094, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.789 [0.000, 36.340], loss: 2.695786, mean_squared_error: 59.444824, mean_q: 9.513857\n",
      " 2418/6000: episode: 1095, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.573 [0.000, 26.400], loss: 2.547448, mean_squared_error: 56.258366, mean_q: 9.480571\n",
      " 2419/6000: episode: 1096, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.200 [0.000, 20.000], loss: 0.288449, mean_squared_error: 58.724060, mean_q: 9.610276\n",
      " 2420/6000: episode: 1097, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.257 [0.000, 21.140], loss: 1.268104, mean_squared_error: 60.500343, mean_q: 9.387922\n",
      " 2427/6000: episode: 1098, duration: 0.086s, episode steps: 7, steps per second: 82, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.714 [0.000, 2.000], mean observation: 1.677 [0.000, 26.840], loss: 1.857941, mean_squared_error: 62.053959, mean_q: 9.618910\n",
      " 2428/6000: episode: 1099, duration: 0.023s, episode steps: 1, steps per second: 44, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.241 [0.000, 24.490], loss: 2.677470, mean_squared_error: 63.126026, mean_q: 9.624397\n",
      " 2430/6000: episode: 1100, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.483 [0.000, 17.000], loss: 0.414028, mean_squared_error: 59.374065, mean_q: 9.457143\n",
      " 2431/6000: episode: 1101, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.969 [0.000, 36.870], loss: 1.841024, mean_squared_error: 62.282276, mean_q: 9.818344\n",
      " 2432/6000: episode: 1102, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.335 [0.000, 19.000], loss: 0.419254, mean_squared_error: 56.893150, mean_q: 9.397040\n",
      " 2433/6000: episode: 1103, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.774 [0.000, 21.090], loss: 1.188250, mean_squared_error: 57.746674, mean_q: 9.290420\n",
      " 2436/6000: episode: 1104, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.509 [0.000, 32.670], loss: 1.047587, mean_squared_error: 63.661610, mean_q: 9.813844\n",
      " 2437/6000: episode: 1105, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.250 [0.000, 14.790], loss: 1.521098, mean_squared_error: 66.345078, mean_q: 9.906926\n",
      " 2445/6000: episode: 1106, duration: 0.118s, episode steps: 8, steps per second: 68, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.125 [0.000, 1.000], mean observation: 0.671 [0.000, 9.390], loss: 0.836175, mean_squared_error: 63.547539, mean_q: 9.778195\n",
      " 2446/6000: episode: 1107, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.781 [0.000, 11.000], loss: 0.266114, mean_squared_error: 57.703491, mean_q: 9.478770\n",
      " 2447/6000: episode: 1108, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.534 [0.000, 30.590], loss: 0.378192, mean_squared_error: 55.616177, mean_q: 9.299923\n",
      " 2449/6000: episode: 1109, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.130 [0.000, 20.460], loss: 1.616861, mean_squared_error: 57.197655, mean_q: 9.385699\n",
      " 2452/6000: episode: 1110, duration: 0.050s, episode steps: 3, steps per second: 59, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.343 [0.000, 18.307], loss: 1.820853, mean_squared_error: 60.220417, mean_q: 9.503442\n",
      " 2455/6000: episode: 1111, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.467 [0.000, 26.520], loss: 1.368475, mean_squared_error: 56.610836, mean_q: 9.377289\n",
      " 2456/6000: episode: 1112, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.966 [0.000, 37.640], loss: 2.153946, mean_squared_error: 59.921608, mean_q: 9.653833\n",
      " 2457/6000: episode: 1113, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.881 [0.000, 29.020], loss: 1.388313, mean_squared_error: 60.237888, mean_q: 9.702389\n",
      " 2460/6000: episode: 1114, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 2.000], mean observation: 1.053 [0.000, 15.596], loss: 0.908879, mean_squared_error: 59.270374, mean_q: 9.545456\n",
      " 2463/6000: episode: 1115, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [0.000, 3.000], mean observation: 1.234 [0.000, 18.379], loss: 0.598997, mean_squared_error: 64.713905, mean_q: 9.880799\n",
      " 2464/6000: episode: 1116, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.414 [0.000, 17.610], loss: 0.199068, mean_squared_error: 60.943657, mean_q: 9.558080\n",
      " 2465/6000: episode: 1117, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.053 [0.000, 13.913], loss: 0.244278, mean_squared_error: 62.532310, mean_q: 9.761633\n",
      " 2466/6000: episode: 1118, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.366 [0.000, 20.560], loss: 0.086675, mean_squared_error: 65.411217, mean_q: 9.930465\n",
      " 2475/6000: episode: 1119, duration: 0.123s, episode steps: 9, steps per second: 73, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.111 [0.000, 3.000], mean observation: 1.195 [0.000, 19.380], loss: 2.041242, mean_squared_error: 60.729214, mean_q: 9.584879\n",
      " 2480/6000: episode: 1120, duration: 0.071s, episode steps: 5, steps per second: 70, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [0.000, 2.000], mean observation: 1.469 [0.000, 27.610], loss: 2.123622, mean_squared_error: 60.049885, mean_q: 9.503764\n",
      " 2481/6000: episode: 1121, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.491 [0.000, 23.310], loss: 0.147068, mean_squared_error: 63.973682, mean_q: 9.780068\n",
      " 2482/6000: episode: 1122, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.075 [0.000, 32.110], loss: 1.340785, mean_squared_error: 64.195984, mean_q: 9.838381\n",
      " 2483/6000: episode: 1123, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [0.000, 23.100], loss: 2.612429, mean_squared_error: 63.883396, mean_q: 9.719169\n",
      " 2484/6000: episode: 1124, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.655 [0.000, 37.740], loss: 0.116080, mean_squared_error: 63.087322, mean_q: 9.739260\n",
      " 2485/6000: episode: 1125, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.523 [0.000, 32.670], loss: 0.336055, mean_squared_error: 59.608070, mean_q: 9.657614\n",
      " 2495/6000: episode: 1126, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.345 [0.000, 18.370], loss: 0.976086, mean_squared_error: 62.004089, mean_q: 9.654718\n",
      " 2496/6000: episode: 1127, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.976 [0.000, 16.510], loss: 0.208057, mean_squared_error: 60.870907, mean_q: 9.565187\n",
      " 2497/6000: episode: 1128, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.261 [0.000, 17.711], loss: 1.323601, mean_squared_error: 60.678268, mean_q: 9.761684\n",
      " 2499/6000: episode: 1129, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.551 [0.000, 25.970], loss: 0.161120, mean_squared_error: 60.920670, mean_q: 9.661099\n",
      " 2509/6000: episode: 1130, duration: 0.131s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 1.000], mean observation: 1.133 [0.000, 15.760], loss: 1.467911, mean_squared_error: 60.788952, mean_q: 9.535480\n",
      " 2510/6000: episode: 1131, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.022 [0.000, 16.000], loss: 1.150226, mean_squared_error: 56.408119, mean_q: 9.281235\n",
      " 2511/6000: episode: 1132, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.466 [0.000, 19.623], loss: 0.782535, mean_squared_error: 62.823502, mean_q: 9.740263\n",
      " 2512/6000: episode: 1133, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.867 [0.000, 35.160], loss: 0.136685, mean_squared_error: 62.465321, mean_q: 9.678395\n",
      " 2513/6000: episode: 1134, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.105 [0.000, 20.790], loss: 2.681522, mean_squared_error: 63.382256, mean_q: 9.608321\n",
      " 2514/6000: episode: 1135, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.971 [0.000, 16.080], loss: 2.382523, mean_squared_error: 58.976158, mean_q: 9.482840\n",
      " 2515/6000: episode: 1136, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.184 [0.000, 17.441], loss: 1.354622, mean_squared_error: 56.006050, mean_q: 9.111656\n",
      " 2516/6000: episode: 1137, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.536 [0.000, 33.490], loss: 0.342302, mean_squared_error: 61.538116, mean_q: 9.627790\n",
      " 2518/6000: episode: 1138, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.855 [0.000, 35.160], loss: 2.601635, mean_squared_error: 63.276917, mean_q: 9.705827\n",
      " 2519/6000: episode: 1139, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.389 [0.000, 19.189], loss: 1.848844, mean_squared_error: 64.420464, mean_q: 9.750339\n",
      " 2522/6000: episode: 1140, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.347 [0.000, 18.410], loss: 0.583455, mean_squared_error: 63.105408, mean_q: 9.750760\n",
      " 2523/6000: episode: 1141, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.942 [0.000, 16.360], loss: 2.184474, mean_squared_error: 66.334091, mean_q: 9.906285\n",
      " 2524/6000: episode: 1142, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.347 [0.000, 18.410], loss: 2.314888, mean_squared_error: 65.067368, mean_q: 9.749683\n",
      " 2527/6000: episode: 1143, duration: 0.051s, episode steps: 3, steps per second: 58, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [1.000, 3.000], mean observation: 1.560 [0.000, 26.300], loss: 1.312573, mean_squared_error: 60.966961, mean_q: 9.662792\n",
      " 2528/6000: episode: 1144, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.324 [0.000, 27.470], loss: 1.261915, mean_squared_error: 54.933075, mean_q: 9.261789\n",
      " 2529/6000: episode: 1145, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.856 [0.000, 28.120], loss: 0.125684, mean_squared_error: 62.451393, mean_q: 9.782724\n",
      " 2530/6000: episode: 1146, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.242 [0.000, 21.420], loss: 0.161443, mean_squared_error: 65.718132, mean_q: 9.904278\n",
      " 2531/6000: episode: 1147, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.691 [0.000, 31.150], loss: 0.176634, mean_squared_error: 65.581528, mean_q: 9.905813\n",
      " 2534/6000: episode: 1148, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [1.000, 2.000], mean observation: 1.523 [0.000, 32.670], loss: 1.358438, mean_squared_error: 61.015594, mean_q: 9.542558\n",
      " 2538/6000: episode: 1149, duration: 0.061s, episode steps: 4, steps per second: 65, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.750 [0.000, 3.000], mean observation: 1.367 [0.000, 31.060], loss: 1.746283, mean_squared_error: 61.840073, mean_q: 9.520242\n",
      " 2539/6000: episode: 1150, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.382 [0.000, 17.962], loss: 0.325439, mean_squared_error: 58.602615, mean_q: 9.496948\n",
      " 2540/6000: episode: 1151, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.620 [0.000, 32.760], loss: 1.309007, mean_squared_error: 58.662098, mean_q: 9.529606\n",
      " 2543/6000: episode: 1152, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.369 [0.000, 25.140], loss: 0.601752, mean_squared_error: 60.020462, mean_q: 9.374917\n",
      " 2544/6000: episode: 1153, duration: 0.033s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.239 [0.000, 19.030], loss: 1.643071, mean_squared_error: 65.908745, mean_q: 9.773538\n",
      " 2554/6000: episode: 1154, duration: 0.183s, episode steps: 10, steps per second: 55, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.300 [0.000, 3.000], mean observation: 1.431 [0.000, 31.390], loss: 1.337543, mean_squared_error: 59.909027, mean_q: 9.583309\n",
      " 2555/6000: episode: 1155, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.177 [0.000, 15.811], loss: 0.038096, mean_squared_error: 63.832272, mean_q: 9.809919\n",
      " 2556/6000: episode: 1156, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.450 [0.000, 26.870], loss: 2.773468, mean_squared_error: 64.199936, mean_q: 9.849020\n",
      " 2563/6000: episode: 1157, duration: 0.092s, episode steps: 7, steps per second: 76, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 2.857 [2.000, 3.000], mean observation: 1.534 [0.000, 28.270], loss: 0.674897, mean_squared_error: 61.362801, mean_q: 9.560554\n",
      " 2573/6000: episode: 1158, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.800 [0.000, 2.000], mean observation: 1.672 [0.000, 37.070], loss: 1.817257, mean_squared_error: 62.079430, mean_q: 9.627353\n",
      " 2579/6000: episode: 1159, duration: 0.084s, episode steps: 6, steps per second: 71, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 0.833 [0.000, 1.000], mean observation: 1.525 [0.000, 36.720], loss: 1.079313, mean_squared_error: 62.809444, mean_q: 9.650532\n",
      " 2580/6000: episode: 1160, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.296 [0.000, 22.490], loss: 0.049389, mean_squared_error: 61.399933, mean_q: 9.625736\n",
      " 2581/6000: episode: 1161, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.352 [0.000, 33.170], loss: 1.195163, mean_squared_error: 64.225311, mean_q: 9.755872\n",
      " 2582/6000: episode: 1162, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.034 [0.000, 38.040], loss: 0.133792, mean_squared_error: 63.261543, mean_q: 9.846112\n",
      " 2592/6000: episode: 1163, duration: 0.230s, episode steps: 10, steps per second: 43, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.987 [0.000, 15.000], loss: 1.068366, mean_squared_error: 61.858784, mean_q: 9.632034\n",
      " 2600/6000: episode: 1164, duration: 0.102s, episode steps: 8, steps per second: 78, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.625 [1.000, 3.000], mean observation: 1.259 [0.000, 24.090], loss: 1.027632, mean_squared_error: 63.915268, mean_q: 9.734859\n",
      " 2602/6000: episode: 1165, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.297 [0.000, 31.370], loss: 0.868014, mean_squared_error: 64.908707, mean_q: 9.752682\n",
      " 2603/6000: episode: 1166, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.309 [0.000, 18.469], loss: 1.263666, mean_squared_error: 62.304813, mean_q: 9.586817\n",
      " 2604/6000: episode: 1167, duration: 0.033s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.031 [0.000, 13.220], loss: 1.496568, mean_squared_error: 59.910717, mean_q: 9.604292\n",
      " 2614/6000: episode: 1168, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.200 [0.000, 2.000], mean observation: 1.371 [0.000, 16.420], loss: 1.264421, mean_squared_error: 62.089233, mean_q: 9.654517\n",
      " 2615/6000: episode: 1169, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.476 [0.000, 20.570], loss: 1.750468, mean_squared_error: 60.431126, mean_q: 9.712519\n",
      " 2617/6000: episode: 1170, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.716 [0.000, 22.240], loss: 1.235582, mean_squared_error: 56.141205, mean_q: 9.466127\n",
      " 2626/6000: episode: 1171, duration: 0.118s, episode steps: 9, steps per second: 76, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.889 [0.000, 1.000], mean observation: 1.604 [0.000, 36.890], loss: 1.032824, mean_squared_error: 61.684036, mean_q: 9.579486\n",
      " 2627/6000: episode: 1172, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.277 [0.000, 17.000], loss: 1.620085, mean_squared_error: 62.699730, mean_q: 9.627112\n",
      " 2628/6000: episode: 1173, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.526 [0.000, 38.520], loss: 1.498878, mean_squared_error: 60.069153, mean_q: 9.513639\n",
      " 2630/6000: episode: 1174, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.801 [0.000, 13.000], loss: 2.312271, mean_squared_error: 60.958073, mean_q: 9.536133\n",
      " 2640/6000: episode: 1175, duration: 0.128s, episode steps: 10, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.627 [0.000, 24.460], loss: 1.235787, mean_squared_error: 61.790108, mean_q: 9.663042\n",
      " 2641/6000: episode: 1176, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.806 [0.000, 22.440], loss: 1.458256, mean_squared_error: 62.980114, mean_q: 9.752951\n",
      " 2643/6000: episode: 1177, duration: 0.037s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.675 [0.000, 27.220], loss: 0.558560, mean_squared_error: 65.360718, mean_q: 9.938753\n",
      " 2644/6000: episode: 1178, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.728 [0.000, 33.070], loss: 0.875582, mean_squared_error: 56.780487, mean_q: 9.540030\n",
      " 2645/6000: episode: 1179, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.973 [0.000, 38.590], loss: 2.365686, mean_squared_error: 60.197186, mean_q: 9.531148\n",
      " 2646/6000: episode: 1180, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.123 [0.000, 18.000], loss: 2.486015, mean_squared_error: 58.810238, mean_q: 9.599828\n",
      " 2649/6000: episode: 1181, duration: 0.047s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.667 [2.000, 3.000], mean observation: 1.225 [0.000, 21.970], loss: 1.241867, mean_squared_error: 60.952419, mean_q: 9.549570\n",
      " 2650/6000: episode: 1182, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.282 [0.000, 16.477], loss: 0.120532, mean_squared_error: 62.711617, mean_q: 9.808539\n",
      " 2651/6000: episode: 1183, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [0.000, 30.200], loss: 1.387431, mean_squared_error: 65.452965, mean_q: 9.949041\n",
      " 2652/6000: episode: 1184, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.620 [0.000, 22.540], loss: 0.259244, mean_squared_error: 57.693012, mean_q: 9.666319\n",
      " 2653/6000: episode: 1185, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.901 [0.000, 14.520], loss: 0.067735, mean_squared_error: 63.328003, mean_q: 9.764820\n",
      " 2655/6000: episode: 1186, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 0.926 [0.000, 15.000], loss: 1.862878, mean_squared_error: 59.708027, mean_q: 9.465502\n",
      " 2656/6000: episode: 1187, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.399 [0.000, 17.946], loss: 2.824686, mean_squared_error: 61.041557, mean_q: 9.586003\n",
      " 2657/6000: episode: 1188, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.749 [0.000, 38.480], loss: 0.277516, mean_squared_error: 59.911175, mean_q: 9.700996\n",
      " 2663/6000: episode: 1189, duration: 0.080s, episode steps: 6, steps per second: 75, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.315 [0.000, 21.160], loss: 0.708814, mean_squared_error: 63.264542, mean_q: 9.846765\n",
      " 2664/6000: episode: 1190, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.041 [0.000, 12.943], loss: 2.376045, mean_squared_error: 59.186035, mean_q: 9.523225\n",
      " 2665/6000: episode: 1191, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.003 [0.000, 37.420], loss: 3.182303, mean_squared_error: 59.665279, mean_q: 9.312088\n",
      " 2667/6000: episode: 1192, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.433 [0.000, 24.740], loss: 1.203948, mean_squared_error: 60.223816, mean_q: 9.611246\n",
      " 2669/6000: episode: 1193, duration: 0.040s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.831 [0.000, 39.560], loss: 2.563888, mean_squared_error: 60.724030, mean_q: 9.524303\n",
      " 2675/6000: episode: 1194, duration: 0.089s, episode steps: 6, steps per second: 67, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.500 [0.000, 3.000], mean observation: 1.787 [0.000, 30.930], loss: 1.570619, mean_squared_error: 58.724873, mean_q: 9.497584\n",
      " 2685/6000: episode: 1195, duration: 0.131s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.200 [0.000, 2.000], mean observation: 1.087 [0.000, 19.290], loss: 1.452798, mean_squared_error: 57.874138, mean_q: 9.444760\n",
      " 2690/6000: episode: 1196, duration: 0.069s, episode steps: 5, steps per second: 72, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.800 [1.000, 2.000], mean observation: 1.300 [0.000, 19.180], loss: 1.651632, mean_squared_error: 60.098461, mean_q: 9.575388\n",
      " 2691/6000: episode: 1197, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.750 [0.000, 38.190], loss: 0.157253, mean_squared_error: 62.132446, mean_q: 9.645979\n",
      " 2692/6000: episode: 1198, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.478 [0.000, 32.060], loss: 1.625950, mean_squared_error: 65.177444, mean_q: 9.886810\n",
      " 2694/6000: episode: 1199, duration: 0.042s, episode steps: 2, steps per second: 47, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.472 [0.000, 27.420], loss: 0.131902, mean_squared_error: 63.955490, mean_q: 9.906012\n",
      " 2695/6000: episode: 1200, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.112 [0.000, 18.000], loss: 1.665840, mean_squared_error: 59.084396, mean_q: 9.605242\n",
      " 2704/6000: episode: 1201, duration: 0.119s, episode steps: 9, steps per second: 76, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.333 [0.000, 3.000], mean observation: 1.087 [0.000, 16.906], loss: 1.158537, mean_squared_error: 61.613945, mean_q: 9.671382\n",
      " 2705/6000: episode: 1202, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.249 [0.000, 19.920], loss: 0.124076, mean_squared_error: 64.766235, mean_q: 9.792616\n",
      " 2715/6000: episode: 1203, duration: 0.138s, episode steps: 10, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.435 [0.000, 30.030], loss: 1.213928, mean_squared_error: 62.007771, mean_q: 9.651160\n",
      " 2718/6000: episode: 1204, duration: 0.055s, episode steps: 3, steps per second: 55, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.466 [0.000, 36.660], loss: 2.212834, mean_squared_error: 62.759430, mean_q: 9.676454\n",
      " 2719/6000: episode: 1205, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [0.000, 20.960], loss: 2.726855, mean_squared_error: 62.047852, mean_q: 9.768093\n",
      " 2721/6000: episode: 1206, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.624 [0.000, 30.960], loss: 1.285414, mean_squared_error: 57.989090, mean_q: 9.386944\n",
      " 2723/6000: episode: 1207, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.807 [0.000, 36.290], loss: 1.596887, mean_squared_error: 61.288933, mean_q: 9.592461\n",
      " 2724/6000: episode: 1208, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.774 [0.000, 10.745], loss: 0.289926, mean_squared_error: 57.788975, mean_q: 9.590798\n",
      " 2725/6000: episode: 1209, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.675 [0.000, 25.090], loss: 1.050465, mean_squared_error: 60.210812, mean_q: 9.629876\n",
      " 2727/6000: episode: 1210, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 0.955 [0.000, 13.823], loss: 3.507422, mean_squared_error: 60.906174, mean_q: 9.569601\n",
      " 2734/6000: episode: 1211, duration: 0.108s, episode steps: 7, steps per second: 65, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 2.857 [2.000, 3.000], mean observation: 1.177 [0.000, 18.746], loss: 1.879452, mean_squared_error: 60.619637, mean_q: 9.516824\n",
      " 2741/6000: episode: 1212, duration: 0.084s, episode steps: 7, steps per second: 83, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 0.714 [0.000, 3.000], mean observation: 1.133 [0.000, 15.929], loss: 2.228279, mean_squared_error: 55.709637, mean_q: 9.262952\n",
      " 2743/6000: episode: 1213, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.450 [0.000, 19.687], loss: 0.855848, mean_squared_error: 61.546959, mean_q: 9.665426\n",
      " 2744/6000: episode: 1214, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.349 [0.000, 31.580], loss: 0.303203, mean_squared_error: 56.710621, mean_q: 9.351952\n",
      " 2754/6000: episode: 1215, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.200 [1.000, 3.000], mean observation: 1.147 [0.000, 20.040], loss: 1.106752, mean_squared_error: 64.016098, mean_q: 9.759596\n",
      " 2755/6000: episode: 1216, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.147 [0.000, 15.548], loss: 1.489110, mean_squared_error: 52.186306, mean_q: 8.961946\n",
      " 2760/6000: episode: 1217, duration: 0.071s, episode steps: 5, steps per second: 71, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.800 [0.000, 1.000], mean observation: 1.402 [0.000, 24.030], loss: 1.508976, mean_squared_error: 56.923656, mean_q: 9.333054\n",
      " 2761/6000: episode: 1218, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.453 [0.000, 21.220], loss: 0.380457, mean_squared_error: 57.922436, mean_q: 9.462934\n",
      " 2762/6000: episode: 1219, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.956 [0.000, 17.860], loss: 1.284234, mean_squared_error: 60.745468, mean_q: 9.457947\n",
      " 2763/6000: episode: 1220, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.008 [0.000, 16.631], loss: 2.929510, mean_squared_error: 65.695999, mean_q: 9.866723\n",
      " 2764/6000: episode: 1221, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.353 [0.000, 27.650], loss: 0.335136, mean_squared_error: 57.113884, mean_q: 9.444136\n",
      " 2774/6000: episode: 1222, duration: 0.137s, episode steps: 10, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.100 [2.000, 3.000], mean observation: 1.248 [0.000, 18.000], loss: 1.144443, mean_squared_error: 62.691425, mean_q: 9.637807\n",
      " 2775/6000: episode: 1223, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.289 [0.000, 19.350], loss: 0.242329, mean_squared_error: 54.984917, mean_q: 9.146381\n",
      " 2777/6000: episode: 1224, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.617 [0.000, 35.280], loss: 2.272177, mean_squared_error: 59.993416, mean_q: 9.506096\n",
      " 2779/6000: episode: 1225, duration: 0.043s, episode steps: 2, steps per second: 47, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.478 [0.000, 28.030], loss: 2.425806, mean_squared_error: 63.236565, mean_q: 9.621683\n",
      " 2781/6000: episode: 1226, duration: 0.037s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.951 [0.000, 39.270], loss: 1.964268, mean_squared_error: 62.216324, mean_q: 9.642519\n",
      " 2787/6000: episode: 1227, duration: 0.092s, episode steps: 6, steps per second: 65, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.167 [1.000, 2.000], mean observation: 1.667 [0.000, 35.240], loss: 2.014553, mean_squared_error: 57.948177, mean_q: 9.364635\n",
      " 2791/6000: episode: 1228, duration: 0.062s, episode steps: 4, steps per second: 65, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 2.000], mean observation: 1.714 [0.000, 34.500], loss: 1.363268, mean_squared_error: 57.883003, mean_q: 9.364299\n",
      " 2792/6000: episode: 1229, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.508 [0.000, 27.620], loss: 0.230956, mean_squared_error: 63.010567, mean_q: 9.842457\n",
      " 2793/6000: episode: 1230, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.675 [0.000, 22.580], loss: 0.170082, mean_squared_error: 61.612129, mean_q: 9.808117\n",
      " 2794/6000: episode: 1231, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.340 [0.000, 17.250], loss: 3.245731, mean_squared_error: 64.820023, mean_q: 9.761570\n",
      " 2797/6000: episode: 1232, duration: 0.052s, episode steps: 3, steps per second: 58, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.707 [0.000, 38.620], loss: 2.677037, mean_squared_error: 55.685635, mean_q: 9.220860\n",
      " 2805/6000: episode: 1233, duration: 0.167s, episode steps: 8, steps per second: 48, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.875 [2.000, 3.000], mean observation: 1.720 [0.000, 30.940], loss: 1.010703, mean_squared_error: 62.510502, mean_q: 9.631042\n",
      " 2815/6000: episode: 1234, duration: 0.419s, episode steps: 10, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 3.000], mean observation: 1.570 [0.000, 34.710], loss: 1.120439, mean_squared_error: 61.355297, mean_q: 9.630706\n",
      " 2816/6000: episode: 1235, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.942 [0.000, 16.360], loss: 1.627072, mean_squared_error: 59.820107, mean_q: 9.361677\n",
      " 2817/6000: episode: 1236, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.712 [0.000, 23.390], loss: 0.341343, mean_squared_error: 59.418797, mean_q: 9.413273\n",
      " 2827/6000: episode: 1237, duration: 0.143s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.400 [0.000, 2.000], mean observation: 1.406 [0.000, 24.880], loss: 1.270377, mean_squared_error: 60.362999, mean_q: 9.627514\n",
      " 2831/6000: episode: 1238, duration: 0.089s, episode steps: 4, steps per second: 45, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 2.000], mean observation: 1.077 [0.000, 17.540], loss: 2.090885, mean_squared_error: 63.560482, mean_q: 9.737064\n",
      " 2832/6000: episode: 1239, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.331 [0.000, 25.410], loss: 1.182439, mean_squared_error: 58.707211, mean_q: 9.472519\n",
      " 2833/6000: episode: 1240, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.396 [0.000, 18.036], loss: 1.462699, mean_squared_error: 60.830585, mean_q: 9.591875\n",
      " 2839/6000: episode: 1241, duration: 0.078s, episode steps: 6, steps per second: 77, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 0.167 [0.000, 1.000], mean observation: 1.547 [0.000, 33.860], loss: 1.184252, mean_squared_error: 63.138916, mean_q: 9.707685\n",
      " 2840/6000: episode: 1242, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.604 [0.000, 21.650], loss: 2.766828, mean_squared_error: 62.164925, mean_q: 9.560448\n",
      " 2841/6000: episode: 1243, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.571 [0.000, 37.870], loss: 5.546745, mean_squared_error: 63.402245, mean_q: 9.582378\n",
      " 2842/6000: episode: 1244, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.417 [0.000, 21.050], loss: 1.138463, mean_squared_error: 59.345615, mean_q: 9.358161\n",
      " 2844/6000: episode: 1245, duration: 0.048s, episode steps: 2, steps per second: 42, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.567 [0.000, 30.710], loss: 2.004869, mean_squared_error: 63.551987, mean_q: 9.643292\n",
      " 2854/6000: episode: 1246, duration: 0.171s, episode steps: 10, steps per second: 58, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.700 [0.000, 3.000], mean observation: 0.864 [0.000, 12.520], loss: 1.017916, mean_squared_error: 62.592918, mean_q: 9.709097\n",
      " 2864/6000: episode: 1247, duration: 0.173s, episode steps: 10, steps per second: 58, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.423 [0.000, 19.000], loss: 1.666802, mean_squared_error: 59.724499, mean_q: 9.529561\n",
      " 2865/6000: episode: 1248, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.743 [0.000, 31.310], loss: 1.098641, mean_squared_error: 61.777374, mean_q: 9.649843\n",
      " 2867/6000: episode: 1249, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.909 [0.000, 39.000], loss: 2.552053, mean_squared_error: 61.870617, mean_q: 9.598717\n",
      " 2871/6000: episode: 1250, duration: 0.062s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.595 [0.000, 39.480], loss: 1.314993, mean_squared_error: 62.029549, mean_q: 9.644260\n",
      " 2872/6000: episode: 1251, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.141 [0.000, 16.445], loss: 3.869762, mean_squared_error: 65.378098, mean_q: 9.819412\n",
      " 2874/6000: episode: 1252, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.020 [0.000, 12.610], loss: 1.033739, mean_squared_error: 60.593414, mean_q: 9.632089\n",
      " 2875/6000: episode: 1253, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.113 [0.000, 15.386], loss: 1.649332, mean_squared_error: 56.231861, mean_q: 9.394868\n",
      " 2878/6000: episode: 1254, duration: 0.068s, episode steps: 3, steps per second: 44, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.420 [0.000, 30.650], loss: 0.131485, mean_squared_error: 62.077885, mean_q: 9.704911\n",
      " 2879/6000: episode: 1255, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.290 [0.000, 19.800], loss: 1.183747, mean_squared_error: 62.940887, mean_q: 9.763709\n",
      " 2880/6000: episode: 1256, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.133 [0.000, 15.000], loss: 1.178456, mean_squared_error: 49.142574, mean_q: 8.740736\n",
      " 2881/6000: episode: 1257, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.678 [0.000, 23.480], loss: 1.607295, mean_squared_error: 58.037170, mean_q: 9.713512\n",
      " 2891/6000: episode: 1258, duration: 0.164s, episode steps: 10, steps per second: 61, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.100 [1.000, 2.000], mean observation: 1.296 [0.000, 17.300], loss: 1.758378, mean_squared_error: 59.244152, mean_q: 9.552588\n",
      " 2901/6000: episode: 1259, duration: 0.299s, episode steps: 10, steps per second: 33, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 3.000], mean observation: 1.148 [0.000, 19.750], loss: 1.547157, mean_squared_error: 60.278076, mean_q: 9.497176\n",
      " 2902/6000: episode: 1260, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.698 [0.000, 33.970], loss: 0.182151, mean_squared_error: 61.765804, mean_q: 9.728235\n",
      " 2903/6000: episode: 1261, duration: 0.054s, episode steps: 1, steps per second: 18, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.117 [0.000, 24.730], loss: 1.234506, mean_squared_error: 63.873428, mean_q: 9.685312\n",
      " 2904/6000: episode: 1262, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.419 [0.000, 26.730], loss: 0.163114, mean_squared_error: 63.119011, mean_q: 9.890083\n",
      " 2905/6000: episode: 1263, duration: 0.067s, episode steps: 1, steps per second: 15, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.252 [0.000, 24.110], loss: 3.054933, mean_squared_error: 60.733364, mean_q: 9.630513\n",
      " 2915/6000: episode: 1264, duration: 0.238s, episode steps: 10, steps per second: 42, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 2.000], mean observation: 1.349 [0.000, 16.590], loss: 1.964562, mean_squared_error: 58.440235, mean_q: 9.476566\n",
      " 2925/6000: episode: 1265, duration: 0.157s, episode steps: 10, steps per second: 64, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.365 [0.000, 17.728], loss: 1.559979, mean_squared_error: 59.927406, mean_q: 9.509515\n",
      " 2932/6000: episode: 1266, duration: 0.113s, episode steps: 7, steps per second: 62, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 2.143 [0.000, 3.000], mean observation: 1.343 [0.000, 17.722], loss: 1.331003, mean_squared_error: 59.902103, mean_q: 9.557071\n",
      " 2942/6000: episode: 1267, duration: 0.154s, episode steps: 10, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.700 [0.000, 3.000], mean observation: 0.919 [0.000, 10.954], loss: 1.312411, mean_squared_error: 62.679218, mean_q: 9.647676\n",
      " 2944/6000: episode: 1268, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.435 [0.000, 27.580], loss: 0.797839, mean_squared_error: 58.653900, mean_q: 9.431295\n",
      " 2946/6000: episode: 1269, duration: 0.045s, episode steps: 2, steps per second: 45, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.114 [0.000, 25.190], loss: 1.082659, mean_squared_error: 60.168381, mean_q: 9.471568\n",
      " 2947/6000: episode: 1270, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.851 [0.000, 32.500], loss: 2.684944, mean_squared_error: 60.798744, mean_q: 9.630604\n",
      " 2948/6000: episode: 1271, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.163 [0.000, 19.132], loss: 1.267747, mean_squared_error: 61.861832, mean_q: 9.582600\n",
      " 2956/6000: episode: 1272, duration: 0.112s, episode steps: 8, steps per second: 71, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.658 [0.000, 32.600], loss: 1.334750, mean_squared_error: 60.986004, mean_q: 9.576311\n",
      " 2957/6000: episode: 1273, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.931 [0.000, 37.320], loss: 0.876008, mean_squared_error: 64.599548, mean_q: 9.978060\n",
      " 2958/6000: episode: 1274, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.207 [0.000, 16.930], loss: 1.499007, mean_squared_error: 59.011459, mean_q: 9.399956\n",
      " 2965/6000: episode: 1275, duration: 0.114s, episode steps: 7, steps per second: 61, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.424 [0.000, 23.480], loss: 1.778003, mean_squared_error: 58.790890, mean_q: 9.393033\n",
      " 2972/6000: episode: 1276, duration: 0.124s, episode steps: 7, steps per second: 57, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.143 [0.000, 3.000], mean observation: 1.578 [0.000, 24.420], loss: 1.802456, mean_squared_error: 61.182091, mean_q: 9.634784\n",
      " 2973/6000: episode: 1277, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.212 [0.000, 24.650], loss: 0.340055, mean_squared_error: 53.925827, mean_q: 9.170688\n",
      " 2974/6000: episode: 1278, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.482 [0.000, 35.430], loss: 0.144563, mean_squared_error: 62.472633, mean_q: 9.740166\n",
      " 2982/6000: episode: 1279, duration: 0.126s, episode steps: 8, steps per second: 64, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.082 [0.000, 19.000], loss: 2.003273, mean_squared_error: 58.596565, mean_q: 9.504876\n",
      " 2983/6000: episode: 1280, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.305 [0.000, 20.680], loss: 1.275483, mean_squared_error: 56.384205, mean_q: 9.231760\n",
      " 2987/6000: episode: 1281, duration: 0.069s, episode steps: 4, steps per second: 58, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.250 [0.000, 1.000], mean observation: 1.368 [0.000, 29.620], loss: 1.115899, mean_squared_error: 60.798122, mean_q: 9.553048\n",
      " 2988/6000: episode: 1282, duration: 0.036s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.657 [0.000, 37.940], loss: 1.177914, mean_squared_error: 61.653984, mean_q: 9.642816\n",
      " 2989/6000: episode: 1283, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.706 [0.000, 32.520], loss: 2.175380, mean_squared_error: 57.916908, mean_q: 9.506557\n",
      " 2990/6000: episode: 1284, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.471 [0.000, 26.390], loss: 3.211200, mean_squared_error: 54.805336, mean_q: 9.108973\n",
      " 2991/6000: episode: 1285, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.524 [0.000, 35.350], loss: 1.184640, mean_squared_error: 60.064720, mean_q: 9.444839\n",
      " 2992/6000: episode: 1286, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.854 [0.000, 37.530], loss: 1.130485, mean_squared_error: 61.700115, mean_q: 9.812206\n",
      " 2994/6000: episode: 1287, duration: 0.043s, episode steps: 2, steps per second: 47, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.567 [0.000, 28.160], loss: 1.491782, mean_squared_error: 59.479893, mean_q: 9.515858\n",
      " 3000/6000: episode: 1288, duration: 0.103s, episode steps: 6, steps per second: 58, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.833 [1.000, 2.000], mean observation: 1.004 [0.000, 17.210], loss: 1.828886, mean_squared_error: 59.393215, mean_q: 9.480662\n",
      " 3001/6000: episode: 1289, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.175 [0.000, 15.718], loss: 2.665638, mean_squared_error: 64.038147, mean_q: 9.601597\n",
      " 3003/6000: episode: 1290, duration: 0.044s, episode steps: 2, steps per second: 45, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.136 [0.000, 16.000], loss: 1.356714, mean_squared_error: 56.730942, mean_q: 9.253902\n",
      " 3004/6000: episode: 1291, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.700 [0.000, 35.270], loss: 1.355023, mean_squared_error: 66.537590, mean_q: 9.910967\n",
      " 3005/6000: episode: 1292, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.286 [0.000, 29.770], loss: 1.092303, mean_squared_error: 62.173496, mean_q: 9.709522\n",
      " 3006/6000: episode: 1293, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.498 [0.000, 19.366], loss: 2.119405, mean_squared_error: 61.714470, mean_q: 9.674109\n",
      " 3014/6000: episode: 1294, duration: 0.122s, episode steps: 8, steps per second: 66, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.750 [1.000, 3.000], mean observation: 1.655 [0.000, 36.250], loss: 0.921454, mean_squared_error: 61.172871, mean_q: 9.620678\n",
      " 3015/6000: episode: 1295, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.551 [0.000, 27.100], loss: 1.649172, mean_squared_error: 62.086857, mean_q: 9.445717\n",
      " 3017/6000: episode: 1296, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.687 [0.000, 38.220], loss: 0.869591, mean_squared_error: 61.615601, mean_q: 9.674507\n",
      " 3019/6000: episode: 1297, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.819 [0.000, 34.500], loss: 1.239696, mean_squared_error: 60.876133, mean_q: 9.579527\n",
      " 3020/6000: episode: 1298, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.000 [0.000, 16.951], loss: 0.220124, mean_squared_error: 58.978813, mean_q: 9.526546\n",
      " 3021/6000: episode: 1299, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.431 [0.000, 31.390], loss: 0.088310, mean_squared_error: 59.402008, mean_q: 9.622716\n",
      " 3022/6000: episode: 1300, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.271 [0.000, 31.640], loss: 1.166221, mean_squared_error: 65.104385, mean_q: 9.808543\n",
      " 3031/6000: episode: 1301, duration: 0.149s, episode steps: 9, steps per second: 61, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.444 [0.000, 3.000], mean observation: 1.253 [0.000, 18.000], loss: 1.642442, mean_squared_error: 60.698982, mean_q: 9.554982\n",
      " 3032/6000: episode: 1302, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.497 [0.000, 29.700], loss: 0.265445, mean_squared_error: 58.974159, mean_q: 9.394547\n",
      " 3040/6000: episode: 1303, duration: 0.124s, episode steps: 8, steps per second: 64, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.875 [0.000, 1.000], mean observation: 1.604 [0.000, 21.290], loss: 1.673228, mean_squared_error: 58.168625, mean_q: 9.430164\n",
      " 3048/6000: episode: 1304, duration: 0.125s, episode steps: 8, steps per second: 64, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.375 [0.000, 2.000], mean observation: 1.139 [0.000, 18.540], loss: 1.438548, mean_squared_error: 59.140099, mean_q: 9.451553\n",
      " 3049/6000: episode: 1305, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.369 [0.000, 25.140], loss: 3.084674, mean_squared_error: 59.019676, mean_q: 9.292674\n",
      " 3059/6000: episode: 1306, duration: 0.145s, episode steps: 10, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.868 [0.000, 12.489], loss: 1.098682, mean_squared_error: 60.759846, mean_q: 9.591595\n",
      " 3064/6000: episode: 1307, duration: 0.080s, episode steps: 5, steps per second: 63, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.800 [2.000, 3.000], mean observation: 1.468 [0.000, 17.739], loss: 2.023610, mean_squared_error: 59.762215, mean_q: 9.459470\n",
      " 3066/6000: episode: 1308, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.465 [0.000, 39.870], loss: 1.446768, mean_squared_error: 60.738304, mean_q: 9.521843\n",
      " 3067/6000: episode: 1309, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.186 [0.000, 17.166], loss: 0.187722, mean_squared_error: 57.963062, mean_q: 9.427230\n",
      " 3070/6000: episode: 1310, duration: 0.054s, episode steps: 3, steps per second: 55, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [0.000, 3.000], mean observation: 1.381 [0.000, 19.419], loss: 1.107267, mean_squared_error: 63.850697, mean_q: 9.729085\n",
      " 3071/6000: episode: 1311, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.897 [0.000, 19.800], loss: 1.117082, mean_squared_error: 58.865143, mean_q: 9.618820\n",
      " 3081/6000: episode: 1312, duration: 0.126s, episode steps: 10, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.400 [0.000, 3.000], mean observation: 1.154 [0.000, 19.000], loss: 1.389511, mean_squared_error: 62.566029, mean_q: 9.707365\n",
      " 3082/6000: episode: 1313, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.776 [0.000, 28.680], loss: 1.377899, mean_squared_error: 59.803490, mean_q: 9.383070\n",
      " 3092/6000: episode: 1314, duration: 0.144s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.300 [1.000, 3.000], mean observation: 1.458 [0.000, 17.627], loss: 1.684570, mean_squared_error: 60.929218, mean_q: 9.509686\n",
      " 3094/6000: episode: 1315, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.673 [0.000, 34.800], loss: 1.580668, mean_squared_error: 62.575703, mean_q: 9.619779\n",
      " 3096/6000: episode: 1316, duration: 0.048s, episode steps: 2, steps per second: 42, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.626 [0.000, 33.280], loss: 1.793409, mean_squared_error: 57.759815, mean_q: 9.337959\n",
      " 3097/6000: episode: 1317, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.847 [0.000, 14.262], loss: 1.428488, mean_squared_error: 62.142372, mean_q: 9.653017\n",
      " 3098/6000: episode: 1318, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.264 [0.000, 32.060], loss: 1.473212, mean_squared_error: 64.200714, mean_q: 9.743856\n",
      " 3101/6000: episode: 1319, duration: 0.051s, episode steps: 3, steps per second: 59, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 1.930 [0.000, 39.000], loss: 1.816535, mean_squared_error: 62.813629, mean_q: 9.657811\n",
      " 3102/6000: episode: 1320, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.561 [0.000, 23.900], loss: 1.517857, mean_squared_error: 63.387901, mean_q: 9.778732\n",
      " 3103/6000: episode: 1321, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.887 [0.000, 15.540], loss: 3.682464, mean_squared_error: 60.958397, mean_q: 9.469429\n",
      " 3113/6000: episode: 1322, duration: 0.145s, episode steps: 10, steps per second: 69, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 0.300 [0.000, 2.000], mean observation: 1.372 [0.000, 33.750], loss: 1.341197, mean_squared_error: 59.935425, mean_q: 9.522120\n",
      " 3121/6000: episode: 1323, duration: 0.128s, episode steps: 8, steps per second: 62, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.125 [2.000, 3.000], mean observation: 1.398 [0.000, 17.570], loss: 1.532550, mean_squared_error: 61.115936, mean_q: 9.600058\n",
      " 3122/6000: episode: 1324, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.624 [0.000, 19.260], loss: 1.238786, mean_squared_error: 56.017433, mean_q: 9.262234\n",
      " 3132/6000: episode: 1325, duration: 0.162s, episode steps: 10, steps per second: 62, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 2.100 [0.000, 3.000], mean observation: 1.030 [0.000, 14.770], loss: 1.062249, mean_squared_error: 61.799095, mean_q: 9.673437\n",
      " 3133/6000: episode: 1326, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.320 [0.000, 18.650], loss: 0.108642, mean_squared_error: 59.016022, mean_q: 9.635426\n",
      " 3134/6000: episode: 1327, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.348 [0.000, 20.130], loss: 0.419487, mean_squared_error: 58.224419, mean_q: 9.757593\n",
      " 3135/6000: episode: 1328, duration: 0.051s, episode steps: 1, steps per second: 19, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.214 [0.000, 27.700], loss: 0.401152, mean_squared_error: 55.008518, mean_q: 9.154203\n",
      " 3136/6000: episode: 1329, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.532 [0.000, 18.260], loss: 1.134110, mean_squared_error: 53.831486, mean_q: 9.225281\n",
      " 3137/6000: episode: 1330, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.046 [0.000, 13.980], loss: 1.476260, mean_squared_error: 57.120049, mean_q: 9.409075\n",
      " 3138/6000: episode: 1331, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.679 [0.000, 35.030], loss: 0.106661, mean_squared_error: 60.241051, mean_q: 9.636714\n",
      " 3139/6000: episode: 1332, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.654 [0.000, 38.710], loss: 0.207359, mean_squared_error: 63.486652, mean_q: 9.864006\n",
      " 3141/6000: episode: 1333, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.155 [0.000, 19.858], loss: 0.826905, mean_squared_error: 58.500244, mean_q: 9.411009\n",
      " 3144/6000: episode: 1334, duration: 0.085s, episode steps: 3, steps per second: 35, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 1.035 [0.000, 19.980], loss: 0.437304, mean_squared_error: 59.835430, mean_q: 9.541718\n",
      " 3145/6000: episode: 1335, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.502 [0.000, 29.480], loss: 0.260461, mean_squared_error: 56.088879, mean_q: 9.389660\n",
      " 3155/6000: episode: 1336, duration: 0.151s, episode steps: 10, steps per second: 66, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.400 [0.000, 2.000], mean observation: 1.478 [0.000, 19.080], loss: 1.246332, mean_squared_error: 62.224567, mean_q: 9.676054\n",
      " 3157/6000: episode: 1337, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.335 [0.000, 16.250], loss: 0.719114, mean_squared_error: 61.130943, mean_q: 9.622471\n",
      " 3158/6000: episode: 1338, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.906 [0.000, 13.482], loss: 1.590745, mean_squared_error: 59.033463, mean_q: 9.362949\n",
      " 3159/6000: episode: 1339, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.294 [0.000, 19.278], loss: 0.369090, mean_squared_error: 57.056553, mean_q: 9.357015\n",
      " 3160/6000: episode: 1340, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [0.000, 30.200], loss: 2.199941, mean_squared_error: 61.630424, mean_q: 9.676735\n",
      " 3161/6000: episode: 1341, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.839 [0.000, 32.710], loss: 1.118538, mean_squared_error: 61.594177, mean_q: 9.646162\n",
      " 3165/6000: episode: 1342, duration: 0.062s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.750 [1.000, 2.000], mean observation: 1.070 [0.000, 17.720], loss: 1.736185, mean_squared_error: 57.340488, mean_q: 9.375353\n",
      " 3168/6000: episode: 1343, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [1.000, 2.000], mean observation: 1.060 [0.000, 16.415], loss: 1.491935, mean_squared_error: 62.219482, mean_q: 9.585505\n",
      " 3169/6000: episode: 1344, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.283 [0.000, 15.000], loss: 2.761768, mean_squared_error: 66.228546, mean_q: 9.947756\n",
      " 3170/6000: episode: 1345, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.943 [0.000, 16.000], loss: 1.316579, mean_squared_error: 63.815956, mean_q: 9.791223\n",
      " 3171/6000: episode: 1346, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.999 [0.000, 22.140], loss: 0.318847, mean_squared_error: 66.803024, mean_q: 9.944235\n",
      " 3172/6000: episode: 1347, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.077 [0.000, 23.420], loss: 0.101936, mean_squared_error: 60.862381, mean_q: 9.661640\n",
      " 3173/6000: episode: 1348, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [0.000, 16.000], loss: 0.078639, mean_squared_error: 64.138687, mean_q: 9.836349\n",
      " 3178/6000: episode: 1349, duration: 0.078s, episode steps: 5, steps per second: 64, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.400 [0.000, 3.000], mean observation: 1.087 [0.000, 13.760], loss: 1.988466, mean_squared_error: 59.094921, mean_q: 9.489159\n",
      " 3179/6000: episode: 1350, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.951 [0.000, 14.122], loss: 0.133562, mean_squared_error: 63.536274, mean_q: 9.810811\n",
      " 3180/6000: episode: 1351, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.342 [0.000, 28.420], loss: 0.188847, mean_squared_error: 61.556614, mean_q: 9.636440\n",
      " 3182/6000: episode: 1352, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.116 [0.000, 22.090], loss: 3.810045, mean_squared_error: 61.226761, mean_q: 9.463531\n",
      " 3185/6000: episode: 1353, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.667 [2.000, 3.000], mean observation: 1.867 [0.000, 37.920], loss: 1.981550, mean_squared_error: 61.236343, mean_q: 9.566382\n",
      " 3187/6000: episode: 1354, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.748 [0.000, 35.670], loss: 0.671676, mean_squared_error: 60.023537, mean_q: 9.617700\n",
      " 3188/6000: episode: 1355, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.295 [0.000, 20.690], loss: 0.142479, mean_squared_error: 60.364441, mean_q: 9.534376\n",
      " 3189/6000: episode: 1356, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.123 [0.000, 17.000], loss: 0.126522, mean_squared_error: 66.046539, mean_q: 9.903875\n",
      " 3199/6000: episode: 1357, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.460 [0.000, 27.100], loss: 0.970558, mean_squared_error: 60.434845, mean_q: 9.592939\n",
      " 3200/6000: episode: 1358, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.992 [0.000, 33.750], loss: 2.245023, mean_squared_error: 67.460381, mean_q: 10.014372\n",
      " 3201/6000: episode: 1359, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.166 [0.000, 14.187], loss: 0.227420, mean_squared_error: 63.279102, mean_q: 9.910415\n",
      " 3204/6000: episode: 1360, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.729 [0.000, 30.700], loss: 0.949672, mean_squared_error: 63.160419, mean_q: 9.719661\n",
      " 3207/6000: episode: 1361, duration: 0.046s, episode steps: 3, steps per second: 66, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.731 [0.000, 31.150], loss: 2.309003, mean_squared_error: 58.819897, mean_q: 9.420624\n",
      " 3208/6000: episode: 1362, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.069 [0.000, 16.566], loss: 2.936174, mean_squared_error: 67.835320, mean_q: 10.137556\n",
      " 3210/6000: episode: 1363, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.248 [0.000, 18.000], loss: 1.896193, mean_squared_error: 62.535946, mean_q: 9.807365\n",
      " 3212/6000: episode: 1364, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.120 [0.000, 14.941], loss: 0.896330, mean_squared_error: 62.645416, mean_q: 9.751826\n",
      " 3216/6000: episode: 1365, duration: 0.056s, episode steps: 4, steps per second: 71, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.469 [0.000, 32.450], loss: 1.305505, mean_squared_error: 59.248638, mean_q: 9.531710\n",
      " 3226/6000: episode: 1366, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.100 [0.000, 1.000], mean observation: 1.453 [0.000, 15.755], loss: 1.566030, mean_squared_error: 59.990986, mean_q: 9.566339\n",
      " 3227/6000: episode: 1367, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.493 [0.000, 19.878], loss: 0.157324, mean_squared_error: 60.776928, mean_q: 9.639515\n",
      " 3228/6000: episode: 1368, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.452 [0.000, 32.560], loss: 1.135743, mean_squared_error: 63.721222, mean_q: 9.791143\n",
      " 3238/6000: episode: 1369, duration: 0.226s, episode steps: 10, steps per second: 44, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.400 [0.000, 3.000], mean observation: 1.403 [0.000, 19.676], loss: 1.920002, mean_squared_error: 60.148262, mean_q: 9.519130\n",
      " 3239/6000: episode: 1370, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.396 [0.000, 27.150], loss: 1.184671, mean_squared_error: 57.767700, mean_q: 9.430219\n",
      " 3244/6000: episode: 1371, duration: 0.073s, episode steps: 5, steps per second: 69, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [1.000, 2.000], mean observation: 1.471 [0.000, 26.390], loss: 2.001755, mean_squared_error: 56.968483, mean_q: 9.371431\n",
      " 3249/6000: episode: 1372, duration: 0.073s, episode steps: 5, steps per second: 68, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.400 [0.000, 3.000], mean observation: 0.908 [0.000, 19.765], loss: 2.475753, mean_squared_error: 56.336140, mean_q: 9.218871\n",
      " 3250/6000: episode: 1373, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.532 [0.000, 31.990], loss: 0.130693, mean_squared_error: 62.735622, mean_q: 9.698682\n",
      " 3253/6000: episode: 1374, duration: 0.053s, episode steps: 3, steps per second: 57, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 1.224 [0.000, 33.790], loss: 1.700390, mean_squared_error: 55.571995, mean_q: 9.280360\n",
      " 3254/6000: episode: 1375, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.214 [0.000, 22.370], loss: 0.098979, mean_squared_error: 61.450272, mean_q: 9.716772\n",
      " 3257/6000: episode: 1376, duration: 0.060s, episode steps: 3, steps per second: 50, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 0.924 [0.000, 14.271], loss: 1.388196, mean_squared_error: 62.064999, mean_q: 9.650823\n",
      " 3258/6000: episode: 1377, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.505 [0.000, 28.230], loss: 0.103695, mean_squared_error: 62.101601, mean_q: 9.725781\n",
      " 3259/6000: episode: 1378, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [0.000, 24.300], loss: 2.319522, mean_squared_error: 57.115425, mean_q: 9.176865\n",
      " 3264/6000: episode: 1379, duration: 0.073s, episode steps: 5, steps per second: 68, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.600 [1.000, 3.000], mean observation: 1.539 [0.000, 31.350], loss: 1.811574, mean_squared_error: 59.725258, mean_q: 9.524794\n",
      " 3265/6000: episode: 1380, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.175 [0.000, 15.688], loss: 3.868557, mean_squared_error: 65.887108, mean_q: 9.747471\n",
      " 3267/6000: episode: 1381, duration: 0.044s, episode steps: 2, steps per second: 45, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.930 [0.000, 36.950], loss: 0.957014, mean_squared_error: 59.628532, mean_q: 9.567852\n",
      " 3268/6000: episode: 1382, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.082 [0.000, 17.293], loss: 1.444242, mean_squared_error: 61.172073, mean_q: 9.398058\n",
      " 3278/6000: episode: 1383, duration: 0.155s, episode steps: 10, steps per second: 64, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.700 [1.000, 3.000], mean observation: 1.299 [0.000, 24.590], loss: 1.675552, mean_squared_error: 59.910412, mean_q: 9.521563\n",
      " 3280/6000: episode: 1384, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 0.855 [0.000, 15.560], loss: 1.549591, mean_squared_error: 62.720535, mean_q: 9.660511\n",
      " 3282/6000: episode: 1385, duration: 0.035s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.180 [0.000, 14.961], loss: 1.163746, mean_squared_error: 59.614899, mean_q: 9.495396\n",
      " 3283/6000: episode: 1386, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [0.000, 32.300], loss: 2.119691, mean_squared_error: 63.280556, mean_q: 9.685413\n",
      " 3287/6000: episode: 1387, duration: 0.064s, episode steps: 4, steps per second: 63, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [0.000, 3.000], mean observation: 0.664 [0.000, 9.000], loss: 0.813290, mean_squared_error: 61.448227, mean_q: 9.716624\n",
      " 3291/6000: episode: 1388, duration: 0.080s, episode steps: 4, steps per second: 50, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.252 [0.000, 14.000], loss: 2.151772, mean_squared_error: 59.039330, mean_q: 9.551347\n",
      " 3292/6000: episode: 1389, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.350 [0.000, 18.000], loss: 0.390265, mean_squared_error: 56.118378, mean_q: 9.797798\n",
      " 3293/6000: episode: 1390, duration: 0.038s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.648 [0.000, 35.480], loss: 0.082898, mean_squared_error: 63.377865, mean_q: 9.797928\n",
      " 3294/6000: episode: 1391, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.933 [0.000, 18.670], loss: 3.517086, mean_squared_error: 58.043304, mean_q: 9.333338\n",
      " 3295/6000: episode: 1392, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.492 [0.000, 28.120], loss: 0.243325, mean_squared_error: 59.578590, mean_q: 9.517707\n",
      " 3296/6000: episode: 1393, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.188 [0.000, 15.456], loss: 2.067259, mean_squared_error: 61.587673, mean_q: 9.747271\n",
      " 3297/6000: episode: 1394, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.416 [0.000, 26.090], loss: 0.247753, mean_squared_error: 60.836102, mean_q: 9.619936\n",
      " 3298/6000: episode: 1395, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.651 [0.000, 31.060], loss: 1.337849, mean_squared_error: 57.885349, mean_q: 9.361816\n",
      " 3300/6000: episode: 1396, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.582 [0.000, 30.280], loss: 0.934115, mean_squared_error: 58.984287, mean_q: 9.414391\n",
      " 3310/6000: episode: 1397, duration: 0.147s, episode steps: 10, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.100 [2.000, 3.000], mean observation: 1.753 [0.000, 25.200], loss: 0.956249, mean_squared_error: 60.830677, mean_q: 9.583176\n",
      " 3311/6000: episode: 1398, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.017 [0.000, 16.796], loss: 3.924169, mean_squared_error: 66.716049, mean_q: 9.749952\n",
      " 3312/6000: episode: 1399, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.089 [0.000, 15.000], loss: 1.377549, mean_squared_error: 67.022209, mean_q: 10.086101\n",
      " 3313/6000: episode: 1400, duration: 0.036s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.635 [0.000, 28.660], loss: 1.078665, mean_squared_error: 58.248688, mean_q: 9.541157\n",
      " 3314/6000: episode: 1401, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.560 [0.000, 19.274], loss: 3.062215, mean_squared_error: 58.557549, mean_q: 9.462633\n",
      " 3318/6000: episode: 1402, duration: 0.069s, episode steps: 4, steps per second: 58, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [2.000, 3.000], mean observation: 1.456 [0.000, 18.000], loss: 0.721894, mean_squared_error: 59.887276, mean_q: 9.628165\n",
      " 3319/6000: episode: 1403, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.589 [0.000, 39.150], loss: 0.153307, mean_squared_error: 59.772907, mean_q: 9.504961\n",
      " 3320/6000: episode: 1404, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.625 [0.000, 30.370], loss: 1.498446, mean_squared_error: 62.329094, mean_q: 9.602251\n",
      " 3321/6000: episode: 1405, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.341 [0.000, 18.283], loss: 2.159147, mean_squared_error: 54.104870, mean_q: 8.956094\n",
      " 3322/6000: episode: 1406, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.687 [0.000, 38.220], loss: 1.401238, mean_squared_error: 62.173561, mean_q: 9.558833\n",
      " 3323/6000: episode: 1407, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.299 [0.000, 18.846], loss: 2.097177, mean_squared_error: 65.161575, mean_q: 9.802456\n",
      " 3325/6000: episode: 1408, duration: 0.037s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.307 [0.000, 23.780], loss: 2.163291, mean_squared_error: 59.811111, mean_q: 9.680574\n",
      " 3326/6000: episode: 1409, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.619 [0.000, 35.060], loss: 0.224897, mean_squared_error: 58.221062, mean_q: 9.287102\n",
      " 3331/6000: episode: 1410, duration: 0.084s, episode steps: 5, steps per second: 59, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.800 [0.000, 1.000], mean observation: 1.357 [0.000, 16.944], loss: 1.123107, mean_squared_error: 61.449486, mean_q: 9.662787\n",
      " 3332/6000: episode: 1411, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.153 [0.000, 18.595], loss: 1.370517, mean_squared_error: 59.415298, mean_q: 9.497036\n",
      " 3333/6000: episode: 1412, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.402 [0.000, 22.090], loss: 0.174364, mean_squared_error: 57.160042, mean_q: 9.437058\n",
      " 3334/6000: episode: 1413, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.137 [0.000, 19.000], loss: 1.142651, mean_squared_error: 62.327496, mean_q: 9.747208\n",
      " 3344/6000: episode: 1414, duration: 0.160s, episode steps: 10, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.451 [0.000, 18.706], loss: 1.270207, mean_squared_error: 61.021362, mean_q: 9.536469\n",
      " 3346/6000: episode: 1415, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.601 [0.000, 36.940], loss: 1.311861, mean_squared_error: 59.343910, mean_q: 9.538191\n",
      " 3352/6000: episode: 1416, duration: 0.084s, episode steps: 6, steps per second: 71, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 0.833 [0.000, 3.000], mean observation: 1.558 [0.000, 19.410], loss: 0.753559, mean_squared_error: 61.632427, mean_q: 9.764529\n",
      " 3356/6000: episode: 1417, duration: 0.047s, episode steps: 4, steps per second: 85, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [0.000, 3.000], mean observation: 2.021 [0.000, 38.590], loss: 1.435465, mean_squared_error: 58.787354, mean_q: 9.413319\n",
      " 3357/6000: episode: 1418, duration: 0.021s, episode steps: 1, steps per second: 48, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.705 [0.000, 27.840], loss: 2.314031, mean_squared_error: 55.874634, mean_q: 9.201723\n",
      " 3367/6000: episode: 1419, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.900 [0.000, 3.000], mean observation: 1.799 [0.000, 38.920], loss: 0.733408, mean_squared_error: 62.732136, mean_q: 9.702180\n",
      " 3368/6000: episode: 1420, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.188 [0.000, 22.960], loss: 0.111513, mean_squared_error: 57.304413, mean_q: 9.390762\n",
      " 3376/6000: episode: 1421, duration: 0.145s, episode steps: 8, steps per second: 55, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.425 [0.000, 20.580], loss: 1.081199, mean_squared_error: 63.187531, mean_q: 9.773901\n",
      " 3379/6000: episode: 1422, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.660 [0.000, 35.760], loss: 1.465973, mean_squared_error: 57.416061, mean_q: 9.487191\n",
      " 3380/6000: episode: 1423, duration: 0.023s, episode steps: 1, steps per second: 43, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.498 [0.000, 29.280], loss: 3.191473, mean_squared_error: 61.467308, mean_q: 9.656789\n",
      " 3381/6000: episode: 1424, duration: 0.020s, episode steps: 1, steps per second: 51, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.049 [0.000, 15.000], loss: 1.224298, mean_squared_error: 61.913223, mean_q: 9.808331\n",
      " 3391/6000: episode: 1425, duration: 0.113s, episode steps: 10, steps per second: 88, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 0.400 [0.000, 3.000], mean observation: 1.617 [0.000, 33.970], loss: 1.187671, mean_squared_error: 58.348919, mean_q: 9.470823\n",
      " 3401/6000: episode: 1426, duration: 0.138s, episode steps: 10, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.800 [1.000, 3.000], mean observation: 1.472 [0.000, 18.000], loss: 1.029755, mean_squared_error: 60.207111, mean_q: 9.609266\n",
      " 3405/6000: episode: 1427, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 2.000], mean observation: 1.145 [0.000, 19.950], loss: 0.569667, mean_squared_error: 61.102989, mean_q: 9.612803\n",
      " 3406/6000: episode: 1428, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.814 [0.000, 13.514], loss: 1.053583, mean_squared_error: 63.652206, mean_q: 9.690403\n",
      " 3407/6000: episode: 1429, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.764 [0.000, 28.700], loss: 1.412115, mean_squared_error: 65.696327, mean_q: 9.898216\n",
      " 3408/6000: episode: 1430, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.344 [0.000, 19.430], loss: 1.272957, mean_squared_error: 60.182888, mean_q: 9.547838\n",
      " 3409/6000: episode: 1431, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.361 [0.000, 27.360], loss: 1.378451, mean_squared_error: 58.893173, mean_q: 9.453849\n",
      " 3410/6000: episode: 1432, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.075 [0.000, 39.860], loss: 1.204283, mean_squared_error: 67.700890, mean_q: 9.998238\n",
      " 3414/6000: episode: 1433, duration: 0.064s, episode steps: 4, steps per second: 62, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.003 [0.000, 14.000], loss: 0.873353, mean_squared_error: 59.185482, mean_q: 9.567089\n",
      " 3416/6000: episode: 1434, duration: 0.051s, episode steps: 2, steps per second: 39, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.578 [0.000, 24.420], loss: 0.727553, mean_squared_error: 56.936413, mean_q: 9.499956\n",
      " 3419/6000: episode: 1435, duration: 0.059s, episode steps: 3, steps per second: 51, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [0.000, 3.000], mean observation: 1.343 [0.000, 18.307], loss: 2.789243, mean_squared_error: 58.439953, mean_q: 9.335206\n",
      " 3421/6000: episode: 1436, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.694 [0.000, 31.540], loss: 1.271963, mean_squared_error: 61.541283, mean_q: 9.696582\n",
      " 3422/6000: episode: 1437, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.028 [0.000, 16.659], loss: 2.323101, mean_squared_error: 60.354359, mean_q: 9.492214\n",
      " 3423/6000: episode: 1438, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.659 [0.000, 9.000], loss: 3.878264, mean_squared_error: 59.210987, mean_q: 9.464642\n",
      " 3425/6000: episode: 1439, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.599 [0.000, 35.370], loss: 1.328195, mean_squared_error: 58.805382, mean_q: 9.493799\n",
      " 3433/6000: episode: 1440, duration: 0.109s, episode steps: 8, steps per second: 73, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.500 [1.000, 3.000], mean observation: 1.349 [0.000, 16.590], loss: 1.867951, mean_squared_error: 59.285378, mean_q: 9.509258\n",
      " 3434/6000: episode: 1441, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.499 [0.000, 35.970], loss: 4.234390, mean_squared_error: 63.098503, mean_q: 9.544958\n",
      " 3435/6000: episode: 1442, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.790 [0.000, 36.170], loss: 0.950755, mean_squared_error: 59.566578, mean_q: 9.507862\n",
      " 3439/6000: episode: 1443, duration: 0.059s, episode steps: 4, steps per second: 68, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [0.000, 3.000], mean observation: 1.615 [0.000, 18.000], loss: 0.776577, mean_squared_error: 61.025707, mean_q: 9.651807\n",
      " 3440/6000: episode: 1444, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.219 [0.000, 16.450], loss: 1.401767, mean_squared_error: 58.739845, mean_q: 9.442314\n",
      " 3442/6000: episode: 1445, duration: 0.055s, episode steps: 2, steps per second: 36, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.164 [0.000, 27.250], loss: 0.762349, mean_squared_error: 59.019562, mean_q: 9.422155\n",
      " 3446/6000: episode: 1446, duration: 0.097s, episode steps: 4, steps per second: 41, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 1.000], mean observation: 1.598 [0.000, 36.990], loss: 0.854434, mean_squared_error: 61.695801, mean_q: 9.622486\n",
      " 3449/6000: episode: 1447, duration: 0.076s, episode steps: 3, steps per second: 40, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.698 [0.000, 9.000], loss: 0.136016, mean_squared_error: 62.632244, mean_q: 9.693704\n",
      " 3455/6000: episode: 1448, duration: 0.079s, episode steps: 6, steps per second: 76, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 0.833 [0.000, 1.000], mean observation: 1.246 [0.000, 34.050], loss: 1.602529, mean_squared_error: 61.794376, mean_q: 9.644945\n",
      " 3456/6000: episode: 1449, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.788 [0.000, 33.510], loss: 0.197477, mean_squared_error: 57.572086, mean_q: 9.561466\n",
      " 3466/6000: episode: 1450, duration: 0.139s, episode steps: 10, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.700 [0.000, 2.000], mean observation: 1.409 [0.000, 17.130], loss: 1.042894, mean_squared_error: 61.939575, mean_q: 9.637354\n",
      " 3475/6000: episode: 1451, duration: 0.116s, episode steps: 9, steps per second: 77, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.222 [0.000, 3.000], mean observation: 1.120 [0.000, 15.993], loss: 1.250425, mean_squared_error: 60.959488, mean_q: 9.673778\n",
      " 3476/6000: episode: 1452, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.855 [0.000, 28.680], loss: 2.538093, mean_squared_error: 60.551575, mean_q: 9.583194\n",
      " 3477/6000: episode: 1453, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.059 [0.000, 16.140], loss: 1.222223, mean_squared_error: 65.446922, mean_q: 9.806111\n",
      " 3478/6000: episode: 1454, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.276 [0.000, 18.000], loss: 1.432062, mean_squared_error: 62.898865, mean_q: 9.726912\n",
      " 3481/6000: episode: 1455, duration: 0.052s, episode steps: 3, steps per second: 57, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.770 [0.000, 37.610], loss: 2.637741, mean_squared_error: 57.236572, mean_q: 9.246257\n",
      " 3482/6000: episode: 1456, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.993 [0.000, 19.374], loss: 1.335088, mean_squared_error: 58.472729, mean_q: 9.505449\n",
      " 3483/6000: episode: 1457, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.775 [0.000, 38.130], loss: 2.515210, mean_squared_error: 65.757828, mean_q: 9.815828\n",
      " 3484/6000: episode: 1458, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.213 [0.000, 24.650], loss: 0.221745, mean_squared_error: 59.030685, mean_q: 9.435223\n",
      " 3490/6000: episode: 1459, duration: 0.108s, episode steps: 6, steps per second: 55, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 0.167 [0.000, 1.000], mean observation: 1.434 [0.000, 24.020], loss: 1.341758, mean_squared_error: 59.248035, mean_q: 9.568143\n",
      " 3491/6000: episode: 1460, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.538 [0.000, 27.960], loss: 1.354471, mean_squared_error: 62.097748, mean_q: 9.604193\n",
      " 3501/6000: episode: 1461, duration: 0.143s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.800 [0.000, 2.000], mean observation: 1.252 [0.000, 14.000], loss: 1.134710, mean_squared_error: 61.353485, mean_q: 9.629521\n",
      " 3505/6000: episode: 1462, duration: 0.064s, episode steps: 4, steps per second: 62, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [2.000, 3.000], mean observation: 0.959 [0.000, 12.000], loss: 1.729253, mean_squared_error: 60.145653, mean_q: 9.551622\n",
      " 3506/6000: episode: 1463, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.208 [0.000, 15.180], loss: 0.253348, mean_squared_error: 58.178902, mean_q: 9.391061\n",
      " 3515/6000: episode: 1464, duration: 0.121s, episode steps: 9, steps per second: 74, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 2.111 [2.000, 3.000], mean observation: 1.191 [0.000, 18.410], loss: 1.670859, mean_squared_error: 59.739243, mean_q: 9.531730\n",
      " 3517/6000: episode: 1465, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.084 [0.000, 17.310], loss: 1.178815, mean_squared_error: 62.873398, mean_q: 9.631978\n",
      " 3518/6000: episode: 1466, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.289 [0.000, 25.070], loss: 2.666332, mean_squared_error: 58.453735, mean_q: 9.378397\n",
      " 3519/6000: episode: 1467, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.809 [0.000, 31.260], loss: 1.825674, mean_squared_error: 58.830379, mean_q: 9.344127\n",
      " 3520/6000: episode: 1468, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [0.000, 24.740], loss: 1.149221, mean_squared_error: 64.258652, mean_q: 9.757361\n",
      " 3523/6000: episode: 1469, duration: 0.050s, episode steps: 3, steps per second: 59, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [2.000, 3.000], mean observation: 1.203 [0.000, 16.000], loss: 1.816244, mean_squared_error: 59.297729, mean_q: 9.492864\n",
      " 3532/6000: episode: 1470, duration: 0.124s, episode steps: 9, steps per second: 73, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.889 [0.000, 1.000], mean observation: 1.463 [0.000, 27.550], loss: 1.118622, mean_squared_error: 60.830856, mean_q: 9.589266\n",
      " 3542/6000: episode: 1471, duration: 0.136s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.257 [0.000, 18.950], loss: 1.923404, mean_squared_error: 58.653114, mean_q: 9.422082\n",
      " 3543/6000: episode: 1472, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.307 [0.000, 21.660], loss: 2.093359, mean_squared_error: 59.059761, mean_q: 9.455114\n",
      " 3553/6000: episode: 1473, duration: 0.154s, episode steps: 10, steps per second: 65, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 2.600 [0.000, 3.000], mean observation: 1.073 [0.000, 21.230], loss: 1.202641, mean_squared_error: 62.190735, mean_q: 9.699193\n",
      " 3554/6000: episode: 1474, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.421 [0.000, 23.760], loss: 2.717432, mean_squared_error: 61.191475, mean_q: 9.656831\n",
      " 3564/6000: episode: 1475, duration: 0.134s, episode steps: 10, steps per second: 74, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 2.700 [0.000, 3.000], mean observation: 1.476 [0.000, 19.240], loss: 1.491315, mean_squared_error: 60.603783, mean_q: 9.606333\n",
      " 3565/6000: episode: 1476, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.770 [0.000, 33.630], loss: 1.025319, mean_squared_error: 61.714928, mean_q: 9.562324\n",
      " 3569/6000: episode: 1477, duration: 0.069s, episode steps: 4, steps per second: 58, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.649 [0.000, 18.770], loss: 2.719641, mean_squared_error: 59.095562, mean_q: 9.460508\n",
      " 3570/6000: episode: 1478, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.246 [0.000, 33.080], loss: 0.153627, mean_squared_error: 56.815132, mean_q: 9.335238\n",
      " 3575/6000: episode: 1479, duration: 0.073s, episode steps: 5, steps per second: 69, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [0.000, 3.000], mean observation: 1.490 [0.000, 25.280], loss: 1.128441, mean_squared_error: 60.455547, mean_q: 9.553276\n",
      " 3576/6000: episode: 1480, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.627 [0.000, 33.460], loss: 2.192618, mean_squared_error: 57.220818, mean_q: 9.309983\n",
      " 3577/6000: episode: 1481, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.372 [0.000, 18.457], loss: 0.137492, mean_squared_error: 62.490147, mean_q: 9.773296\n",
      " 3578/6000: episode: 1482, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.536 [0.000, 27.760], loss: 1.825477, mean_squared_error: 62.472931, mean_q: 9.705718\n",
      " 3584/6000: episode: 1483, duration: 0.085s, episode steps: 6, steps per second: 71, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.764 [0.000, 30.720], loss: 0.904597, mean_squared_error: 62.095577, mean_q: 9.636902\n",
      " 3586/6000: episode: 1484, duration: 0.045s, episode steps: 2, steps per second: 44, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.348 [0.000, 36.890], loss: 0.633443, mean_squared_error: 60.675636, mean_q: 9.571486\n",
      " 3587/6000: episode: 1485, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.051 [0.000, 16.000], loss: 0.109560, mean_squared_error: 59.843857, mean_q: 9.482597\n",
      " 3591/6000: episode: 1486, duration: 0.066s, episode steps: 4, steps per second: 60, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.750 [2.000, 3.000], mean observation: 0.949 [0.000, 10.648], loss: 1.078625, mean_squared_error: 60.457619, mean_q: 9.581346\n",
      " 3593/6000: episode: 1487, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.263 [0.000, 19.026], loss: 1.964799, mean_squared_error: 59.877380, mean_q: 9.472691\n",
      " 3600/6000: episode: 1488, duration: 0.103s, episode steps: 7, steps per second: 68, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.714 [0.000, 3.000], mean observation: 1.099 [0.000, 12.390], loss: 1.531795, mean_squared_error: 60.680073, mean_q: 9.655095\n",
      " 3601/6000: episode: 1489, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.896 [0.000, 37.570], loss: 2.372636, mean_squared_error: 53.658470, mean_q: 8.932145\n",
      " 3602/6000: episode: 1490, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.515 [0.000, 25.410], loss: 2.506253, mean_squared_error: 61.753380, mean_q: 9.693714\n",
      " 3604/6000: episode: 1491, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.456 [0.000, 31.830], loss: 3.001003, mean_squared_error: 56.664162, mean_q: 9.156364\n",
      " 3606/6000: episode: 1492, duration: 0.041s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.987 [0.000, 35.220], loss: 2.364266, mean_squared_error: 57.388275, mean_q: 9.315011\n",
      " 3607/6000: episode: 1493, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [0.000, 19.000], loss: 5.055393, mean_squared_error: 62.458775, mean_q: 9.460606\n",
      " 3608/6000: episode: 1494, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.507 [0.000, 28.970], loss: 0.138949, mean_squared_error: 62.599194, mean_q: 9.917799\n",
      " 3609/6000: episode: 1495, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.117 [0.000, 22.090], loss: 1.800261, mean_squared_error: 56.955154, mean_q: 9.548227\n",
      " 3610/6000: episode: 1496, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.808 [0.000, 37.640], loss: 0.190828, mean_squared_error: 57.209534, mean_q: 9.463418\n",
      " 3611/6000: episode: 1497, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.028 [0.000, 19.280], loss: 0.259615, mean_squared_error: 59.662216, mean_q: 9.647819\n",
      " 3618/6000: episode: 1498, duration: 0.103s, episode steps: 7, steps per second: 68, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.143 [0.000, 3.000], mean observation: 1.880 [0.000, 37.530], loss: 0.820791, mean_squared_error: 60.401226, mean_q: 9.612596\n",
      " 3619/6000: episode: 1499, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.350 [0.000, 36.240], loss: 0.291824, mean_squared_error: 63.134682, mean_q: 9.748686\n",
      " 3620/6000: episode: 1500, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.077 [0.000, 18.490], loss: 1.036490, mean_squared_error: 61.079594, mean_q: 9.585768\n",
      " 3621/6000: episode: 1501, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.738 [0.000, 35.650], loss: 0.132951, mean_squared_error: 64.648170, mean_q: 9.809816\n",
      " 3622/6000: episode: 1502, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.819 [0.000, 39.430], loss: 0.163992, mean_squared_error: 60.550056, mean_q: 9.603680\n",
      " 3626/6000: episode: 1503, duration: 0.074s, episode steps: 4, steps per second: 54, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.750 [2.000, 3.000], mean observation: 0.940 [0.000, 10.737], loss: 1.129657, mean_squared_error: 61.988178, mean_q: 9.761688\n",
      " 3627/6000: episode: 1504, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.017 [0.000, 16.796], loss: 0.133276, mean_squared_error: 62.288040, mean_q: 9.772137\n",
      " 3637/6000: episode: 1505, duration: 0.144s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 2.000], mean observation: 1.567 [0.000, 32.250], loss: 1.133026, mean_squared_error: 61.148338, mean_q: 9.615499\n",
      " 3638/6000: episode: 1506, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.834 [0.000, 14.000], loss: 0.943017, mean_squared_error: 62.887142, mean_q: 9.672983\n",
      " 3642/6000: episode: 1507, duration: 0.058s, episode steps: 4, steps per second: 69, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [0.000, 3.000], mean observation: 1.228 [0.000, 23.230], loss: 1.799988, mean_squared_error: 59.591881, mean_q: 9.431201\n",
      " 3643/6000: episode: 1508, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.113 [0.000, 15.878], loss: 2.222981, mean_squared_error: 57.416656, mean_q: 9.423828\n",
      " 3648/6000: episode: 1509, duration: 0.077s, episode steps: 5, steps per second: 65, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.879 [0.000, 38.720], loss: 1.511280, mean_squared_error: 60.643585, mean_q: 9.634338\n",
      " 3649/6000: episode: 1510, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.650 [0.000, 27.470], loss: 1.430610, mean_squared_error: 64.554306, mean_q: 9.796358\n",
      " 3651/6000: episode: 1511, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 0.961 [0.000, 16.380], loss: 0.642840, mean_squared_error: 58.806217, mean_q: 9.516237\n",
      " 3652/6000: episode: 1512, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.398 [0.000, 25.860], loss: 1.039114, mean_squared_error: 62.064247, mean_q: 9.738411\n",
      " 3653/6000: episode: 1513, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.037 [0.000, 18.160], loss: 1.493966, mean_squared_error: 56.722809, mean_q: 9.262463\n",
      " 3654/6000: episode: 1514, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.890 [0.000, 12.310], loss: 0.937261, mean_squared_error: 60.720963, mean_q: 9.520136\n",
      " 3655/6000: episode: 1515, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.081 [0.000, 16.879], loss: 2.442187, mean_squared_error: 64.727180, mean_q: 9.921822\n",
      " 3656/6000: episode: 1516, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.691 [0.000, 31.150], loss: 1.194513, mean_squared_error: 59.061321, mean_q: 9.422897\n",
      " 3657/6000: episode: 1517, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.706 [0.000, 32.520], loss: 1.418661, mean_squared_error: 64.127014, mean_q: 9.799263\n",
      " 3659/6000: episode: 1518, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 0.992 [0.000, 23.340], loss: 1.141253, mean_squared_error: 61.086472, mean_q: 9.741766\n",
      " 3660/6000: episode: 1519, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.896 [0.000, 14.000], loss: 0.370974, mean_squared_error: 53.048611, mean_q: 9.211843\n",
      " 3661/6000: episode: 1520, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.151 [0.000, 23.370], loss: 2.009378, mean_squared_error: 60.013569, mean_q: 9.535205\n",
      " 3662/6000: episode: 1521, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.689 [0.000, 10.360], loss: 0.108755, mean_squared_error: 60.216400, mean_q: 9.646153\n",
      " 3667/6000: episode: 1522, duration: 0.073s, episode steps: 5, steps per second: 69, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [0.000, 3.000], mean observation: 0.975 [0.000, 24.430], loss: 1.203141, mean_squared_error: 63.463825, mean_q: 9.750465\n",
      " 3668/6000: episode: 1523, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.391 [0.000, 18.390], loss: 1.355286, mean_squared_error: 53.780952, mean_q: 9.072409\n",
      " 3669/6000: episode: 1524, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.242 [0.000, 15.803], loss: 1.412715, mean_squared_error: 60.761009, mean_q: 9.611640\n",
      " 3679/6000: episode: 1525, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 3.000], mean observation: 1.300 [0.000, 27.780], loss: 1.176164, mean_squared_error: 60.575844, mean_q: 9.569710\n",
      " 3689/6000: episode: 1526, duration: 0.143s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.400 [1.000, 3.000], mean observation: 1.118 [0.000, 15.471], loss: 0.906908, mean_squared_error: 60.061230, mean_q: 9.546409\n",
      " 3695/6000: episode: 1527, duration: 0.081s, episode steps: 6, steps per second: 74, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 0.667 [0.000, 3.000], mean observation: 1.611 [0.000, 28.040], loss: 1.908895, mean_squared_error: 60.060062, mean_q: 9.566209\n",
      " 3705/6000: episode: 1528, duration: 0.124s, episode steps: 10, steps per second: 81, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.400 [1.000, 2.000], mean observation: 1.140 [0.000, 16.225], loss: 1.870909, mean_squared_error: 59.038769, mean_q: 9.415413\n",
      " 3715/6000: episode: 1529, duration: 0.129s, episode steps: 10, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.900 [2.000, 3.000], mean observation: 1.886 [0.000, 39.950], loss: 0.932779, mean_squared_error: 61.131939, mean_q: 9.624215\n",
      " 3716/6000: episode: 1530, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.216 [0.000, 20.300], loss: 0.224671, mean_squared_error: 59.607750, mean_q: 9.617510\n",
      " 3717/6000: episode: 1531, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [0.000, 19.000], loss: 0.297383, mean_squared_error: 55.293209, mean_q: 9.189774\n",
      " 3721/6000: episode: 1532, duration: 0.083s, episode steps: 4, steps per second: 48, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.500 [0.000, 2.000], mean observation: 1.106 [0.000, 14.117], loss: 1.751056, mean_squared_error: 60.976746, mean_q: 9.601986\n",
      " 3725/6000: episode: 1533, duration: 0.064s, episode steps: 4, steps per second: 63, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.722 [0.000, 31.540], loss: 1.642246, mean_squared_error: 60.688004, mean_q: 9.559436\n",
      " 3732/6000: episode: 1534, duration: 0.105s, episode steps: 7, steps per second: 67, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.714 [0.000, 2.000], mean observation: 1.425 [0.000, 17.590], loss: 1.368375, mean_squared_error: 61.234749, mean_q: 9.617799\n",
      " 3733/6000: episode: 1535, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.835 [0.000, 13.000], loss: 2.221248, mean_squared_error: 63.201492, mean_q: 9.714162\n",
      " 3734/6000: episode: 1536, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.470 [0.000, 27.670], loss: 1.804088, mean_squared_error: 57.594856, mean_q: 9.207815\n",
      " 3735/6000: episode: 1537, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.959 [0.000, 34.810], loss: 0.928319, mean_squared_error: 63.061516, mean_q: 9.728420\n",
      " 3738/6000: episode: 1538, duration: 0.046s, episode steps: 3, steps per second: 66, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.191 [0.000, 15.405], loss: 2.569109, mean_squared_error: 62.649506, mean_q: 9.661267\n",
      " 3741/6000: episode: 1539, duration: 0.049s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.675 [0.000, 21.440], loss: 1.940778, mean_squared_error: 59.742107, mean_q: 9.435329\n",
      " 3742/6000: episode: 1540, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.528 [0.000, 7.000], loss: 1.293101, mean_squared_error: 58.089333, mean_q: 9.427216\n",
      " 3744/6000: episode: 1541, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.501 [0.000, 18.990], loss: 0.598430, mean_squared_error: 59.780586, mean_q: 9.475950\n",
      " 3752/6000: episode: 1542, duration: 0.107s, episode steps: 8, steps per second: 75, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.750 [0.000, 3.000], mean observation: 1.409 [0.000, 25.380], loss: 1.647761, mean_squared_error: 59.264961, mean_q: 9.493719\n",
      " 3754/6000: episode: 1543, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.329 [0.000, 18.340], loss: 0.837104, mean_squared_error: 59.782852, mean_q: 9.665098\n",
      " 3762/6000: episode: 1544, duration: 0.105s, episode steps: 8, steps per second: 76, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.375 [0.000, 3.000], mean observation: 1.313 [0.000, 14.000], loss: 1.901686, mean_squared_error: 59.600082, mean_q: 9.523459\n",
      " 3766/6000: episode: 1545, duration: 0.066s, episode steps: 4, steps per second: 60, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 0.629 [0.000, 8.240], loss: 1.908741, mean_squared_error: 58.848450, mean_q: 9.386978\n",
      " 3767/6000: episode: 1546, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.472 [0.000, 26.900], loss: 1.553481, mean_squared_error: 59.327770, mean_q: 9.391438\n",
      " 3769/6000: episode: 1547, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.757 [0.000, 31.550], loss: 1.261215, mean_squared_error: 58.066643, mean_q: 9.403458\n",
      " 3772/6000: episode: 1548, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.286 [0.000, 16.919], loss: 1.630239, mean_squared_error: 59.230991, mean_q: 9.413924\n",
      " 3773/6000: episode: 1549, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.192 [0.000, 16.621], loss: 0.861765, mean_squared_error: 57.302666, mean_q: 9.228966\n",
      " 3779/6000: episode: 1550, duration: 0.089s, episode steps: 6, steps per second: 67, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.833 [0.000, 3.000], mean observation: 1.172 [0.000, 18.000], loss: 0.804139, mean_squared_error: 61.421741, mean_q: 9.578483\n",
      " 3783/6000: episode: 1551, duration: 0.061s, episode steps: 4, steps per second: 66, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 2.000], mean observation: 1.639 [0.000, 28.320], loss: 1.894134, mean_squared_error: 60.369286, mean_q: 9.523758\n",
      " 3785/6000: episode: 1552, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.155 [0.000, 19.116], loss: 0.148835, mean_squared_error: 61.680035, mean_q: 9.784008\n",
      " 3786/6000: episode: 1553, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.528 [0.000, 7.000], loss: 4.768482, mean_squared_error: 54.035095, mean_q: 9.137308\n",
      " 3790/6000: episode: 1554, duration: 0.068s, episode steps: 4, steps per second: 59, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 2.000], mean observation: 1.529 [0.000, 28.540], loss: 1.450498, mean_squared_error: 60.706367, mean_q: 9.699121\n",
      " 3792/6000: episode: 1555, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.398 [0.000, 30.330], loss: 1.107885, mean_squared_error: 59.320450, mean_q: 9.538570\n",
      " 3799/6000: episode: 1556, duration: 0.092s, episode steps: 7, steps per second: 76, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.259 [0.000, 26.470], loss: 0.962662, mean_squared_error: 60.965706, mean_q: 9.574554\n",
      " 3803/6000: episode: 1557, duration: 0.064s, episode steps: 4, steps per second: 63, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.418 [0.000, 25.390], loss: 0.753959, mean_squared_error: 61.976162, mean_q: 9.729074\n",
      " 3804/6000: episode: 1558, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.623 [0.000, 18.297], loss: 2.716000, mean_squared_error: 60.152321, mean_q: 9.694622\n",
      " 3806/6000: episode: 1559, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.859 [0.000, 32.780], loss: 0.188432, mean_squared_error: 64.626999, mean_q: 9.883709\n",
      " 3807/6000: episode: 1560, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.510 [0.000, 26.600], loss: 4.034030, mean_squared_error: 66.331459, mean_q: 9.903044\n",
      " 3809/6000: episode: 1561, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 0.786 [0.000, 15.769], loss: 0.778166, mean_squared_error: 60.405151, mean_q: 9.582823\n",
      " 3810/6000: episode: 1562, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.592 [0.000, 31.900], loss: 1.336083, mean_squared_error: 61.561165, mean_q: 9.640283\n",
      " 3811/6000: episode: 1563, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.817 [0.000, 9.522], loss: 0.186999, mean_squared_error: 59.719830, mean_q: 9.621418\n",
      " 3812/6000: episode: 1564, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.840 [0.000, 10.910], loss: 0.132566, mean_squared_error: 60.387783, mean_q: 9.709539\n",
      " 3813/6000: episode: 1565, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.128 [0.000, 15.158], loss: 0.251925, mean_squared_error: 58.903927, mean_q: 9.431788\n",
      " 3814/6000: episode: 1566, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.219 [0.000, 19.438], loss: 2.493868, mean_squared_error: 71.007690, mean_q: 10.217279\n",
      " 3815/6000: episode: 1567, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.711 [0.000, 21.600], loss: 0.128329, mean_squared_error: 64.780670, mean_q: 9.865194\n",
      " 3816/6000: episode: 1568, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.462 [0.000, 23.950], loss: 1.227288, mean_squared_error: 60.496014, mean_q: 9.449681\n",
      " 3826/6000: episode: 1569, duration: 0.141s, episode steps: 10, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [0.000, 2.000], mean observation: 1.517 [0.000, 28.080], loss: 1.320011, mean_squared_error: 60.542500, mean_q: 9.625634\n",
      " 3827/6000: episode: 1570, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.231 [0.000, 16.178], loss: 2.192966, mean_squared_error: 61.417175, mean_q: 9.545913\n",
      " 3830/6000: episode: 1571, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.667 [2.000, 3.000], mean observation: 1.133 [0.000, 15.760], loss: 1.143709, mean_squared_error: 59.538830, mean_q: 9.387672\n",
      " 3831/6000: episode: 1572, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.678 [0.000, 27.810], loss: 1.490231, mean_squared_error: 55.973404, mean_q: 9.349766\n",
      " 3832/6000: episode: 1573, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.965 [0.000, 38.290], loss: 0.945040, mean_squared_error: 57.120354, mean_q: 9.356040\n",
      " 3834/6000: episode: 1574, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.286 [0.000, 18.680], loss: 0.650898, mean_squared_error: 58.850616, mean_q: 9.648635\n",
      " 3835/6000: episode: 1575, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.218 [0.000, 16.654], loss: 0.128738, mean_squared_error: 64.123886, mean_q: 9.968708\n",
      " 3837/6000: episode: 1576, duration: 0.044s, episode steps: 2, steps per second: 46, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.660 [0.000, 30.760], loss: 0.811182, mean_squared_error: 59.520916, mean_q: 9.752474\n",
      " 3842/6000: episode: 1577, duration: 0.077s, episode steps: 5, steps per second: 65, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.200 [2.000, 3.000], mean observation: 1.546 [0.000, 30.750], loss: 1.781677, mean_squared_error: 60.003490, mean_q: 9.583995\n",
      " 3852/6000: episode: 1578, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.587 [0.000, 27.580], loss: 0.981348, mean_squared_error: 60.759632, mean_q: 9.624327\n",
      " 3860/6000: episode: 1579, duration: 0.146s, episode steps: 8, steps per second: 55, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.625 [0.000, 2.000], mean observation: 0.967 [0.000, 18.906], loss: 1.284941, mean_squared_error: 60.970566, mean_q: 9.600379\n",
      " 3870/6000: episode: 1580, duration: 0.285s, episode steps: 10, steps per second: 35, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.600 [1.000, 2.000], mean observation: 1.973 [0.000, 38.740], loss: 1.175578, mean_squared_error: 61.766529, mean_q: 9.653682\n",
      " 3871/6000: episode: 1581, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.613 [0.000, 23.360], loss: 1.482008, mean_squared_error: 57.358383, mean_q: 9.560884\n",
      " 3874/6000: episode: 1582, duration: 0.133s, episode steps: 3, steps per second: 23, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.188 [0.000, 18.380], loss: 0.590981, mean_squared_error: 62.007755, mean_q: 9.743098\n",
      " 3877/6000: episode: 1583, duration: 0.069s, episode steps: 3, steps per second: 44, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.022 [0.000, 15.259], loss: 1.701422, mean_squared_error: 56.539433, mean_q: 9.315735\n",
      " 3880/6000: episode: 1584, duration: 0.069s, episode steps: 3, steps per second: 44, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [2.000, 3.000], mean observation: 1.578 [0.000, 34.480], loss: 2.340629, mean_squared_error: 60.485535, mean_q: 9.509002\n",
      " 3881/6000: episode: 1585, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.613 [0.000, 39.310], loss: 1.479114, mean_squared_error: 62.526169, mean_q: 9.700809\n",
      " 3891/6000: episode: 1586, duration: 0.239s, episode steps: 10, steps per second: 42, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 1.000], mean observation: 1.951 [0.000, 37.680], loss: 1.861435, mean_squared_error: 59.282814, mean_q: 9.554140\n",
      " 3892/6000: episode: 1587, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.147 [0.000, 19.000], loss: 1.389454, mean_squared_error: 55.912529, mean_q: 9.258142\n",
      " 3893/6000: episode: 1588, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.484 [0.000, 29.970], loss: 1.413212, mean_squared_error: 62.504150, mean_q: 9.602381\n",
      " 3894/6000: episode: 1589, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.147 [0.000, 38.640], loss: 1.443293, mean_squared_error: 67.381210, mean_q: 9.884725\n",
      " 3901/6000: episode: 1590, duration: 0.168s, episode steps: 7, steps per second: 42, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.857 [1.000, 2.000], mean observation: 1.195 [0.000, 19.380], loss: 1.251171, mean_squared_error: 60.241039, mean_q: 9.610726\n",
      " 3904/6000: episode: 1591, duration: 0.079s, episode steps: 3, steps per second: 38, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.673 [0.000, 36.120], loss: 0.104978, mean_squared_error: 63.991714, mean_q: 9.795011\n",
      " 3909/6000: episode: 1592, duration: 0.108s, episode steps: 5, steps per second: 46, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.400 [1.000, 3.000], mean observation: 1.225 [0.000, 21.970], loss: 1.595587, mean_squared_error: 58.524071, mean_q: 9.464572\n",
      " 3910/6000: episode: 1593, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.924 [0.000, 31.670], loss: 2.745450, mean_squared_error: 65.136467, mean_q: 9.854486\n",
      " 3915/6000: episode: 1594, duration: 0.107s, episode steps: 5, steps per second: 47, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.400 [0.000, 3.000], mean observation: 1.656 [0.000, 29.300], loss: 1.310729, mean_squared_error: 59.691994, mean_q: 9.450502\n",
      " 3917/6000: episode: 1595, duration: 0.055s, episode steps: 2, steps per second: 37, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.458 [0.000, 26.690], loss: 1.320107, mean_squared_error: 63.368561, mean_q: 9.751840\n",
      " 3918/6000: episode: 1596, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.066 [0.000, 14.114], loss: 0.270249, mean_squared_error: 59.111473, mean_q: 9.489620\n",
      " 3921/6000: episode: 1597, duration: 0.077s, episode steps: 3, steps per second: 39, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.828 [0.000, 36.500], loss: 1.355092, mean_squared_error: 59.285130, mean_q: 9.539748\n",
      " 3922/6000: episode: 1598, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.106 [0.000, 18.791], loss: 1.134089, mean_squared_error: 65.167610, mean_q: 9.802607\n",
      " 3932/6000: episode: 1599, duration: 0.151s, episode steps: 10, steps per second: 66, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.352 [0.000, 19.000], loss: 1.202216, mean_squared_error: 62.026123, mean_q: 9.671904\n",
      " 3935/6000: episode: 1600, duration: 0.046s, episode steps: 3, steps per second: 65, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.280 [0.000, 19.819], loss: 0.998972, mean_squared_error: 60.987759, mean_q: 9.564864\n",
      " 3936/6000: episode: 1601, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.268 [0.000, 18.869], loss: 2.713110, mean_squared_error: 65.989624, mean_q: 9.886909\n",
      " 3937/6000: episode: 1602, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.820 [0.000, 24.880], loss: 0.362962, mean_squared_error: 57.321190, mean_q: 9.429292\n",
      " 3938/6000: episode: 1603, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.554 [0.000, 39.450], loss: 2.583189, mean_squared_error: 64.314362, mean_q: 9.760183\n",
      " 3939/6000: episode: 1604, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.823 [0.000, 12.862], loss: 0.712774, mean_squared_error: 60.203693, mean_q: 9.660935\n",
      " 3949/6000: episode: 1605, duration: 0.138s, episode steps: 10, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 2.000], mean observation: 1.650 [0.000, 38.970], loss: 1.697177, mean_squared_error: 58.529472, mean_q: 9.498676\n",
      " 3951/6000: episode: 1606, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.522 [0.000, 19.666], loss: 0.764053, mean_squared_error: 61.911121, mean_q: 9.760874\n",
      " 3952/6000: episode: 1607, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.224 [0.000, 17.428], loss: 0.263586, mean_squared_error: 57.171135, mean_q: 9.482843\n",
      " 3954/6000: episode: 1608, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.418 [0.000, 25.590], loss: 1.221260, mean_squared_error: 61.010262, mean_q: 9.584933\n",
      " 3961/6000: episode: 1609, duration: 0.093s, episode steps: 7, steps per second: 75, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 0.714 [0.000, 2.000], mean observation: 1.451 [0.000, 33.670], loss: 0.615506, mean_squared_error: 60.469463, mean_q: 9.566366\n",
      " 3962/6000: episode: 1610, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.473 [0.000, 30.280], loss: 1.218158, mean_squared_error: 58.636246, mean_q: 9.550985\n",
      " 3963/6000: episode: 1611, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.224 [0.000, 33.790], loss: 1.630112, mean_squared_error: 54.603413, mean_q: 9.207794\n",
      " 3973/6000: episode: 1612, duration: 0.149s, episode steps: 10, steps per second: 67, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.522 [0.000, 21.370], loss: 2.078394, mean_squared_error: 58.495502, mean_q: 9.479870\n",
      " 3974/6000: episode: 1613, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.353 [0.000, 27.650], loss: 2.088310, mean_squared_error: 52.383137, mean_q: 9.073528\n",
      " 3984/6000: episode: 1614, duration: 0.142s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.500 [0.000, 2.000], mean observation: 1.226 [0.000, 18.540], loss: 1.302150, mean_squared_error: 60.069775, mean_q: 9.597209\n",
      " 3985/6000: episode: 1615, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.137 [0.000, 27.910], loss: 1.092587, mean_squared_error: 60.896576, mean_q: 9.655775\n",
      " 3987/6000: episode: 1616, duration: 0.052s, episode steps: 2, steps per second: 38, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.072 [0.000, 15.952], loss: 1.799623, mean_squared_error: 57.012825, mean_q: 9.287196\n",
      " 3997/6000: episode: 1617, duration: 0.128s, episode steps: 10, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.100 [0.000, 3.000], mean observation: 1.131 [0.000, 16.838], loss: 1.325011, mean_squared_error: 59.507488, mean_q: 9.502752\n",
      " 4001/6000: episode: 1618, duration: 0.063s, episode steps: 4, steps per second: 63, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.608 [0.000, 37.150], loss: 0.696351, mean_squared_error: 59.271484, mean_q: 9.529042\n",
      " 4002/6000: episode: 1619, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.566 [0.000, 36.520], loss: 1.537502, mean_squared_error: 58.571800, mean_q: 9.328833\n",
      " 4003/6000: episode: 1620, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.723 [0.000, 9.125], loss: 0.121981, mean_squared_error: 61.237595, mean_q: 9.705334\n",
      " 4005/6000: episode: 1621, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.532 [0.000, 39.040], loss: 2.553426, mean_squared_error: 56.088951, mean_q: 9.308662\n",
      " 4015/6000: episode: 1622, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.113 [0.000, 14.770], loss: 1.680882, mean_squared_error: 59.831287, mean_q: 9.518122\n",
      " 4019/6000: episode: 1623, duration: 0.062s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 3.000], mean observation: 1.683 [0.000, 30.990], loss: 1.524627, mean_squared_error: 59.949631, mean_q: 9.499648\n",
      " 4022/6000: episode: 1624, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.547 [0.000, 18.000], loss: 2.387965, mean_squared_error: 60.494633, mean_q: 9.579115\n",
      " 4023/6000: episode: 1625, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.830 [0.000, 34.180], loss: 2.365398, mean_squared_error: 60.596664, mean_q: 9.651909\n",
      " 4024/6000: episode: 1626, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.151 [0.000, 15.093], loss: 1.247657, mean_squared_error: 59.193523, mean_q: 9.528468\n",
      " 4025/6000: episode: 1627, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.089 [0.000, 16.820], loss: 1.288638, mean_squared_error: 60.212357, mean_q: 9.600037\n",
      " 4026/6000: episode: 1628, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.476 [0.000, 20.570], loss: 0.146435, mean_squared_error: 61.326828, mean_q: 9.547510\n",
      " 4027/6000: episode: 1629, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.970 [0.000, 36.890], loss: 1.575637, mean_squared_error: 60.984940, mean_q: 9.552345\n",
      " 4028/6000: episode: 1630, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.617 [0.000, 23.830], loss: 0.434418, mean_squared_error: 53.108814, mean_q: 9.107336\n",
      " 4031/6000: episode: 1631, duration: 0.054s, episode steps: 3, steps per second: 55, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.337 [0.000, 20.870], loss: 2.082819, mean_squared_error: 59.540100, mean_q: 9.442981\n",
      " 4032/6000: episode: 1632, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.828 [0.000, 19.170], loss: 2.636837, mean_squared_error: 58.779160, mean_q: 9.573947\n",
      " 4033/6000: episode: 1633, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.317 [0.000, 17.183], loss: 1.282030, mean_squared_error: 58.894047, mean_q: 9.747512\n",
      " 4035/6000: episode: 1634, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.474 [0.000, 37.490], loss: 0.939215, mean_squared_error: 59.082413, mean_q: 9.563717\n",
      " 4036/6000: episode: 1635, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.559 [0.000, 38.970], loss: 2.153490, mean_squared_error: 58.614105, mean_q: 9.468586\n",
      " 4037/6000: episode: 1636, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.649 [0.000, 30.480], loss: 3.506823, mean_squared_error: 64.589752, mean_q: 9.712506\n",
      " 4047/6000: episode: 1637, duration: 0.161s, episode steps: 10, steps per second: 62, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 2.700 [0.000, 3.000], mean observation: 1.357 [0.000, 16.944], loss: 0.764645, mean_squared_error: 62.239269, mean_q: 9.671280\n",
      " 4048/6000: episode: 1638, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.174 [0.000, 18.177], loss: 1.107050, mean_squared_error: 54.981762, mean_q: 9.215736\n",
      " 4049/6000: episode: 1639, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.653 [0.000, 33.240], loss: 1.281210, mean_squared_error: 64.276588, mean_q: 9.683133\n",
      " 4051/6000: episode: 1640, duration: 0.117s, episode steps: 2, steps per second: 17, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.741 [0.000, 38.410], loss: 0.209738, mean_squared_error: 58.397400, mean_q: 9.417263\n",
      " 4054/6000: episode: 1641, duration: 0.104s, episode steps: 3, steps per second: 29, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.382 [0.000, 36.180], loss: 2.001803, mean_squared_error: 58.807178, mean_q: 9.391296\n",
      " 4057/6000: episode: 1642, duration: 0.080s, episode steps: 3, steps per second: 37, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [1.000, 3.000], mean observation: 1.546 [0.000, 32.430], loss: 2.804055, mean_squared_error: 60.799347, mean_q: 9.501203\n",
      " 4060/6000: episode: 1643, duration: 0.066s, episode steps: 3, steps per second: 46, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.308 [0.000, 18.692], loss: 1.082810, mean_squared_error: 57.767426, mean_q: 9.446366\n",
      " 4061/6000: episode: 1644, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.129 [0.000, 25.380], loss: 1.464912, mean_squared_error: 58.571011, mean_q: 9.465349\n",
      " 4062/6000: episode: 1645, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.242 [0.000, 19.000], loss: 0.348496, mean_squared_error: 55.697773, mean_q: 9.306402\n",
      " 4063/6000: episode: 1646, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.841 [0.000, 39.990], loss: 0.102882, mean_squared_error: 60.985909, mean_q: 9.593459\n",
      " 4064/6000: episode: 1647, duration: 0.064s, episode steps: 1, steps per second: 16, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.251 [0.000, 19.000], loss: 0.418340, mean_squared_error: 53.410057, mean_q: 9.264454\n",
      " 4065/6000: episode: 1648, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.085 [0.000, 14.784], loss: 1.167443, mean_squared_error: 55.302364, mean_q: 9.226133\n",
      " 4067/6000: episode: 1649, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.214 [0.000, 22.370], loss: 1.878079, mean_squared_error: 59.229359, mean_q: 9.355261\n",
      " 4068/6000: episode: 1650, duration: 0.074s, episode steps: 1, steps per second: 14, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.063 [0.000, 17.467], loss: 1.161966, mean_squared_error: 57.626083, mean_q: 9.470667\n",
      " 4078/6000: episode: 1651, duration: 0.294s, episode steps: 10, steps per second: 34, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.400 [0.000, 3.000], mean observation: 1.120 [0.000, 17.370], loss: 1.197194, mean_squared_error: 61.176537, mean_q: 9.625702\n",
      " 4080/6000: episode: 1652, duration: 0.044s, episode steps: 2, steps per second: 45, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.316 [0.000, 18.899], loss: 2.611965, mean_squared_error: 61.826313, mean_q: 9.718433\n",
      " 4082/6000: episode: 1653, duration: 0.049s, episode steps: 2, steps per second: 41, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.069 [0.000, 16.566], loss: 0.171051, mean_squared_error: 60.381779, mean_q: 9.556952\n",
      " 4083/6000: episode: 1654, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.529 [0.000, 38.840], loss: 1.620177, mean_squared_error: 57.119358, mean_q: 9.254676\n",
      " 4084/6000: episode: 1655, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.278 [0.000, 17.818], loss: 0.261292, mean_squared_error: 59.251930, mean_q: 9.501742\n",
      " 4085/6000: episode: 1656, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.014 [0.000, 16.000], loss: 1.354515, mean_squared_error: 57.978611, mean_q: 9.515544\n",
      " 4086/6000: episode: 1657, duration: 0.038s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.001 [0.000, 32.830], loss: 1.550242, mean_squared_error: 62.310085, mean_q: 9.779047\n",
      " 4087/6000: episode: 1658, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.789 [0.000, 29.000], loss: 4.078701, mean_squared_error: 55.478355, mean_q: 8.946722\n",
      " 4088/6000: episode: 1659, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.235 [0.000, 20.310], loss: 2.008719, mean_squared_error: 57.406265, mean_q: 9.413570\n",
      " 4098/6000: episode: 1660, duration: 0.299s, episode steps: 10, steps per second: 33, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.800 [1.000, 3.000], mean observation: 0.527 [0.000, 7.000], loss: 0.704806, mean_squared_error: 61.004517, mean_q: 9.568136\n",
      " 4108/6000: episode: 1661, duration: 0.134s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.491 [0.000, 21.730], loss: 1.657565, mean_squared_error: 58.191048, mean_q: 9.448252\n",
      " 4109/6000: episode: 1662, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.711 [0.000, 30.930], loss: 0.368977, mean_squared_error: 58.672791, mean_q: 9.473336\n",
      " 4110/6000: episode: 1663, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.458 [0.000, 19.000], loss: 1.226080, mean_squared_error: 58.859894, mean_q: 9.622684\n",
      " 4111/6000: episode: 1664, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.363 [0.000, 31.520], loss: 2.272544, mean_squared_error: 57.566139, mean_q: 9.371199\n",
      " 4114/6000: episode: 1665, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [1.000, 3.000], mean observation: 1.380 [0.000, 22.880], loss: 1.182723, mean_squared_error: 61.535248, mean_q: 9.598416\n",
      " 4116/6000: episode: 1666, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.723 [0.000, 38.620], loss: 1.374701, mean_squared_error: 60.698257, mean_q: 9.622197\n",
      " 4117/6000: episode: 1667, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.631 [0.000, 19.889], loss: 2.042405, mean_squared_error: 58.784447, mean_q: 9.406363\n",
      " 4121/6000: episode: 1668, duration: 0.116s, episode steps: 4, steps per second: 34, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [0.000, 3.000], mean observation: 1.243 [0.000, 19.000], loss: 1.654584, mean_squared_error: 61.021820, mean_q: 9.521604\n",
      " 4124/6000: episode: 1669, duration: 0.068s, episode steps: 3, steps per second: 44, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.130 [0.000, 17.187], loss: 1.018340, mean_squared_error: 59.305714, mean_q: 9.479439\n",
      " 4125/6000: episode: 1670, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.855 [0.000, 14.253], loss: 2.408289, mean_squared_error: 58.065529, mean_q: 9.442177\n",
      " 4126/6000: episode: 1671, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.089 [0.000, 12.200], loss: 3.936079, mean_squared_error: 65.828201, mean_q: 9.799894\n",
      " 4129/6000: episode: 1672, duration: 0.067s, episode steps: 3, steps per second: 45, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.237 [0.000, 16.399], loss: 1.276070, mean_squared_error: 58.027729, mean_q: 9.415210\n",
      " 4132/6000: episode: 1673, duration: 0.058s, episode steps: 3, steps per second: 51, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.785 [0.000, 29.430], loss: 2.022791, mean_squared_error: 59.128399, mean_q: 9.471314\n",
      " 4133/6000: episode: 1674, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.581 [0.000, 21.100], loss: 1.707362, mean_squared_error: 50.208725, mean_q: 8.927679\n",
      " 4143/6000: episode: 1675, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.100 [2.000, 3.000], mean observation: 0.528 [0.000, 7.000], loss: 1.270551, mean_squared_error: 59.499786, mean_q: 9.543534\n",
      " 4146/6000: episode: 1676, duration: 0.049s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 1.389 [0.000, 35.230], loss: 1.633143, mean_squared_error: 59.323833, mean_q: 9.368209\n",
      " 4147/6000: episode: 1677, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.917 [0.000, 37.770], loss: 1.661625, mean_squared_error: 66.126190, mean_q: 9.833431\n",
      " 4149/6000: episode: 1678, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.180 [0.000, 14.961], loss: 1.840645, mean_squared_error: 63.206863, mean_q: 9.773945\n",
      " 4155/6000: episode: 1679, duration: 0.081s, episode steps: 6, steps per second: 74, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.000 [0.000, 3.000], mean observation: 0.884 [0.000, 16.040], loss: 1.667135, mean_squared_error: 60.312683, mean_q: 9.637341\n",
      " 4156/6000: episode: 1680, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.126 [0.000, 26.160], loss: 3.182956, mean_squared_error: 62.714165, mean_q: 9.514288\n",
      " 4158/6000: episode: 1681, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.053 [0.000, 19.308], loss: 2.557901, mean_squared_error: 52.239040, mean_q: 9.167140\n",
      " 4159/6000: episode: 1682, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.284 [0.000, 16.010], loss: 2.868550, mean_squared_error: 61.443382, mean_q: 9.628441\n",
      " 4169/6000: episode: 1683, duration: 0.146s, episode steps: 10, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 2.000], mean observation: 1.490 [0.000, 20.730], loss: 0.989601, mean_squared_error: 60.255013, mean_q: 9.572345\n",
      " 4170/6000: episode: 1684, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.137 [0.000, 19.000], loss: 0.224883, mean_squared_error: 59.046329, mean_q: 9.575543\n",
      " 4172/6000: episode: 1685, duration: 0.037s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.622 [0.000, 39.430], loss: 0.853794, mean_squared_error: 56.960175, mean_q: 9.434175\n",
      " 4173/6000: episode: 1686, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.378 [0.000, 26.750], loss: 2.364726, mean_squared_error: 56.180397, mean_q: 9.300835\n",
      " 4175/6000: episode: 1687, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.952 [0.000, 13.000], loss: 0.926293, mean_squared_error: 58.761608, mean_q: 9.626152\n",
      " 4177/6000: episode: 1688, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 0.979 [0.000, 19.399], loss: 2.300417, mean_squared_error: 55.924019, mean_q: 9.288414\n",
      " 4179/6000: episode: 1689, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 0.977 [0.000, 17.726], loss: 1.463687, mean_squared_error: 58.412933, mean_q: 9.433086\n",
      " 4182/6000: episode: 1690, duration: 0.051s, episode steps: 3, steps per second: 59, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 0.841 [0.000, 17.250], loss: 1.958293, mean_squared_error: 57.340626, mean_q: 9.347294\n",
      " 4185/6000: episode: 1691, duration: 0.052s, episode steps: 3, steps per second: 57, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.348 [0.000, 20.830], loss: 0.614014, mean_squared_error: 57.282032, mean_q: 9.588645\n",
      " 4186/6000: episode: 1692, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.651 [0.000, 37.960], loss: 1.551694, mean_squared_error: 60.030708, mean_q: 9.588694\n",
      " 4191/6000: episode: 1693, duration: 0.071s, episode steps: 5, steps per second: 70, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.800 [0.000, 1.000], mean observation: 0.891 [0.000, 13.590], loss: 1.417259, mean_squared_error: 59.190582, mean_q: 9.537983\n",
      " 4201/6000: episode: 1694, duration: 0.135s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.366 [0.000, 22.200], loss: 0.875387, mean_squared_error: 60.111614, mean_q: 9.584093\n",
      " 4202/6000: episode: 1695, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.269 [0.000, 27.790], loss: 1.341589, mean_squared_error: 60.716480, mean_q: 9.550909\n",
      " 4203/6000: episode: 1696, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.507 [0.000, 24.230], loss: 4.701492, mean_squared_error: 59.112652, mean_q: 9.560221\n",
      " 4204/6000: episode: 1697, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.963 [0.000, 13.777], loss: 3.772334, mean_squared_error: 64.214622, mean_q: 9.735165\n",
      " 4205/6000: episode: 1698, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.055 [0.000, 16.854], loss: 0.878352, mean_squared_error: 60.210808, mean_q: 9.519438\n",
      " 4209/6000: episode: 1699, duration: 0.059s, episode steps: 4, steps per second: 68, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [1.000, 3.000], mean observation: 1.711 [0.000, 32.860], loss: 0.946434, mean_squared_error: 59.404030, mean_q: 9.515247\n",
      " 4210/6000: episode: 1700, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.341 [0.000, 18.283], loss: 2.527601, mean_squared_error: 55.162010, mean_q: 9.244478\n",
      " 4211/6000: episode: 1701, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.114 [0.000, 18.998], loss: 0.120269, mean_squared_error: 60.915749, mean_q: 9.643651\n",
      " 4221/6000: episode: 1702, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.100 [1.000, 2.000], mean observation: 1.101 [0.000, 19.493], loss: 1.342568, mean_squared_error: 60.829285, mean_q: 9.603570\n",
      " 4222/6000: episode: 1703, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.814 [0.000, 13.514], loss: 2.350978, mean_squared_error: 64.858810, mean_q: 9.793876\n",
      " 4223/6000: episode: 1704, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.821 [0.000, 39.600], loss: 0.198781, mean_squared_error: 59.895245, mean_q: 9.507345\n",
      " 4225/6000: episode: 1705, duration: 0.040s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.182 [0.000, 18.638], loss: 1.281080, mean_squared_error: 58.496334, mean_q: 9.280797\n",
      " 4226/6000: episode: 1706, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.738 [0.000, 32.470], loss: 0.824514, mean_squared_error: 62.692795, mean_q: 9.727294\n",
      " 4228/6000: episode: 1707, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.342 [0.000, 16.000], loss: 2.880159, mean_squared_error: 56.988792, mean_q: 9.401545\n",
      " 4229/6000: episode: 1708, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.613 [0.000, 39.310], loss: 0.101496, mean_squared_error: 60.277260, mean_q: 9.580466\n",
      " 4231/6000: episode: 1709, duration: 0.037s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.328 [0.000, 22.180], loss: 0.603080, mean_squared_error: 60.447834, mean_q: 9.669329\n",
      " 4232/6000: episode: 1710, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.706 [0.000, 8.021], loss: 1.320189, mean_squared_error: 61.322060, mean_q: 9.696409\n",
      " 4234/6000: episode: 1711, duration: 0.037s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.248 [0.000, 18.890], loss: 1.720705, mean_squared_error: 58.958000, mean_q: 9.423546\n",
      " 4239/6000: episode: 1712, duration: 0.084s, episode steps: 5, steps per second: 60, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.800 [2.000, 3.000], mean observation: 1.193 [0.000, 16.016], loss: 1.879304, mean_squared_error: 60.413918, mean_q: 9.487620\n",
      " 4240/6000: episode: 1713, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.902 [0.000, 13.141], loss: 0.808064, mean_squared_error: 58.384666, mean_q: 9.431740\n",
      " 4241/6000: episode: 1714, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.993 [0.000, 14.700], loss: 2.077041, mean_squared_error: 64.449127, mean_q: 9.674221\n",
      " 4242/6000: episode: 1715, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.630 [0.000, 33.880], loss: 1.763397, mean_squared_error: 62.149075, mean_q: 9.683918\n",
      " 4244/6000: episode: 1716, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.468 [0.000, 23.080], loss: 2.287811, mean_squared_error: 62.008652, mean_q: 9.715515\n",
      " 4246/6000: episode: 1717, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.382 [0.000, 20.980], loss: 2.100713, mean_squared_error: 54.527840, mean_q: 9.363197\n",
      " 4250/6000: episode: 1718, duration: 0.062s, episode steps: 4, steps per second: 65, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 3.000], mean observation: 1.437 [0.000, 19.267], loss: 1.207758, mean_squared_error: 57.922485, mean_q: 9.329221\n",
      " 4251/6000: episode: 1719, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.153 [0.000, 18.230], loss: 1.376869, mean_squared_error: 54.727848, mean_q: 9.250122\n",
      " 4252/6000: episode: 1720, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.158 [0.000, 19.716], loss: 1.452935, mean_squared_error: 57.011452, mean_q: 9.220911\n",
      " 4261/6000: episode: 1721, duration: 0.124s, episode steps: 9, steps per second: 73, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.778 [1.000, 3.000], mean observation: 1.490 [0.000, 27.340], loss: 1.344733, mean_squared_error: 61.630718, mean_q: 9.649961\n",
      " 4264/6000: episode: 1722, duration: 0.047s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 0.872 [0.000, 17.000], loss: 1.543168, mean_squared_error: 59.028442, mean_q: 9.435939\n",
      " 4266/6000: episode: 1723, duration: 0.037s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.213 [0.000, 16.121], loss: 1.783061, mean_squared_error: 61.659405, mean_q: 9.666190\n",
      " 4273/6000: episode: 1724, duration: 0.103s, episode steps: 7, steps per second: 68, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.143 [0.000, 3.000], mean observation: 1.149 [0.000, 15.177], loss: 1.665729, mean_squared_error: 60.232048, mean_q: 9.522151\n",
      " 4274/6000: episode: 1725, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.876 [0.000, 37.320], loss: 2.440540, mean_squared_error: 57.502762, mean_q: 9.550993\n",
      " 4276/6000: episode: 1726, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.566 [0.000, 33.340], loss: 0.842716, mean_squared_error: 61.435932, mean_q: 9.813504\n",
      " 4277/6000: episode: 1727, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.400 [0.000, 31.560], loss: 0.205707, mean_squared_error: 61.115170, mean_q: 9.693797\n",
      " 4279/6000: episode: 1728, duration: 0.051s, episode steps: 2, steps per second: 39, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 0.866 [0.000, 11.153], loss: 0.112783, mean_squared_error: 58.866814, mean_q: 9.516197\n",
      " 4288/6000: episode: 1729, duration: 0.152s, episode steps: 9, steps per second: 59, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.889 [0.000, 3.000], mean observation: 1.645 [0.000, 22.750], loss: 1.375651, mean_squared_error: 60.094524, mean_q: 9.559818\n",
      " 4289/6000: episode: 1730, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.757 [0.000, 31.550], loss: 1.920232, mean_squared_error: 63.061172, mean_q: 9.854036\n",
      " 4290/6000: episode: 1731, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.700 [0.000, 19.610], loss: 2.608795, mean_squared_error: 57.156868, mean_q: 9.322128\n",
      " 4291/6000: episode: 1732, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.760 [0.000, 29.110], loss: 0.932887, mean_squared_error: 63.558193, mean_q: 9.832916\n",
      " 4292/6000: episode: 1733, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.478 [0.000, 28.030], loss: 2.178908, mean_squared_error: 63.760750, mean_q: 9.727030\n",
      " 4293/6000: episode: 1734, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.807 [0.000, 36.530], loss: 2.238666, mean_squared_error: 63.262466, mean_q: 9.660454\n",
      " 4294/6000: episode: 1735, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.299 [0.000, 18.846], loss: 0.285479, mean_squared_error: 56.332817, mean_q: 9.197349\n",
      " 4295/6000: episode: 1736, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.478 [0.000, 19.086], loss: 2.208713, mean_squared_error: 58.987164, mean_q: 9.298254\n",
      " 4296/6000: episode: 1737, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.464 [0.000, 33.720], loss: 1.480436, mean_squared_error: 60.185188, mean_q: 9.532839\n",
      " 4299/6000: episode: 1738, duration: 0.069s, episode steps: 3, steps per second: 43, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [1.000, 2.000], mean observation: 1.078 [0.000, 19.000], loss: 0.815743, mean_squared_error: 64.067719, mean_q: 9.787854\n",
      " 4309/6000: episode: 1739, duration: 0.131s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.700 [1.000, 3.000], mean observation: 1.421 [0.000, 17.542], loss: 1.555597, mean_squared_error: 58.430195, mean_q: 9.428518\n",
      " 4311/6000: episode: 1740, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.404 [0.000, 36.610], loss: 2.273390, mean_squared_error: 60.701645, mean_q: 9.540022\n",
      " 4312/6000: episode: 1741, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.409 [0.000, 31.640], loss: 0.160659, mean_squared_error: 60.232521, mean_q: 9.502014\n",
      " 4313/6000: episode: 1742, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.898 [0.000, 36.620], loss: 1.559724, mean_squared_error: 57.931229, mean_q: 9.434540\n",
      " 4315/6000: episode: 1743, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.290 [0.000, 36.910], loss: 1.579547, mean_squared_error: 58.882027, mean_q: 9.445499\n",
      " 4317/6000: episode: 1744, duration: 0.037s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.680 [0.000, 22.290], loss: 1.199528, mean_squared_error: 59.740894, mean_q: 9.476292\n",
      " 4319/6000: episode: 1745, duration: 0.041s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.987 [0.000, 35.500], loss: 0.951051, mean_squared_error: 58.711361, mean_q: 9.566128\n",
      " 4320/6000: episode: 1746, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.899 [0.000, 39.030], loss: 1.038313, mean_squared_error: 56.619637, mean_q: 9.240503\n",
      " 4323/6000: episode: 1747, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.557 [0.000, 18.678], loss: 2.054667, mean_squared_error: 57.880909, mean_q: 9.362102\n",
      " 4326/6000: episode: 1748, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.284 [0.000, 22.010], loss: 1.316402, mean_squared_error: 60.897053, mean_q: 9.608500\n",
      " 4328/6000: episode: 1749, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.443 [0.000, 22.940], loss: 0.687935, mean_squared_error: 61.978653, mean_q: 9.809345\n",
      " 4329/6000: episode: 1750, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.365 [0.000, 22.160], loss: 1.157952, mean_squared_error: 61.028069, mean_q: 9.612478\n",
      " 4331/6000: episode: 1751, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.305 [0.000, 31.000], loss: 1.774948, mean_squared_error: 58.741302, mean_q: 9.575437\n",
      " 4332/6000: episode: 1752, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.416 [0.000, 26.090], loss: 2.420962, mean_squared_error: 64.132889, mean_q: 9.913961\n",
      " 4334/6000: episode: 1753, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.505 [0.000, 24.410], loss: 1.648246, mean_squared_error: 59.500504, mean_q: 9.688669\n",
      " 4335/6000: episode: 1754, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.676 [0.000, 30.960], loss: 0.285886, mean_squared_error: 62.019150, mean_q: 9.800537\n",
      " 4337/6000: episode: 1755, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.342 [0.000, 29.680], loss: 1.589795, mean_squared_error: 58.665901, mean_q: 9.367182\n",
      " 4338/6000: episode: 1756, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.493 [0.000, 32.610], loss: 1.806617, mean_squared_error: 52.784058, mean_q: 9.014147\n",
      " 4339/6000: episode: 1757, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.499 [0.000, 19.097], loss: 1.327964, mean_squared_error: 55.145348, mean_q: 9.177464\n",
      " 4340/6000: episode: 1758, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.960 [0.000, 32.280], loss: 3.631863, mean_squared_error: 61.603458, mean_q: 9.439579\n",
      " 4341/6000: episode: 1759, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.049 [0.000, 15.000], loss: 1.499017, mean_squared_error: 60.898403, mean_q: 9.575184\n",
      " 4344/6000: episode: 1760, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 2.000], mean observation: 0.961 [0.000, 12.813], loss: 0.134217, mean_squared_error: 62.675537, mean_q: 9.843066\n",
      " 4345/6000: episode: 1761, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.106 [0.000, 18.791], loss: 0.085444, mean_squared_error: 58.377735, mean_q: 9.447643\n",
      " 4346/6000: episode: 1762, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.975 [0.000, 18.588], loss: 0.337061, mean_squared_error: 56.496983, mean_q: 9.482858\n",
      " 4347/6000: episode: 1763, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.077 [0.000, 14.000], loss: 2.622240, mean_squared_error: 61.608818, mean_q: 9.660391\n",
      " 4349/6000: episode: 1764, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.388 [0.000, 23.840], loss: 0.736756, mean_squared_error: 63.339390, mean_q: 9.757072\n",
      " 4350/6000: episode: 1765, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.340 [0.000, 30.300], loss: 3.486764, mean_squared_error: 56.874054, mean_q: 9.189574\n",
      " 4352/6000: episode: 1766, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.378 [0.000, 26.750], loss: 0.900361, mean_squared_error: 60.378906, mean_q: 9.645655\n",
      " 4353/6000: episode: 1767, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.782 [0.000, 37.370], loss: 0.622006, mean_squared_error: 62.750309, mean_q: 9.874109\n",
      " 4354/6000: episode: 1768, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.220 [0.000, 17.220], loss: 2.399006, mean_squared_error: 55.822304, mean_q: 9.146717\n",
      " 4356/6000: episode: 1769, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.744 [0.000, 35.430], loss: 0.265592, mean_squared_error: 58.373241, mean_q: 9.512371\n",
      " 4357/6000: episode: 1770, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.775 [0.000, 38.130], loss: 1.158104, mean_squared_error: 58.218277, mean_q: 9.529168\n",
      " 4358/6000: episode: 1771, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.259 [0.000, 19.710], loss: 0.101113, mean_squared_error: 60.792946, mean_q: 9.778419\n",
      " 4359/6000: episode: 1772, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.845 [0.000, 12.691], loss: 1.241003, mean_squared_error: 58.379551, mean_q: 9.356579\n",
      " 4369/6000: episode: 1773, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.400 [1.000, 3.000], mean observation: 1.166 [0.000, 16.761], loss: 2.075036, mean_squared_error: 57.185467, mean_q: 9.308239\n",
      " 4370/6000: episode: 1774, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.224 [0.000, 16.860], loss: 0.153625, mean_squared_error: 60.539932, mean_q: 9.644520\n",
      " 4371/6000: episode: 1775, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.100 [0.000, 15.826], loss: 1.282312, mean_squared_error: 63.912724, mean_q: 9.624603\n",
      " 4373/6000: episode: 1776, duration: 0.037s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.125 [0.000, 26.340], loss: 2.474237, mean_squared_error: 61.452114, mean_q: 9.545868\n",
      " 4374/6000: episode: 1777, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.841 [0.000, 17.250], loss: 3.080720, mean_squared_error: 59.137924, mean_q: 9.354950\n",
      " 4376/6000: episode: 1778, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.171 [0.000, 23.240], loss: 0.768602, mean_squared_error: 57.014603, mean_q: 9.527096\n",
      " 4377/6000: episode: 1779, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.346 [0.000, 24.370], loss: 2.463719, mean_squared_error: 62.162304, mean_q: 9.744786\n",
      " 4379/6000: episode: 1780, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.527 [0.000, 34.440], loss: 0.693209, mean_squared_error: 63.313690, mean_q: 9.754442\n",
      " 4385/6000: episode: 1781, duration: 0.083s, episode steps: 6, steps per second: 72, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.167 [2.000, 3.000], mean observation: 1.639 [0.000, 32.090], loss: 1.872735, mean_squared_error: 58.888821, mean_q: 9.598328\n",
      " 4388/6000: episode: 1782, duration: 0.052s, episode steps: 3, steps per second: 57, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.641 [0.000, 26.000], loss: 2.991204, mean_squared_error: 53.592579, mean_q: 9.169738\n",
      " 4389/6000: episode: 1783, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.636 [0.000, 26.610], loss: 1.276539, mean_squared_error: 58.545345, mean_q: 9.582656\n",
      " 4390/6000: episode: 1784, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.275 [0.000, 15.000], loss: 1.197272, mean_squared_error: 60.466881, mean_q: 9.573278\n",
      " 4391/6000: episode: 1785, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.992 [0.000, 28.170], loss: 0.136317, mean_squared_error: 66.291473, mean_q: 10.065764\n",
      " 4393/6000: episode: 1786, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 0.689 [0.000, 10.360], loss: 0.993144, mean_squared_error: 61.667248, mean_q: 9.700544\n",
      " 4394/6000: episode: 1787, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.764 [0.000, 31.670], loss: 0.087931, mean_squared_error: 62.827080, mean_q: 9.691309\n",
      " 4395/6000: episode: 1788, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.828 [0.000, 34.650], loss: 1.340726, mean_squared_error: 63.051456, mean_q: 9.722000\n",
      " 4397/6000: episode: 1789, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.206 [0.000, 22.710], loss: 2.413686, mean_squared_error: 58.507835, mean_q: 9.399143\n",
      " 4398/6000: episode: 1790, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.788 [0.000, 36.240], loss: 0.934690, mean_squared_error: 55.630219, mean_q: 9.152105\n",
      " 4399/6000: episode: 1791, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.046 [0.000, 15.840], loss: 0.974891, mean_squared_error: 61.497406, mean_q: 9.632016\n",
      " 4408/6000: episode: 1792, duration: 0.142s, episode steps: 9, steps per second: 64, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.889 [0.000, 1.000], mean observation: 0.838 [0.000, 12.000], loss: 0.745889, mean_squared_error: 61.400555, mean_q: 9.673637\n",
      " 4410/6000: episode: 1793, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 0.864 [0.000, 13.423], loss: 0.091861, mean_squared_error: 65.387131, mean_q: 9.881429\n",
      " 4411/6000: episode: 1794, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.888 [0.000, 13.366], loss: 0.735324, mean_squared_error: 58.792961, mean_q: 9.377963\n",
      " 4413/6000: episode: 1795, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.612 [0.000, 19.232], loss: 2.287286, mean_squared_error: 57.630356, mean_q: 9.304029\n",
      " 4414/6000: episode: 1796, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.631 [0.000, 29.830], loss: 0.183398, mean_squared_error: 63.836124, mean_q: 9.773453\n",
      " 4416/6000: episode: 1797, duration: 0.042s, episode steps: 2, steps per second: 47, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 0.921 [0.000, 19.000], loss: 1.894262, mean_squared_error: 58.369797, mean_q: 9.367498\n",
      " 4417/6000: episode: 1798, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.947 [0.000, 39.330], loss: 2.520844, mean_squared_error: 59.859222, mean_q: 9.674267\n",
      " 4419/6000: episode: 1799, duration: 0.041s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.639 [0.000, 28.320], loss: 2.604981, mean_squared_error: 59.988949, mean_q: 9.551958\n",
      " 4423/6000: episode: 1800, duration: 0.069s, episode steps: 4, steps per second: 58, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.750 [2.000, 3.000], mean observation: 1.252 [0.000, 18.000], loss: 1.519190, mean_squared_error: 58.493481, mean_q: 9.516398\n",
      " 4424/6000: episode: 1801, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.593 [0.000, 37.430], loss: 1.467024, mean_squared_error: 58.327335, mean_q: 9.427464\n",
      " 4427/6000: episode: 1802, duration: 0.054s, episode steps: 3, steps per second: 56, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.087 [0.000, 18.250], loss: 1.367495, mean_squared_error: 60.101635, mean_q: 9.601699\n",
      " 4428/6000: episode: 1803, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.478 [0.000, 23.440], loss: 2.522212, mean_squared_error: 53.956497, mean_q: 8.996178\n",
      " 4438/6000: episode: 1804, duration: 0.126s, episode steps: 10, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.800 [0.000, 2.000], mean observation: 1.311 [0.000, 14.783], loss: 1.660260, mean_squared_error: 58.926197, mean_q: 9.478331\n",
      " 4439/6000: episode: 1805, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.112 [0.000, 39.510], loss: 0.316755, mean_squared_error: 61.094471, mean_q: 9.718552\n",
      " 4444/6000: episode: 1806, duration: 0.080s, episode steps: 5, steps per second: 63, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.800 [2.000, 3.000], mean observation: 1.729 [0.000, 31.260], loss: 1.308220, mean_squared_error: 61.342766, mean_q: 9.661974\n",
      " 4446/6000: episode: 1807, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.273 [0.000, 18.000], loss: 1.586320, mean_squared_error: 58.798149, mean_q: 9.495589\n",
      " 4448/6000: episode: 1808, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.250 [0.000, 22.060], loss: 2.240154, mean_squared_error: 58.584698, mean_q: 9.464382\n",
      " 4449/6000: episode: 1809, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.842 [0.000, 35.320], loss: 2.722921, mean_squared_error: 64.414627, mean_q: 9.730097\n",
      " 4450/6000: episode: 1810, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.031 [0.000, 14.000], loss: 1.242405, mean_squared_error: 61.150299, mean_q: 9.491577\n",
      " 4451/6000: episode: 1811, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [0.000, 37.040], loss: 1.537550, mean_squared_error: 55.844517, mean_q: 9.396835\n",
      " 4453/6000: episode: 1812, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.057 [0.000, 18.679], loss: 1.209841, mean_squared_error: 59.678207, mean_q: 9.545681\n",
      " 4457/6000: episode: 1813, duration: 0.062s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.750 [2.000, 3.000], mean observation: 1.337 [0.000, 15.900], loss: 1.128288, mean_squared_error: 60.148876, mean_q: 9.563054\n",
      " 4458/6000: episode: 1814, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.112 [0.000, 18.000], loss: 1.575917, mean_squared_error: 65.728378, mean_q: 9.992065\n",
      " 4460/6000: episode: 1815, duration: 0.043s, episode steps: 2, steps per second: 47, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.926 [0.000, 37.410], loss: 1.167658, mean_squared_error: 57.571281, mean_q: 9.392134\n",
      " 4462/6000: episode: 1816, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.707 [0.000, 21.650], loss: 0.236653, mean_squared_error: 58.921345, mean_q: 9.416374\n",
      " 4469/6000: episode: 1817, duration: 0.093s, episode steps: 7, steps per second: 75, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 2.857 [2.000, 3.000], mean observation: 1.587 [0.000, 33.220], loss: 0.802177, mean_squared_error: 62.865307, mean_q: 9.681865\n",
      " 4470/6000: episode: 1818, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.393 [0.000, 23.300], loss: 1.203218, mean_squared_error: 59.834625, mean_q: 9.729239\n",
      " 4475/6000: episode: 1819, duration: 0.077s, episode steps: 5, steps per second: 65, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.200 [0.000, 1.000], mean observation: 1.092 [0.000, 18.360], loss: 0.615051, mean_squared_error: 60.936317, mean_q: 9.604133\n",
      " 4476/6000: episode: 1820, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.302 [0.000, 21.740], loss: 3.731051, mean_squared_error: 61.505726, mean_q: 9.639478\n",
      " 4485/6000: episode: 1821, duration: 0.119s, episode steps: 9, steps per second: 75, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.444 [0.000, 2.000], mean observation: 0.869 [0.000, 17.000], loss: 1.170360, mean_squared_error: 61.191406, mean_q: 9.605729\n",
      " 4486/6000: episode: 1822, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [0.000, 28.710], loss: 0.168118, mean_squared_error: 63.442390, mean_q: 9.881847\n",
      " 4487/6000: episode: 1823, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.474 [0.000, 37.490], loss: 0.162429, mean_squared_error: 66.242966, mean_q: 9.927390\n",
      " 4488/6000: episode: 1824, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.229 [0.000, 19.668], loss: 0.193294, mean_squared_error: 62.427624, mean_q: 9.727278\n",
      " 4489/6000: episode: 1825, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.840 [0.000, 13.000], loss: 2.578944, mean_squared_error: 58.469456, mean_q: 9.547836\n",
      " 4496/6000: episode: 1826, duration: 0.098s, episode steps: 7, steps per second: 71, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 2.286 [0.000, 3.000], mean observation: 1.154 [0.000, 18.490], loss: 1.490010, mean_squared_error: 58.374825, mean_q: 9.360186\n",
      " 4505/6000: episode: 1827, duration: 0.115s, episode steps: 9, steps per second: 78, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.111 [1.000, 2.000], mean observation: 1.049 [0.000, 16.680], loss: 0.952479, mean_squared_error: 62.517036, mean_q: 9.703604\n",
      " 4515/6000: episode: 1828, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.600 [1.000, 3.000], mean observation: 1.348 [0.000, 34.530], loss: 1.131450, mean_squared_error: 61.195740, mean_q: 9.609780\n",
      " 4516/6000: episode: 1829, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.346 [0.000, 17.850], loss: 1.290008, mean_squared_error: 54.506157, mean_q: 9.061357\n",
      " 4519/6000: episode: 1830, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.312 [0.000, 20.290], loss: 1.158043, mean_squared_error: 59.956665, mean_q: 9.524376\n",
      " 4520/6000: episode: 1831, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.114 [0.000, 15.932], loss: 1.389016, mean_squared_error: 63.174606, mean_q: 9.878602\n",
      " 4522/6000: episode: 1832, duration: 0.037s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.575 [0.000, 24.480], loss: 1.808072, mean_squared_error: 62.092461, mean_q: 9.708340\n",
      " 4525/6000: episode: 1833, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.282 [0.000, 16.477], loss: 2.463400, mean_squared_error: 57.100567, mean_q: 9.301755\n",
      " 4526/6000: episode: 1834, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.742 [0.000, 30.110], loss: 0.915260, mean_squared_error: 63.674557, mean_q: 9.651275\n",
      " 4528/6000: episode: 1835, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.486 [0.000, 38.400], loss: 0.813296, mean_squared_error: 62.042919, mean_q: 9.647245\n",
      " 4529/6000: episode: 1836, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.965 [0.000, 38.290], loss: 0.239932, mean_squared_error: 61.028568, mean_q: 9.542602\n",
      " 4530/6000: episode: 1837, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.542 [0.000, 30.650], loss: 1.681460, mean_squared_error: 63.434578, mean_q: 9.654405\n",
      " 4531/6000: episode: 1838, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.854 [0.000, 14.523], loss: 1.450731, mean_squared_error: 57.517178, mean_q: 9.376205\n",
      " 4537/6000: episode: 1839, duration: 0.088s, episode steps: 6, steps per second: 68, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 0.500 [0.000, 2.000], mean observation: 1.148 [0.000, 19.750], loss: 1.420600, mean_squared_error: 61.266743, mean_q: 9.617236\n",
      " 4538/6000: episode: 1840, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.922 [0.000, 35.290], loss: 1.714195, mean_squared_error: 67.480682, mean_q: 9.916349\n",
      " 4539/6000: episode: 1841, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.215 [0.000, 25.950], loss: 1.616896, mean_squared_error: 63.865883, mean_q: 9.729867\n",
      " 4540/6000: episode: 1842, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.934 [0.000, 12.496], loss: 1.192736, mean_squared_error: 58.709633, mean_q: 9.537846\n",
      " 4541/6000: episode: 1843, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.029 [0.000, 36.810], loss: 0.907391, mean_squared_error: 61.843307, mean_q: 9.750850\n",
      " 4544/6000: episode: 1844, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 0.753 [0.000, 12.164], loss: 0.452977, mean_squared_error: 62.420017, mean_q: 9.678735\n",
      " 4554/6000: episode: 1845, duration: 0.160s, episode steps: 10, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.800 [1.000, 2.000], mean observation: 1.669 [0.000, 31.590], loss: 1.456939, mean_squared_error: 59.784138, mean_q: 9.460021\n",
      " 4555/6000: episode: 1846, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.990 [0.000, 18.000], loss: 2.742839, mean_squared_error: 61.762878, mean_q: 9.537238\n",
      " 4560/6000: episode: 1847, duration: 0.091s, episode steps: 5, steps per second: 55, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.800 [0.000, 1.000], mean observation: 1.117 [0.000, 24.730], loss: 1.232713, mean_squared_error: 59.900574, mean_q: 9.545275\n",
      " 4561/6000: episode: 1848, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.008 [0.000, 16.631], loss: 1.639618, mean_squared_error: 59.228489, mean_q: 9.505186\n",
      " 4563/6000: episode: 1849, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.242 [0.000, 21.420], loss: 1.810810, mean_squared_error: 59.083813, mean_q: 9.401068\n",
      " 4568/6000: episode: 1850, duration: 0.085s, episode steps: 5, steps per second: 59, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.400 [1.000, 3.000], mean observation: 1.098 [0.000, 12.790], loss: 1.076762, mean_squared_error: 61.115898, mean_q: 9.597659\n",
      " 4570/6000: episode: 1851, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.129 [0.000, 18.250], loss: 0.079205, mean_squared_error: 64.955505, mean_q: 9.828193\n",
      " 4571/6000: episode: 1852, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.076 [0.000, 16.244], loss: 3.171291, mean_squared_error: 62.301014, mean_q: 9.509462\n",
      " 4572/6000: episode: 1853, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.912 [0.000, 15.300], loss: 0.146490, mean_squared_error: 63.914490, mean_q: 9.749667\n",
      " 4574/6000: episode: 1854, duration: 0.042s, episode steps: 2, steps per second: 47, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 0.909 [0.000, 20.030], loss: 1.434077, mean_squared_error: 56.734421, mean_q: 9.459084\n",
      " 4584/6000: episode: 1855, duration: 0.141s, episode steps: 10, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.100 [0.000, 3.000], mean observation: 1.111 [0.000, 18.000], loss: 0.639718, mean_squared_error: 62.895092, mean_q: 9.709281\n",
      " 4585/6000: episode: 1856, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.076 [0.000, 16.244], loss: 0.571310, mean_squared_error: 53.865986, mean_q: 9.080640\n",
      " 4586/6000: episode: 1857, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.172 [0.000, 19.480], loss: 2.338193, mean_squared_error: 61.017612, mean_q: 9.545752\n",
      " 4587/6000: episode: 1858, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.709 [0.000, 28.540], loss: 1.483460, mean_squared_error: 61.708626, mean_q: 9.668646\n",
      " 4597/6000: episode: 1859, duration: 0.129s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.100 [2.000, 3.000], mean observation: 1.004 [0.000, 14.280], loss: 1.541022, mean_squared_error: 59.418098, mean_q: 9.428040\n",
      " 4598/6000: episode: 1860, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.793 [0.000, 11.697], loss: 2.045100, mean_squared_error: 64.160927, mean_q: 9.739968\n",
      " 4601/6000: episode: 1861, duration: 0.049s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.817 [0.000, 14.074], loss: 0.755311, mean_squared_error: 58.823818, mean_q: 9.452949\n",
      " 4602/6000: episode: 1862, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.711 [0.000, 21.600], loss: 1.484937, mean_squared_error: 59.233154, mean_q: 9.565947\n",
      " 4603/6000: episode: 1863, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.959 [0.000, 34.810], loss: 1.530128, mean_squared_error: 55.212349, mean_q: 9.476112\n",
      " 4604/6000: episode: 1864, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.851 [0.000, 16.305], loss: 0.175175, mean_squared_error: 61.453476, mean_q: 9.713315\n",
      " 4611/6000: episode: 1865, duration: 0.093s, episode steps: 7, steps per second: 76, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.714 [1.000, 3.000], mean observation: 1.449 [0.000, 28.290], loss: 0.774914, mean_squared_error: 61.715923, mean_q: 9.645947\n",
      " 4613/6000: episode: 1866, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.440 [0.000, 18.385], loss: 0.595676, mean_squared_error: 62.571480, mean_q: 9.775949\n",
      " 4614/6000: episode: 1867, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.499 [0.000, 35.970], loss: 4.648950, mean_squared_error: 55.583527, mean_q: 9.278311\n",
      " 4615/6000: episode: 1868, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.047 [0.000, 35.840], loss: 0.425018, mean_squared_error: 59.858826, mean_q: 9.844678\n",
      " 4618/6000: episode: 1869, duration: 0.054s, episode steps: 3, steps per second: 55, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [2.000, 3.000], mean observation: 1.309 [0.000, 17.250], loss: 1.073972, mean_squared_error: 61.244038, mean_q: 9.632989\n",
      " 4628/6000: episode: 1870, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.789 [0.000, 10.000], loss: 0.918690, mean_squared_error: 61.684296, mean_q: 9.612547\n",
      " 4629/6000: episode: 1871, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.244 [0.000, 17.206], loss: 0.213899, mean_squared_error: 60.772484, mean_q: 9.617020\n",
      " 4635/6000: episode: 1872, duration: 0.087s, episode steps: 6, steps per second: 69, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.833 [0.000, 3.000], mean observation: 0.968 [0.000, 15.870], loss: 0.442095, mean_squared_error: 64.753822, mean_q: 9.818665\n",
      " 4643/6000: episode: 1873, duration: 0.108s, episode steps: 8, steps per second: 74, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.315 [0.000, 20.700], loss: 1.226446, mean_squared_error: 60.447304, mean_q: 9.558895\n",
      " 4647/6000: episode: 1874, duration: 0.058s, episode steps: 4, steps per second: 68, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.750 [0.000, 3.000], mean observation: 1.542 [0.000, 21.140], loss: 1.986750, mean_squared_error: 61.234600, mean_q: 9.511475\n",
      " 4657/6000: episode: 1875, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 2.400 [0.000, 3.000], mean observation: 1.571 [0.000, 23.680], loss: 1.194604, mean_squared_error: 61.327202, mean_q: 9.585019\n",
      " 4658/6000: episode: 1876, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.794 [0.000, 39.260], loss: 2.157314, mean_squared_error: 62.064297, mean_q: 9.586697\n",
      " 4659/6000: episode: 1877, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.962 [0.000, 16.000], loss: 0.190278, mean_squared_error: 61.446800, mean_q: 9.665345\n",
      " 4660/6000: episode: 1878, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.783 [0.000, 37.840], loss: 0.213324, mean_squared_error: 66.335167, mean_q: 9.868591\n",
      " 4661/6000: episode: 1879, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.886 [0.000, 32.390], loss: 4.146774, mean_squared_error: 58.396889, mean_q: 9.283627\n",
      " 4662/6000: episode: 1880, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.699 [0.000, 33.160], loss: 1.190455, mean_squared_error: 60.469162, mean_q: 9.675428\n",
      " 4664/6000: episode: 1881, duration: 0.049s, episode steps: 2, steps per second: 41, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.728 [0.000, 31.260], loss: 1.449263, mean_squared_error: 58.868587, mean_q: 9.490946\n",
      " 4665/6000: episode: 1882, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.882 [0.000, 35.330], loss: 1.305817, mean_squared_error: 67.331253, mean_q: 10.061282\n",
      " 4674/6000: episode: 1883, duration: 0.142s, episode steps: 9, steps per second: 64, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.444 [0.000, 2.000], mean observation: 1.508 [0.000, 33.450], loss: 1.177155, mean_squared_error: 61.117920, mean_q: 9.698712\n",
      " 4675/6000: episode: 1884, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.290 [0.000, 19.800], loss: 4.196799, mean_squared_error: 64.627106, mean_q: 9.584000\n",
      " 4685/6000: episode: 1885, duration: 0.153s, episode steps: 10, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 2.000], mean observation: 1.422 [0.000, 18.920], loss: 1.808627, mean_squared_error: 59.579140, mean_q: 9.454453\n",
      " 4695/6000: episode: 1886, duration: 0.146s, episode steps: 10, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [0.000, 3.000], mean observation: 1.099 [0.000, 20.040], loss: 1.025845, mean_squared_error: 61.605827, mean_q: 9.629893\n",
      " 4696/6000: episode: 1887, duration: 0.021s, episode steps: 1, steps per second: 47, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.256 [0.000, 16.890], loss: 4.677065, mean_squared_error: 64.195419, mean_q: 9.680120\n",
      " 4697/6000: episode: 1888, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [0.000, 27.410], loss: 1.130172, mean_squared_error: 54.031479, mean_q: 9.118021\n",
      " 4702/6000: episode: 1889, duration: 0.068s, episode steps: 5, steps per second: 74, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [1.000, 2.000], mean observation: 1.418 [0.000, 25.390], loss: 1.200012, mean_squared_error: 65.294640, mean_q: 9.805127\n",
      " 4705/6000: episode: 1890, duration: 0.061s, episode steps: 3, steps per second: 49, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 1.445 [0.000, 39.110], loss: 1.663976, mean_squared_error: 62.606350, mean_q: 9.747645\n",
      " 4706/6000: episode: 1891, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.127 [0.000, 16.000], loss: 2.657004, mean_squared_error: 59.469666, mean_q: 9.367125\n",
      " 4707/6000: episode: 1892, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.599 [0.000, 18.720], loss: 2.325747, mean_squared_error: 59.152786, mean_q: 9.321630\n",
      " 4708/6000: episode: 1893, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.854 [0.000, 14.523], loss: 3.403873, mean_squared_error: 62.282745, mean_q: 9.802031\n",
      " 4709/6000: episode: 1894, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.397 [0.000, 19.914], loss: 1.438749, mean_squared_error: 58.867210, mean_q: 9.498186\n",
      " 4711/6000: episode: 1895, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.107 [0.000, 21.520], loss: 0.861442, mean_squared_error: 55.064186, mean_q: 9.170972\n",
      " 4715/6000: episode: 1896, duration: 0.057s, episode steps: 4, steps per second: 70, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.012 [0.000, 18.672], loss: 1.360159, mean_squared_error: 61.295052, mean_q: 9.535787\n",
      " 4717/6000: episode: 1897, duration: 0.041s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.181 [0.000, 17.017], loss: 2.207086, mean_squared_error: 62.290035, mean_q: 9.620232\n",
      " 4719/6000: episode: 1898, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.399 [0.000, 19.000], loss: 1.410738, mean_squared_error: 62.855068, mean_q: 9.660238\n",
      " 4720/6000: episode: 1899, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.009 [0.000, 17.943], loss: 0.497318, mean_squared_error: 56.645370, mean_q: 9.187850\n",
      " 4721/6000: episode: 1900, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.003 [0.000, 14.000], loss: 0.124895, mean_squared_error: 65.594238, mean_q: 9.840429\n",
      " 4722/6000: episode: 1901, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.821 [0.000, 16.012], loss: 0.228664, mean_squared_error: 57.213612, mean_q: 9.424643\n",
      " 4727/6000: episode: 1902, duration: 0.070s, episode steps: 5, steps per second: 71, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.400 [0.000, 3.000], mean observation: 1.853 [0.000, 38.520], loss: 1.046838, mean_squared_error: 62.376545, mean_q: 9.623305\n",
      " 4736/6000: episode: 1903, duration: 0.120s, episode steps: 9, steps per second: 75, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 0.667 [0.000, 2.000], mean observation: 1.144 [0.000, 14.860], loss: 1.525818, mean_squared_error: 57.860630, mean_q: 9.425562\n",
      " 4737/6000: episode: 1904, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.933 [0.000, 18.670], loss: 0.310620, mean_squared_error: 57.915642, mean_q: 9.500147\n",
      " 4747/6000: episode: 1905, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.392 [0.000, 25.410], loss: 1.023635, mean_squared_error: 62.572227, mean_q: 9.650709\n",
      " 4748/6000: episode: 1906, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.548 [0.000, 30.110], loss: 1.803954, mean_squared_error: 68.151825, mean_q: 9.949011\n",
      " 4750/6000: episode: 1907, duration: 0.046s, episode steps: 2, steps per second: 44, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 0.976 [0.000, 14.347], loss: 1.340511, mean_squared_error: 63.376358, mean_q: 9.726555\n",
      " 4751/6000: episode: 1908, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.805 [0.000, 17.270], loss: 2.445004, mean_squared_error: 68.344673, mean_q: 10.075544\n",
      " 4754/6000: episode: 1909, duration: 0.055s, episode steps: 3, steps per second: 55, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.183 [0.000, 17.345], loss: 0.929632, mean_squared_error: 60.201138, mean_q: 9.485970\n",
      " 4764/6000: episode: 1910, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.250 [0.000, 22.060], loss: 1.041741, mean_squared_error: 59.997425, mean_q: 9.506314\n",
      " 4765/6000: episode: 1911, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.266 [0.000, 25.810], loss: 1.721273, mean_squared_error: 59.968445, mean_q: 9.393003\n",
      " 4767/6000: episode: 1912, duration: 0.043s, episode steps: 2, steps per second: 46, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.217 [0.000, 18.000], loss: 0.684431, mean_squared_error: 64.840561, mean_q: 9.784977\n",
      " 4769/6000: episode: 1913, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.691 [0.000, 33.920], loss: 1.424112, mean_squared_error: 60.348763, mean_q: 9.467324\n",
      " 4772/6000: episode: 1914, duration: 0.049s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.667 [2.000, 3.000], mean observation: 1.168 [0.000, 19.746], loss: 0.867641, mean_squared_error: 62.455364, mean_q: 9.605848\n",
      " 4773/6000: episode: 1915, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.391 [0.000, 19.518], loss: 0.876627, mean_squared_error: 54.961578, mean_q: 9.186995\n",
      " 4774/6000: episode: 1916, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.187 [0.000, 14.274], loss: 2.232249, mean_squared_error: 64.337425, mean_q: 9.770083\n",
      " 4775/6000: episode: 1917, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.224 [0.000, 16.000], loss: 0.097972, mean_squared_error: 65.251198, mean_q: 9.984019\n",
      " 4777/6000: episode: 1918, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.534 [0.000, 33.230], loss: 2.439533, mean_squared_error: 59.416409, mean_q: 9.428814\n",
      " 4779/6000: episode: 1919, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.425 [0.000, 30.690], loss: 0.662692, mean_squared_error: 63.270260, mean_q: 9.724653\n",
      " 4782/6000: episode: 1920, duration: 0.046s, episode steps: 3, steps per second: 65, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [1.000, 3.000], mean observation: 1.152 [0.000, 17.000], loss: 1.570878, mean_squared_error: 62.260975, mean_q: 9.654719\n",
      " 4783/6000: episode: 1921, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.896 [0.000, 38.540], loss: 1.058597, mean_squared_error: 57.537182, mean_q: 9.409020\n",
      " 4784/6000: episode: 1922, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.168 [0.000, 19.746], loss: 1.482186, mean_squared_error: 53.837643, mean_q: 9.413620\n",
      " 4785/6000: episode: 1923, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.503 [0.000, 19.878], loss: 2.233152, mean_squared_error: 60.467884, mean_q: 9.560488\n",
      " 4786/6000: episode: 1924, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.392 [0.000, 22.670], loss: 0.158632, mean_squared_error: 60.699516, mean_q: 9.712864\n",
      " 4792/6000: episode: 1925, duration: 0.080s, episode steps: 6, steps per second: 75, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 0.167 [0.000, 1.000], mean observation: 1.604 [0.000, 31.780], loss: 1.309859, mean_squared_error: 61.738922, mean_q: 9.668358\n",
      " 4793/6000: episode: 1926, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.459 [0.000, 22.080], loss: 1.574794, mean_squared_error: 60.531075, mean_q: 9.779968\n",
      " 4794/6000: episode: 1927, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.289 [0.000, 17.000], loss: 2.620343, mean_squared_error: 61.015350, mean_q: 9.553119\n",
      " 4795/6000: episode: 1928, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.828 [0.000, 34.030], loss: 0.694798, mean_squared_error: 55.000393, mean_q: 9.428820\n",
      " 4801/6000: episode: 1929, duration: 0.082s, episode steps: 6, steps per second: 73, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.333 [1.000, 3.000], mean observation: 1.644 [0.000, 31.020], loss: 1.293135, mean_squared_error: 59.688782, mean_q: 9.531982\n",
      " 4802/6000: episode: 1930, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.127 [0.000, 16.824], loss: 0.976751, mean_squared_error: 57.613808, mean_q: 9.406627\n",
      " 4805/6000: episode: 1931, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.318 [0.000, 19.661], loss: 0.539243, mean_squared_error: 66.501587, mean_q: 9.965032\n",
      " 4806/6000: episode: 1932, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.781 [0.000, 38.980], loss: 2.799994, mean_squared_error: 64.018051, mean_q: 9.771250\n",
      " 4807/6000: episode: 1933, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.583 [0.000, 33.850], loss: 0.169775, mean_squared_error: 53.580704, mean_q: 9.280640\n",
      " 4812/6000: episode: 1934, duration: 0.091s, episode steps: 5, steps per second: 55, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.600 [0.000, 3.000], mean observation: 1.322 [0.000, 20.650], loss: 1.699506, mean_squared_error: 58.820263, mean_q: 9.384117\n",
      " 4819/6000: episode: 1935, duration: 0.097s, episode steps: 7, steps per second: 72, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.571 [0.000, 2.000], mean observation: 1.352 [0.000, 23.260], loss: 1.188485, mean_squared_error: 60.571621, mean_q: 9.563193\n",
      " 4820/6000: episode: 1936, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.903 [0.000, 16.959], loss: 1.913054, mean_squared_error: 58.888718, mean_q: 9.426138\n",
      " 4821/6000: episode: 1937, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.993 [0.000, 17.476], loss: 2.421930, mean_squared_error: 63.496811, mean_q: 9.680849\n",
      " 4822/6000: episode: 1938, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.142 [0.000, 19.163], loss: 4.276940, mean_squared_error: 62.701004, mean_q: 9.648893\n",
      " 4824/6000: episode: 1939, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.761 [0.000, 29.880], loss: 0.903694, mean_squared_error: 58.967949, mean_q: 9.468128\n",
      " 4827/6000: episode: 1940, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [2.000, 3.000], mean observation: 1.191 [0.000, 18.410], loss: 0.171141, mean_squared_error: 63.599033, mean_q: 9.748548\n",
      " 4828/6000: episode: 1941, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.324 [0.000, 24.610], loss: 2.105704, mean_squared_error: 70.280365, mean_q: 10.156239\n",
      " 4831/6000: episode: 1942, duration: 0.052s, episode steps: 3, steps per second: 58, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.579 [0.000, 19.562], loss: 0.611793, mean_squared_error: 62.098988, mean_q: 9.638167\n",
      " 4832/6000: episode: 1943, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.508 [0.000, 34.350], loss: 0.099878, mean_squared_error: 66.191086, mean_q: 9.861332\n",
      " 4839/6000: episode: 1944, duration: 0.098s, episode steps: 7, steps per second: 72, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.100 [0.000, 14.605], loss: 1.747934, mean_squared_error: 59.726498, mean_q: 9.454857\n",
      " 4840/6000: episode: 1945, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.505 [0.000, 28.230], loss: 1.749593, mean_squared_error: 63.036446, mean_q: 9.641375\n",
      " 4841/6000: episode: 1946, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.946 [0.000, 13.149], loss: 0.339160, mean_squared_error: 60.808716, mean_q: 9.747047\n",
      " 4842/6000: episode: 1947, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.687 [0.000, 27.910], loss: 0.174861, mean_squared_error: 57.784027, mean_q: 9.363022\n",
      " 4843/6000: episode: 1948, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.297 [0.000, 16.300], loss: 0.175445, mean_squared_error: 63.106941, mean_q: 9.698284\n",
      " 4844/6000: episode: 1949, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.296 [0.000, 17.300], loss: 0.172643, mean_squared_error: 60.195782, mean_q: 9.534185\n",
      " 4848/6000: episode: 1950, duration: 0.067s, episode steps: 4, steps per second: 60, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [1.000, 3.000], mean observation: 1.574 [0.000, 30.730], loss: 1.147092, mean_squared_error: 61.256428, mean_q: 9.589830\n",
      " 4849/6000: episode: 1951, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.430 [0.000, 26.880], loss: 0.178669, mean_squared_error: 62.660130, mean_q: 9.715693\n",
      " 4856/6000: episode: 1952, duration: 0.093s, episode steps: 7, steps per second: 75, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 0.429 [0.000, 2.000], mean observation: 0.736 [0.000, 9.920], loss: 1.500170, mean_squared_error: 60.935978, mean_q: 9.609810\n",
      " 4866/6000: episode: 1953, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.575 [0.000, 39.860], loss: 0.981572, mean_squared_error: 62.172394, mean_q: 9.637707\n",
      " 4867/6000: episode: 1954, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.055 [0.000, 16.566], loss: 2.166983, mean_squared_error: 54.955235, mean_q: 9.353716\n",
      " 4872/6000: episode: 1955, duration: 0.079s, episode steps: 5, steps per second: 63, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [1.000, 2.000], mean observation: 1.515 [0.000, 23.640], loss: 1.393956, mean_squared_error: 61.263958, mean_q: 9.732285\n",
      " 4878/6000: episode: 1956, duration: 0.143s, episode steps: 6, steps per second: 42, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.833 [1.000, 2.000], mean observation: 1.549 [0.000, 31.230], loss: 1.356647, mean_squared_error: 59.644451, mean_q: 9.531413\n",
      " 4879/6000: episode: 1957, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.764 [0.000, 30.720], loss: 0.338966, mean_squared_error: 61.204033, mean_q: 9.656374\n",
      " 4883/6000: episode: 1958, duration: 0.088s, episode steps: 4, steps per second: 45, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.750 [1.000, 3.000], mean observation: 1.395 [0.000, 23.890], loss: 0.471198, mean_squared_error: 59.587666, mean_q: 9.509975\n",
      " 4885/6000: episode: 1959, duration: 0.041s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.243 [0.000, 17.678], loss: 0.073017, mean_squared_error: 64.816124, mean_q: 9.780733\n",
      " 4886/6000: episode: 1960, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.256 [0.000, 17.121], loss: 0.129215, mean_squared_error: 61.191780, mean_q: 9.605454\n",
      " 4887/6000: episode: 1961, duration: 0.022s, episode steps: 1, steps per second: 46, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.010 [0.000, 33.340], loss: 1.202813, mean_squared_error: 60.096447, mean_q: 9.394314\n",
      " 4888/6000: episode: 1962, duration: 0.022s, episode steps: 1, steps per second: 45, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.674 [0.000, 20.880], loss: 0.891842, mean_squared_error: 56.637806, mean_q: 9.278937\n",
      " 4889/6000: episode: 1963, duration: 0.022s, episode steps: 1, steps per second: 45, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.122 [0.000, 19.800], loss: 0.130495, mean_squared_error: 65.326874, mean_q: 9.825049\n",
      " 4898/6000: episode: 1964, duration: 0.117s, episode steps: 9, steps per second: 77, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.778 [0.000, 2.000], mean observation: 1.177 [0.000, 22.220], loss: 1.226784, mean_squared_error: 61.248726, mean_q: 9.541065\n",
      " 4901/6000: episode: 1965, duration: 0.045s, episode steps: 3, steps per second: 67, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.000 [0.000, 3.000], mean observation: 1.249 [0.000, 15.979], loss: 1.640947, mean_squared_error: 59.606903, mean_q: 9.536315\n",
      " 4911/6000: episode: 1966, duration: 0.196s, episode steps: 10, steps per second: 51, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.700 [1.000, 3.000], mean observation: 1.077 [0.000, 19.000], loss: 1.539850, mean_squared_error: 58.939625, mean_q: 9.423295\n",
      " 4912/6000: episode: 1967, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.317 [0.000, 19.000], loss: 2.449287, mean_squared_error: 58.648907, mean_q: 9.465643\n",
      " 4913/6000: episode: 1968, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.462 [0.000, 18.890], loss: 0.151610, mean_squared_error: 61.958252, mean_q: 9.633464\n",
      " 4923/6000: episode: 1969, duration: 0.136s, episode steps: 10, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.800 [0.000, 2.000], mean observation: 1.066 [0.000, 19.460], loss: 1.676258, mean_squared_error: 60.091908, mean_q: 9.591943\n",
      " 4924/6000: episode: 1970, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.193 [0.000, 17.000], loss: 1.377187, mean_squared_error: 62.967087, mean_q: 9.762584\n",
      " 4927/6000: episode: 1971, duration: 0.051s, episode steps: 3, steps per second: 59, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [1.000, 3.000], mean observation: 1.718 [0.000, 38.580], loss: 0.974797, mean_squared_error: 60.783634, mean_q: 9.603118\n",
      " 4937/6000: episode: 1972, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.165 [0.000, 18.000], loss: 1.017146, mean_squared_error: 62.168922, mean_q: 9.701554\n",
      " 4940/6000: episode: 1973, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.378 [0.000, 35.570], loss: 2.337623, mean_squared_error: 61.416737, mean_q: 9.628021\n",
      " 4942/6000: episode: 1974, duration: 0.045s, episode steps: 2, steps per second: 45, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.698 [0.000, 39.610], loss: 0.629700, mean_squared_error: 66.351021, mean_q: 9.919769\n",
      " 4943/6000: episode: 1975, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.085 [0.000, 17.650], loss: 1.389698, mean_squared_error: 58.613983, mean_q: 9.509655\n",
      " 4944/6000: episode: 1976, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.330 [0.000, 22.580], loss: 0.349506, mean_squared_error: 59.771393, mean_q: 9.486997\n",
      " 4945/6000: episode: 1977, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.926 [0.000, 15.000], loss: 0.151293, mean_squared_error: 59.207649, mean_q: 9.521027\n",
      " 4946/6000: episode: 1978, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.240 [0.000, 16.020], loss: 0.074897, mean_squared_error: 63.120266, mean_q: 9.617129\n",
      " 4947/6000: episode: 1979, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.457 [0.000, 21.090], loss: 2.155823, mean_squared_error: 62.795414, mean_q: 9.698801\n",
      " 4948/6000: episode: 1980, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.947 [0.000, 14.430], loss: 2.544153, mean_squared_error: 73.036369, mean_q: 10.294394\n",
      " 4952/6000: episode: 1981, duration: 0.066s, episode steps: 4, steps per second: 61, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.819 [0.000, 35.040], loss: 1.244654, mean_squared_error: 63.855381, mean_q: 9.733147\n",
      " 4953/6000: episode: 1982, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.832 [0.000, 14.000], loss: 0.282786, mean_squared_error: 64.204697, mean_q: 9.874410\n",
      " 4957/6000: episode: 1983, duration: 0.058s, episode steps: 4, steps per second: 68, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.284 [0.000, 16.446], loss: 1.522476, mean_squared_error: 64.873611, mean_q: 9.854258\n",
      " 4965/6000: episode: 1984, duration: 0.113s, episode steps: 8, steps per second: 71, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.375 [0.000, 3.000], mean observation: 1.257 [0.000, 19.046], loss: 0.746286, mean_squared_error: 61.239582, mean_q: 9.613253\n",
      " 4975/6000: episode: 1985, duration: 0.139s, episode steps: 10, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [1.000, 3.000], mean observation: 1.508 [0.000, 22.420], loss: 0.808231, mean_squared_error: 63.310799, mean_q: 9.703198\n",
      " 4977/6000: episode: 1986, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.392 [0.000, 23.750], loss: 1.249628, mean_squared_error: 63.092022, mean_q: 9.773015\n",
      " 4978/6000: episode: 1987, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.497 [0.000, 29.700], loss: 0.130942, mean_squared_error: 61.640614, mean_q: 9.589454\n",
      " 4979/6000: episode: 1988, duration: 0.033s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.565 [0.000, 32.420], loss: 2.462234, mean_squared_error: 64.678673, mean_q: 9.759847\n",
      " 4989/6000: episode: 1989, duration: 0.143s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.566 [0.000, 24.440], loss: 0.801284, mean_squared_error: 64.777763, mean_q: 9.782134\n",
      " 4999/6000: episode: 1990, duration: 0.131s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.800 [1.000, 3.000], mean observation: 1.073 [0.000, 18.000], loss: 0.886526, mean_squared_error: 62.317871, mean_q: 9.663092\n",
      " 5000/6000: episode: 1991, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.246 [0.000, 34.050], loss: 0.081864, mean_squared_error: 67.524551, mean_q: 9.953447\n",
      " 5004/6000: episode: 1992, duration: 0.061s, episode steps: 4, steps per second: 65, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.352 [0.000, 19.781], loss: 0.976904, mean_squared_error: 60.915779, mean_q: 9.542172\n",
      " 5008/6000: episode: 1993, duration: 0.058s, episode steps: 4, steps per second: 69, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.254 [0.000, 18.000], loss: 0.455054, mean_squared_error: 63.264496, mean_q: 9.742019\n",
      " 5009/6000: episode: 1994, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.546 [0.000, 18.530], loss: 1.564463, mean_squared_error: 63.350990, mean_q: 9.669220\n",
      " 5011/6000: episode: 1995, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.561 [0.000, 37.450], loss: 1.087310, mean_squared_error: 61.582817, mean_q: 9.827356\n",
      " 5016/6000: episode: 1996, duration: 0.073s, episode steps: 5, steps per second: 69, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.400 [0.000, 3.000], mean observation: 1.772 [0.000, 31.340], loss: 1.202605, mean_squared_error: 61.429485, mean_q: 9.643677\n",
      " 5017/6000: episode: 1997, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.549 [0.000, 30.820], loss: 1.621448, mean_squared_error: 63.692299, mean_q: 9.782441\n",
      " 5018/6000: episode: 1998, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.394 [0.000, 35.560], loss: 0.222290, mean_squared_error: 60.447586, mean_q: 9.514752\n",
      " 5019/6000: episode: 1999, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.303 [0.000, 28.990], loss: 1.410058, mean_squared_error: 56.724102, mean_q: 9.317171\n",
      " 5020/6000: episode: 2000, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.278 [0.000, 17.818], loss: 3.639464, mean_squared_error: 68.473938, mean_q: 10.012936\n",
      " 5021/6000: episode: 2001, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.286 [0.000, 18.680], loss: 1.330156, mean_squared_error: 57.482117, mean_q: 9.341753\n",
      " 5022/6000: episode: 2002, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.046 [0.000, 27.090], loss: 0.969913, mean_squared_error: 63.454865, mean_q: 9.777966\n",
      " 5024/6000: episode: 2003, duration: 0.050s, episode steps: 2, steps per second: 40, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.819 [0.000, 38.480], loss: 1.128745, mean_squared_error: 63.331650, mean_q: 9.793591\n",
      " 5025/6000: episode: 2004, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.750 [0.000, 28.420], loss: 1.361968, mean_squared_error: 67.844093, mean_q: 10.002669\n",
      " 5026/6000: episode: 2005, duration: 0.021s, episode steps: 1, steps per second: 49, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.992 [0.000, 14.149], loss: 1.048870, mean_squared_error: 62.247639, mean_q: 9.693114\n",
      " 5027/6000: episode: 2006, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.133 [0.000, 27.900], loss: 1.335125, mean_squared_error: 62.967003, mean_q: 9.871993\n",
      " 5030/6000: episode: 2007, duration: 0.053s, episode steps: 3, steps per second: 57, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [0.000, 3.000], mean observation: 1.649 [0.000, 30.480], loss: 3.323640, mean_squared_error: 58.182129, mean_q: 9.243155\n",
      " 5031/6000: episode: 2008, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.824 [0.000, 36.550], loss: 0.239005, mean_squared_error: 63.288593, mean_q: 9.905544\n",
      " 5032/6000: episode: 2009, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.650 [0.000, 23.100], loss: 0.311378, mean_squared_error: 60.236526, mean_q: 9.541813\n",
      " 5036/6000: episode: 2010, duration: 0.059s, episode steps: 4, steps per second: 67, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [2.000, 3.000], mean observation: 1.191 [0.000, 14.928], loss: 1.797663, mean_squared_error: 61.923500, mean_q: 9.641319\n",
      " 5046/6000: episode: 2011, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.400 [1.000, 3.000], mean observation: 1.620 [0.000, 22.540], loss: 1.172027, mean_squared_error: 60.545174, mean_q: 9.557384\n",
      " 5056/6000: episode: 2012, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.600 [0.000, 1.000], mean observation: 1.661 [0.000, 35.530], loss: 1.245764, mean_squared_error: 61.161835, mean_q: 9.584842\n",
      " 5057/6000: episode: 2013, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.128 [0.000, 20.670], loss: 0.090233, mean_squared_error: 66.113831, mean_q: 9.930949\n",
      " 5060/6000: episode: 2014, duration: 0.046s, episode steps: 3, steps per second: 65, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.411 [0.000, 20.560], loss: 1.352231, mean_squared_error: 62.738312, mean_q: 9.653060\n",
      " 5062/6000: episode: 2015, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.704 [0.000, 33.560], loss: 1.225128, mean_squared_error: 59.322899, mean_q: 9.395363\n",
      " 5063/6000: episode: 2016, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.596 [0.000, 18.466], loss: 1.219923, mean_squared_error: 56.064323, mean_q: 9.241896\n",
      " 5064/6000: episode: 2017, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.829 [0.000, 32.090], loss: 1.178801, mean_squared_error: 69.670570, mean_q: 10.072941\n",
      " 5065/6000: episode: 2018, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.853 [0.000, 18.574], loss: 2.230551, mean_squared_error: 61.164368, mean_q: 9.691026\n",
      " 5066/6000: episode: 2019, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.762 [0.000, 21.700], loss: 2.630440, mean_squared_error: 64.435883, mean_q: 9.615870\n",
      " 5067/6000: episode: 2020, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.796 [0.000, 25.480], loss: 0.100121, mean_squared_error: 65.265564, mean_q: 9.987476\n",
      " 5069/6000: episode: 2021, duration: 0.045s, episode steps: 2, steps per second: 45, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.182 [0.000, 18.240], loss: 1.281985, mean_squared_error: 62.366257, mean_q: 9.638546\n",
      " 5079/6000: episode: 2022, duration: 0.141s, episode steps: 10, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.700 [0.000, 1.000], mean observation: 1.673 [0.000, 34.800], loss: 1.366843, mean_squared_error: 59.197491, mean_q: 9.477522\n",
      " 5089/6000: episode: 2023, duration: 0.140s, episode steps: 10, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.673 [0.000, 38.330], loss: 0.742364, mean_squared_error: 62.574512, mean_q: 9.680704\n",
      " 5090/6000: episode: 2024, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.458 [0.000, 19.000], loss: 0.909450, mean_squared_error: 62.796623, mean_q: 9.694318\n",
      " 5091/6000: episode: 2025, duration: 0.023s, episode steps: 1, steps per second: 44, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.868 [0.000, 12.489], loss: 0.114174, mean_squared_error: 66.813171, mean_q: 9.854622\n",
      " 5095/6000: episode: 2026, duration: 0.062s, episode steps: 4, steps per second: 64, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [0.000, 3.000], mean observation: 1.477 [0.000, 24.430], loss: 1.941246, mean_squared_error: 61.307541, mean_q: 9.660870\n",
      " 5105/6000: episode: 2027, duration: 0.140s, episode steps: 10, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.700 [1.000, 3.000], mean observation: 1.449 [0.000, 22.320], loss: 1.227679, mean_squared_error: 62.506187, mean_q: 9.628923\n",
      " 5106/6000: episode: 2028, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.840 [0.000, 13.000], loss: 1.223527, mean_squared_error: 65.494843, mean_q: 9.891531\n",
      " 5107/6000: episode: 2029, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.987 [0.000, 35.960], loss: 0.206386, mean_squared_error: 62.655350, mean_q: 9.830633\n",
      " 5116/6000: episode: 2030, duration: 0.119s, episode steps: 9, steps per second: 75, episode reward: 10.000, mean reward: 1.111 [0.000, 10.000], mean action: 1.444 [0.000, 3.000], mean observation: 1.563 [0.000, 31.250], loss: 1.032553, mean_squared_error: 63.680832, mean_q: 9.728340\n",
      " 5117/6000: episode: 2031, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.622 [0.000, 34.410], loss: 0.094405, mean_squared_error: 66.480423, mean_q: 9.889637\n",
      " 5118/6000: episode: 2032, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.179 [0.000, 17.139], loss: 2.050560, mean_squared_error: 62.381241, mean_q: 9.630782\n",
      " 5119/6000: episode: 2033, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.962 [0.000, 16.000], loss: 1.321054, mean_squared_error: 66.823837, mean_q: 10.024255\n",
      " 5123/6000: episode: 2034, duration: 0.061s, episode steps: 4, steps per second: 66, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.250 [0.000, 1.000], mean observation: 1.255 [0.000, 25.060], loss: 1.646630, mean_squared_error: 62.907650, mean_q: 9.642063\n",
      " 5126/6000: episode: 2035, duration: 0.053s, episode steps: 3, steps per second: 57, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 1.511 [0.000, 28.550], loss: 1.443660, mean_squared_error: 62.494080, mean_q: 9.606761\n",
      " 5127/6000: episode: 2036, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.575 [0.000, 26.190], loss: 0.553841, mean_squared_error: 51.156971, mean_q: 8.996622\n",
      " 5128/6000: episode: 2037, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.081 [0.000, 19.627], loss: 2.300415, mean_squared_error: 60.762489, mean_q: 9.650970\n",
      " 5129/6000: episode: 2038, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.320 [0.000, 25.420], loss: 2.303739, mean_squared_error: 62.836697, mean_q: 9.526435\n",
      " 5133/6000: episode: 2039, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.750 [2.000, 3.000], mean observation: 1.734 [0.000, 38.840], loss: 1.341262, mean_squared_error: 60.958111, mean_q: 9.546024\n",
      " 5138/6000: episode: 2040, duration: 0.075s, episode steps: 5, steps per second: 66, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.400 [0.000, 3.000], mean observation: 1.629 [0.000, 36.060], loss: 1.480310, mean_squared_error: 61.441814, mean_q: 9.545237\n",
      " 5139/6000: episode: 2041, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.477 [0.000, 24.430], loss: 0.975076, mean_squared_error: 54.725006, mean_q: 9.412008\n",
      " 5140/6000: episode: 2042, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.887 [0.000, 31.700], loss: 1.766896, mean_squared_error: 63.003265, mean_q: 9.672704\n",
      " 5150/6000: episode: 2043, duration: 0.131s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.359 [0.000, 18.979], loss: 1.388202, mean_squared_error: 61.909843, mean_q: 9.610697\n",
      " 5151/6000: episode: 2044, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.552 [0.000, 18.714], loss: 1.268508, mean_squared_error: 59.079857, mean_q: 9.284989\n",
      " 5152/6000: episode: 2045, duration: 0.021s, episode steps: 1, steps per second: 48, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.706 [0.000, 36.900], loss: 1.156378, mean_squared_error: 61.623489, mean_q: 9.687169\n",
      " 5153/6000: episode: 2046, duration: 0.020s, episode steps: 1, steps per second: 50, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.900 [0.000, 11.620], loss: 0.534356, mean_squared_error: 52.205643, mean_q: 9.118106\n",
      " 5163/6000: episode: 2047, duration: 0.135s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.300 [0.000, 2.000], mean observation: 1.720 [0.000, 33.170], loss: 2.008234, mean_squared_error: 59.269630, mean_q: 9.505181\n",
      " 5164/6000: episode: 2048, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.951 [0.000, 36.490], loss: 1.049384, mean_squared_error: 61.532372, mean_q: 9.586754\n",
      " 5165/6000: episode: 2049, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.962 [0.000, 14.485], loss: 0.373404, mean_squared_error: 55.125938, mean_q: 9.234179\n",
      " 5166/6000: episode: 2050, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.306 [0.000, 19.888], loss: 1.242758, mean_squared_error: 55.497520, mean_q: 9.137463\n",
      " 5167/6000: episode: 2051, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.928 [0.000, 32.130], loss: 0.482657, mean_squared_error: 57.733009, mean_q: 9.541737\n",
      " 5169/6000: episode: 2052, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.343 [0.000, 18.307], loss: 0.804846, mean_squared_error: 62.644875, mean_q: 9.655441\n",
      " 5170/6000: episode: 2053, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.400 [0.000, 31.560], loss: 2.535028, mean_squared_error: 62.268631, mean_q: 9.670019\n",
      " 5180/6000: episode: 2054, duration: 0.136s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.200 [0.000, 2.000], mean observation: 1.589 [0.000, 24.590], loss: 1.732926, mean_squared_error: 59.885124, mean_q: 9.574549\n",
      " 5184/6000: episode: 2055, duration: 0.063s, episode steps: 4, steps per second: 63, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 1.000], mean observation: 1.311 [0.000, 19.422], loss: 1.833304, mean_squared_error: 60.168770, mean_q: 9.492599\n",
      " 5185/6000: episode: 2056, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.450 [0.000, 29.160], loss: 3.911011, mean_squared_error: 64.320190, mean_q: 9.651508\n",
      " 5188/6000: episode: 2057, duration: 0.046s, episode steps: 3, steps per second: 65, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.003 [0.000, 14.000], loss: 0.918305, mean_squared_error: 60.422504, mean_q: 9.596278\n",
      " 5189/6000: episode: 2058, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.221 [0.000, 24.790], loss: 0.874092, mean_squared_error: 62.968468, mean_q: 9.720933\n",
      " 5190/6000: episode: 2059, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.484 [0.000, 29.970], loss: 1.007231, mean_squared_error: 63.191792, mean_q: 9.671945\n",
      " 5192/6000: episode: 2060, duration: 0.041s, episode steps: 2, steps per second: 48, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.815 [0.000, 9.873], loss: 0.676323, mean_squared_error: 58.208717, mean_q: 9.578737\n",
      " 5202/6000: episode: 2061, duration: 0.129s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.800 [1.000, 2.000], mean observation: 1.147 [0.000, 15.548], loss: 1.566462, mean_squared_error: 59.610058, mean_q: 9.534901\n",
      " 5203/6000: episode: 2062, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.655 [0.000, 37.740], loss: 3.774096, mean_squared_error: 52.520256, mean_q: 8.837230\n",
      " 5211/6000: episode: 2063, duration: 0.112s, episode steps: 8, steps per second: 72, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 0.875 [0.000, 1.000], mean observation: 0.901 [0.000, 18.100], loss: 1.010716, mean_squared_error: 61.430363, mean_q: 9.649317\n",
      " 5212/6000: episode: 2064, duration: 0.025s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.758 [0.000, 32.280], loss: 1.540069, mean_squared_error: 62.894852, mean_q: 9.806768\n",
      " 5213/6000: episode: 2065, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.153 [0.000, 17.260], loss: 1.383692, mean_squared_error: 67.833801, mean_q: 10.130429\n",
      " 5215/6000: episode: 2066, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.608 [0.000, 32.950], loss: 0.758664, mean_squared_error: 62.449432, mean_q: 9.745863\n",
      " 5216/6000: episode: 2067, duration: 0.027s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.495 [0.000, 23.340], loss: 1.402792, mean_squared_error: 55.175194, mean_q: 9.418338\n",
      " 5224/6000: episode: 2068, duration: 0.178s, episode steps: 8, steps per second: 45, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.875 [2.000, 3.000], mean observation: 0.796 [0.000, 11.199], loss: 1.167199, mean_squared_error: 59.233162, mean_q: 9.541422\n",
      " 5225/6000: episode: 2069, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.458 [0.000, 24.830], loss: 1.759739, mean_squared_error: 66.890457, mean_q: 9.966646\n",
      " 5227/6000: episode: 2070, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.052 [0.000, 16.426], loss: 0.803874, mean_squared_error: 61.656746, mean_q: 9.638294\n",
      " 5228/6000: episode: 2071, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.226 [0.000, 18.540], loss: 0.283813, mean_squared_error: 58.505608, mean_q: 9.474544\n",
      " 5229/6000: episode: 2072, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.651 [0.000, 37.960], loss: 1.321840, mean_squared_error: 66.651489, mean_q: 9.992353\n",
      " 5230/6000: episode: 2073, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.050 [0.000, 17.857], loss: 1.581655, mean_squared_error: 65.109116, mean_q: 10.025866\n",
      " 5231/6000: episode: 2074, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.601 [0.000, 31.800], loss: 3.654707, mean_squared_error: 63.685448, mean_q: 9.922974\n",
      " 5234/6000: episode: 2075, duration: 0.051s, episode steps: 3, steps per second: 59, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.785 [0.000, 29.430], loss: 1.154980, mean_squared_error: 62.575817, mean_q: 9.629533\n",
      " 5235/6000: episode: 2076, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.441 [0.000, 18.619], loss: 0.180796, mean_squared_error: 63.616474, mean_q: 9.842415\n",
      " 5237/6000: episode: 2077, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.766 [0.000, 34.190], loss: 1.909297, mean_squared_error: 61.175026, mean_q: 9.575726\n",
      " 5238/6000: episode: 2078, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.376 [0.000, 19.270], loss: 0.216048, mean_squared_error: 63.812920, mean_q: 9.794994\n",
      " 5239/6000: episode: 2079, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.583 [0.000, 33.850], loss: 2.365940, mean_squared_error: 63.358391, mean_q: 9.841844\n",
      " 5242/6000: episode: 2080, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [1.000, 2.000], mean observation: 1.089 [0.000, 18.000], loss: 1.257851, mean_squared_error: 60.418407, mean_q: 9.646657\n",
      " 5252/6000: episode: 2081, duration: 0.140s, episode steps: 10, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.055 [0.000, 15.000], loss: 0.931908, mean_squared_error: 62.937508, mean_q: 9.725627\n",
      " 5253/6000: episode: 2082, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.076 [0.000, 16.319], loss: 1.327742, mean_squared_error: 60.428612, mean_q: 9.493183\n",
      " 5254/6000: episode: 2083, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.459 [0.000, 19.000], loss: 0.289094, mean_squared_error: 68.309151, mean_q: 10.028593\n",
      " 5255/6000: episode: 2084, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.575 [0.000, 24.480], loss: 0.303254, mean_squared_error: 58.721325, mean_q: 9.565382\n",
      " 5256/6000: episode: 2085, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.201 [0.000, 19.313], loss: 0.103836, mean_squared_error: 60.070755, mean_q: 9.457551\n",
      " 5257/6000: episode: 2086, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.707 [0.000, 29.560], loss: 1.790489, mean_squared_error: 58.696354, mean_q: 9.588119\n",
      " 5258/6000: episode: 2087, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.225 [0.000, 19.206], loss: 4.027127, mean_squared_error: 66.425415, mean_q: 9.921919\n",
      " 5264/6000: episode: 2088, duration: 0.097s, episode steps: 6, steps per second: 62, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.933 [0.000, 38.900], loss: 1.633205, mean_squared_error: 58.834324, mean_q: 9.499633\n",
      " 5266/6000: episode: 2089, duration: 0.040s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.765 [0.000, 31.310], loss: 1.145954, mean_squared_error: 62.663528, mean_q: 9.695520\n",
      " 5268/6000: episode: 2090, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.092 [0.000, 18.360], loss: 2.295397, mean_squared_error: 63.409458, mean_q: 9.690115\n",
      " 5269/6000: episode: 2091, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.456 [0.000, 25.860], loss: 2.446726, mean_squared_error: 59.370461, mean_q: 9.401585\n",
      " 5279/6000: episode: 2092, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.300 [1.000, 3.000], mean observation: 1.448 [0.000, 39.430], loss: 1.155997, mean_squared_error: 60.448963, mean_q: 9.579136\n",
      " 5289/6000: episode: 2093, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.300 [0.000, 2.000], mean observation: 1.359 [0.000, 18.979], loss: 1.508614, mean_squared_error: 59.881905, mean_q: 9.614309\n",
      " 5293/6000: episode: 2094, duration: 0.063s, episode steps: 4, steps per second: 63, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 2.000], mean observation: 1.578 [0.000, 25.210], loss: 1.381227, mean_squared_error: 61.212723, mean_q: 9.682560\n",
      " 5294/6000: episode: 2095, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.899 [0.000, 39.030], loss: 0.100789, mean_squared_error: 63.040817, mean_q: 9.677246\n",
      " 5295/6000: episode: 2096, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.236 [0.000, 23.560], loss: 2.145350, mean_squared_error: 58.536137, mean_q: 9.508109\n",
      " 5298/6000: episode: 2097, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.842 [0.000, 31.810], loss: 0.476412, mean_squared_error: 66.624115, mean_q: 9.950265\n",
      " 5300/6000: episode: 2098, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.291 [0.000, 17.009], loss: 0.181550, mean_squared_error: 62.920330, mean_q: 9.820783\n",
      " 5302/6000: episode: 2099, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.450 [0.000, 26.870], loss: 1.360434, mean_squared_error: 59.302414, mean_q: 9.501593\n",
      " 5304/6000: episode: 2100, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.436 [0.000, 38.070], loss: 1.958556, mean_squared_error: 60.649323, mean_q: 9.563117\n",
      " 5306/6000: episode: 2101, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.953 [0.000, 27.620], loss: 1.631343, mean_squared_error: 58.180061, mean_q: 9.416130\n",
      " 5308/6000: episode: 2102, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.170 [0.000, 17.410], loss: 2.491828, mean_squared_error: 57.922626, mean_q: 9.482159\n",
      " 5310/6000: episode: 2103, duration: 0.037s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.544 [0.000, 20.370], loss: 0.656019, mean_squared_error: 57.572571, mean_q: 9.570601\n",
      " 5311/6000: episode: 2104, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.478 [0.000, 28.030], loss: 0.320159, mean_squared_error: 56.555225, mean_q: 9.366718\n",
      " 5312/6000: episode: 2105, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.906 [0.000, 34.610], loss: 0.136813, mean_squared_error: 66.102875, mean_q: 9.850744\n",
      " 5314/6000: episode: 2106, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.248 [0.000, 20.170], loss: 1.905099, mean_squared_error: 59.479965, mean_q: 9.537808\n",
      " 5316/6000: episode: 2107, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.429 [0.000, 23.270], loss: 1.842538, mean_squared_error: 63.593643, mean_q: 9.746147\n",
      " 5317/6000: episode: 2108, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.075 [0.000, 14.421], loss: 2.886034, mean_squared_error: 63.829742, mean_q: 9.662651\n",
      " 5318/6000: episode: 2109, duration: 0.023s, episode steps: 1, steps per second: 44, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.770 [0.000, 25.680], loss: 2.206753, mean_squared_error: 60.048409, mean_q: 9.640074\n",
      " 5324/6000: episode: 2110, duration: 0.094s, episode steps: 6, steps per second: 64, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.667 [0.000, 2.000], mean observation: 1.187 [0.000, 24.360], loss: 0.919146, mean_squared_error: 62.098801, mean_q: 9.685031\n",
      " 5334/6000: episode: 2111, duration: 0.131s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.100 [2.000, 3.000], mean observation: 1.311 [0.000, 29.760], loss: 1.431553, mean_squared_error: 61.096180, mean_q: 9.540760\n",
      " 5344/6000: episode: 2112, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.200 [0.000, 3.000], mean observation: 0.828 [0.000, 12.291], loss: 1.301524, mean_squared_error: 61.542503, mean_q: 9.576063\n",
      " 5354/6000: episode: 2113, duration: 0.128s, episode steps: 10, steps per second: 78, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.300 [0.000, 2.000], mean observation: 1.473 [0.000, 26.370], loss: 0.880142, mean_squared_error: 60.015343, mean_q: 9.549061\n",
      " 5355/6000: episode: 2114, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.602 [0.000, 33.130], loss: 0.689649, mean_squared_error: 63.481853, mean_q: 9.663583\n",
      " 5358/6000: episode: 2115, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.552 [0.000, 19.000], loss: 1.297931, mean_squared_error: 61.613216, mean_q: 9.704900\n",
      " 5360/6000: episode: 2116, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.374 [0.000, 27.880], loss: 1.818413, mean_squared_error: 61.081238, mean_q: 9.602489\n",
      " 5361/6000: episode: 2117, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.700 [0.000, 27.230], loss: 2.760228, mean_squared_error: 64.994034, mean_q: 9.709792\n",
      " 5362/6000: episode: 2118, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.632 [0.000, 19.371], loss: 1.271278, mean_squared_error: 57.423988, mean_q: 9.374092\n",
      " 5365/6000: episode: 2119, duration: 0.056s, episode steps: 3, steps per second: 53, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [2.000, 3.000], mean observation: 1.379 [0.000, 23.360], loss: 1.169078, mean_squared_error: 59.992352, mean_q: 9.497132\n",
      " 5366/6000: episode: 2120, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.534 [0.000, 21.620], loss: 2.204464, mean_squared_error: 58.381939, mean_q: 9.448061\n",
      " 5367/6000: episode: 2121, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.872 [0.000, 31.860], loss: 1.279810, mean_squared_error: 60.357765, mean_q: 9.587376\n",
      " 5377/6000: episode: 2122, duration: 0.131s, episode steps: 10, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.600 [1.000, 3.000], mean observation: 1.576 [0.000, 27.390], loss: 1.326948, mean_squared_error: 60.248005, mean_q: 9.524552\n",
      " 5384/6000: episode: 2123, duration: 0.312s, episode steps: 7, steps per second: 22, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.000 [0.000, 3.000], mean observation: 0.866 [0.000, 11.020], loss: 1.272098, mean_squared_error: 64.119278, mean_q: 9.738025\n",
      " 5386/6000: episode: 2124, duration: 0.126s, episode steps: 2, steps per second: 16, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.446 [0.000, 22.320], loss: 1.390420, mean_squared_error: 59.281498, mean_q: 9.476615\n",
      " 5396/6000: episode: 2125, duration: 0.211s, episode steps: 10, steps per second: 47, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.220 [0.000, 18.103], loss: 0.958801, mean_squared_error: 61.570526, mean_q: 9.686818\n",
      " 5404/6000: episode: 2126, duration: 0.181s, episode steps: 8, steps per second: 44, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.625 [0.000, 3.000], mean observation: 1.166 [0.000, 18.562], loss: 1.821743, mean_squared_error: 61.059177, mean_q: 9.567396\n",
      " 5405/6000: episode: 2127, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.242 [0.000, 16.170], loss: 1.098138, mean_squared_error: 66.224457, mean_q: 9.959722\n",
      " 5406/6000: episode: 2128, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.010 [0.000, 15.430], loss: 1.936970, mean_squared_error: 62.057571, mean_q: 9.554283\n",
      " 5407/6000: episode: 2129, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.043 [0.000, 36.030], loss: 2.530937, mean_squared_error: 58.526764, mean_q: 9.314546\n",
      " 5408/6000: episode: 2130, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.673 [0.000, 36.120], loss: 0.365179, mean_squared_error: 59.436844, mean_q: 9.447005\n",
      " 5410/6000: episode: 2131, duration: 0.033s, episode steps: 2, steps per second: 61, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.444 [0.000, 21.710], loss: 2.702372, mean_squared_error: 61.096252, mean_q: 9.550604\n",
      " 5411/6000: episode: 2132, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.687 [0.000, 39.780], loss: 0.210013, mean_squared_error: 59.059906, mean_q: 9.583345\n",
      " 5412/6000: episode: 2133, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.789 [0.000, 29.000], loss: 1.070722, mean_squared_error: 58.479980, mean_q: 9.445845\n",
      " 5422/6000: episode: 2134, duration: 0.255s, episode steps: 10, steps per second: 39, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.300 [1.000, 2.000], mean observation: 1.559 [0.000, 38.450], loss: 0.946572, mean_squared_error: 62.337990, mean_q: 9.645673\n",
      " 5423/6000: episode: 2135, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.537 [0.000, 36.790], loss: 0.190365, mean_squared_error: 61.382607, mean_q: 9.790469\n",
      " 5427/6000: episode: 2136, duration: 0.176s, episode steps: 4, steps per second: 23, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 2.000], mean observation: 1.269 [0.000, 18.451], loss: 1.640944, mean_squared_error: 58.700645, mean_q: 9.475067\n",
      " 5437/6000: episode: 2137, duration: 0.209s, episode steps: 10, steps per second: 48, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.300 [0.000, 3.000], mean observation: 1.378 [0.000, 35.570], loss: 1.735235, mean_squared_error: 62.059437, mean_q: 9.573241\n",
      " 5438/6000: episode: 2138, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.959 [0.000, 34.810], loss: 2.718277, mean_squared_error: 59.751194, mean_q: 9.453540\n",
      " 5440/6000: episode: 2139, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.414 [0.000, 19.660], loss: 1.297532, mean_squared_error: 60.113159, mean_q: 9.614676\n",
      " 5442/6000: episode: 2140, duration: 0.037s, episode steps: 2, steps per second: 53, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.456 [0.000, 18.000], loss: 1.147228, mean_squared_error: 55.822929, mean_q: 9.289284\n",
      " 5445/6000: episode: 2141, duration: 0.055s, episode steps: 3, steps per second: 55, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [1.000, 3.000], mean observation: 1.110 [0.000, 16.000], loss: 2.465963, mean_squared_error: 59.707516, mean_q: 9.563934\n",
      " 5451/6000: episode: 2142, duration: 0.091s, episode steps: 6, steps per second: 66, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.165 [0.000, 18.000], loss: 2.066174, mean_squared_error: 58.584194, mean_q: 9.350437\n",
      " 5452/6000: episode: 2143, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.058 [0.000, 19.000], loss: 2.427968, mean_squared_error: 66.318558, mean_q: 9.914360\n",
      " 5453/6000: episode: 2144, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.649 [0.000, 30.480], loss: 0.220404, mean_squared_error: 61.813980, mean_q: 9.835279\n",
      " 5454/6000: episode: 2145, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.874 [0.000, 12.000], loss: 1.474633, mean_squared_error: 63.256676, mean_q: 10.004188\n",
      " 5455/6000: episode: 2146, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.951 [0.000, 11.000], loss: 0.413051, mean_squared_error: 56.133862, mean_q: 9.393006\n",
      " 5458/6000: episode: 2147, duration: 0.049s, episode steps: 3, steps per second: 61, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.402 [0.000, 22.090], loss: 2.254084, mean_squared_error: 60.460827, mean_q: 9.567296\n",
      " 5462/6000: episode: 2148, duration: 0.079s, episode steps: 4, steps per second: 50, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.750 [1.000, 2.000], mean observation: 0.782 [0.000, 9.142], loss: 1.246814, mean_squared_error: 62.832253, mean_q: 9.674348\n",
      " 5463/6000: episode: 2149, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.755 [0.000, 38.310], loss: 0.449686, mean_squared_error: 55.545414, mean_q: 9.428707\n",
      " 5464/6000: episode: 2150, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.214 [0.000, 16.230], loss: 2.264003, mean_squared_error: 63.056438, mean_q: 9.535809\n",
      " 5465/6000: episode: 2151, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.218 [0.000, 14.967], loss: 2.362971, mean_squared_error: 63.645584, mean_q: 9.618513\n",
      " 5466/6000: episode: 2152, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.965 [0.000, 35.500], loss: 1.012417, mean_squared_error: 66.725601, mean_q: 10.010912\n",
      " 5476/6000: episode: 2153, duration: 0.142s, episode steps: 10, steps per second: 70, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.700 [0.000, 2.000], mean observation: 1.356 [0.000, 19.080], loss: 2.097847, mean_squared_error: 59.956459, mean_q: 9.473414\n",
      " 5486/6000: episode: 2154, duration: 0.143s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.500 [1.000, 3.000], mean observation: 1.408 [0.000, 18.430], loss: 0.861993, mean_squared_error: 61.305592, mean_q: 9.558874\n",
      " 5489/6000: episode: 2155, duration: 0.060s, episode steps: 3, steps per second: 50, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.803 [0.000, 32.900], loss: 1.401832, mean_squared_error: 58.188919, mean_q: 9.497281\n",
      " 5490/6000: episode: 2156, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.644 [0.000, 39.630], loss: 1.509323, mean_squared_error: 62.678398, mean_q: 9.801937\n",
      " 5494/6000: episode: 2157, duration: 0.089s, episode steps: 4, steps per second: 45, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 0.750 [0.000, 1.000], mean observation: 1.778 [0.000, 37.820], loss: 0.937271, mean_squared_error: 57.088345, mean_q: 9.357595\n",
      " 5495/6000: episode: 2158, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.189 [0.000, 17.360], loss: 0.231549, mean_squared_error: 57.866516, mean_q: 9.570944\n",
      " 5496/6000: episode: 2159, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.447 [0.000, 32.950], loss: 0.217184, mean_squared_error: 65.059792, mean_q: 9.853979\n",
      " 5497/6000: episode: 2160, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.252 [0.000, 19.531], loss: 1.945437, mean_squared_error: 63.060974, mean_q: 9.591421\n",
      " 5498/6000: episode: 2161, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.363 [0.000, 19.000], loss: 1.295764, mean_squared_error: 67.115036, mean_q: 9.969721\n",
      " 5499/6000: episode: 2162, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.189 [0.000, 16.535], loss: 0.171401, mean_squared_error: 61.133564, mean_q: 9.548140\n",
      " 5500/6000: episode: 2163, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.630 [0.000, 39.190], loss: 1.455386, mean_squared_error: 64.655563, mean_q: 9.774152\n",
      " 5501/6000: episode: 2164, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.112 [0.000, 18.000], loss: 0.329405, mean_squared_error: 57.478436, mean_q: 9.329276\n",
      " 5503/6000: episode: 2165, duration: 0.047s, episode steps: 2, steps per second: 42, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.269 [0.000, 18.451], loss: 1.336527, mean_squared_error: 60.349663, mean_q: 9.570934\n",
      " 5504/6000: episode: 2166, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [0.000, 19.081], loss: 1.191972, mean_squared_error: 60.767345, mean_q: 9.665465\n",
      " 5505/6000: episode: 2167, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.480 [0.000, 30.570], loss: 2.115126, mean_squared_error: 56.182728, mean_q: 9.241187\n",
      " 5512/6000: episode: 2168, duration: 0.098s, episode steps: 7, steps per second: 72, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.429 [0.000, 3.000], mean observation: 1.078 [0.000, 18.220], loss: 1.173026, mean_squared_error: 62.026882, mean_q: 9.639707\n",
      " 5517/6000: episode: 2169, duration: 0.072s, episode steps: 5, steps per second: 69, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.400 [1.000, 3.000], mean observation: 1.558 [0.000, 28.770], loss: 1.470730, mean_squared_error: 62.489220, mean_q: 9.703796\n",
      " 5518/6000: episode: 2170, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.607 [0.000, 39.400], loss: 1.261187, mean_squared_error: 67.174553, mean_q: 10.014360\n",
      " 5519/6000: episode: 2171, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.472 [0.000, 18.000], loss: 3.154037, mean_squared_error: 65.939171, mean_q: 9.759578\n",
      " 5520/6000: episode: 2172, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.093 [0.000, 14.970], loss: 0.329829, mean_squared_error: 59.539520, mean_q: 9.671305\n",
      " 5521/6000: episode: 2173, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.153 [0.000, 19.000], loss: 0.250376, mean_squared_error: 62.472641, mean_q: 9.868299\n",
      " 5527/6000: episode: 2174, duration: 0.085s, episode steps: 6, steps per second: 71, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.667 [0.000, 2.000], mean observation: 1.412 [0.000, 28.710], loss: 1.238707, mean_squared_error: 61.214970, mean_q: 9.638050\n",
      " 5528/6000: episode: 2175, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.162 [0.000, 14.642], loss: 1.522282, mean_squared_error: 63.372639, mean_q: 9.695282\n",
      " 5529/6000: episode: 2176, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.268 [0.000, 18.869], loss: 0.336771, mean_squared_error: 61.073410, mean_q: 9.561481\n",
      " 5531/6000: episode: 2177, duration: 0.042s, episode steps: 2, steps per second: 47, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.420 [0.000, 18.500], loss: 1.169181, mean_squared_error: 61.291668, mean_q: 9.622364\n",
      " 5532/6000: episode: 2178, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.498 [0.000, 29.280], loss: 0.192633, mean_squared_error: 56.928406, mean_q: 9.372009\n",
      " 5533/6000: episode: 2179, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.317 [0.000, 16.600], loss: 1.465331, mean_squared_error: 61.415039, mean_q: 9.455353\n",
      " 5535/6000: episode: 2180, duration: 0.036s, episode steps: 2, steps per second: 55, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.597 [0.000, 38.070], loss: 0.802026, mean_squared_error: 62.533508, mean_q: 9.742780\n",
      " 5539/6000: episode: 2181, duration: 0.068s, episode steps: 4, steps per second: 58, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.644 [0.000, 33.710], loss: 2.305768, mean_squared_error: 58.677216, mean_q: 9.336239\n",
      " 5540/6000: episode: 2182, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.335 [0.000, 19.000], loss: 0.133829, mean_squared_error: 58.919529, mean_q: 9.741294\n",
      " 5541/6000: episode: 2183, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.954 [0.000, 37.070], loss: 1.521602, mean_squared_error: 62.834930, mean_q: 9.636746\n",
      " 5542/6000: episode: 2184, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.089 [0.000, 19.450], loss: 1.836370, mean_squared_error: 68.808228, mean_q: 10.067137\n",
      " 5548/6000: episode: 2185, duration: 0.091s, episode steps: 6, steps per second: 66, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.833 [2.000, 3.000], mean observation: 1.304 [0.000, 19.837], loss: 0.814496, mean_squared_error: 61.151966, mean_q: 9.648406\n",
      " 5549/6000: episode: 2186, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.239 [0.000, 18.640], loss: 0.619608, mean_squared_error: 53.870430, mean_q: 9.169044\n",
      " 5550/6000: episode: 2187, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.463 [0.000, 22.430], loss: 0.222713, mean_squared_error: 60.696140, mean_q: 9.578032\n",
      " 5560/6000: episode: 2188, duration: 0.141s, episode steps: 10, steps per second: 71, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.155 [0.000, 15.264], loss: 1.564511, mean_squared_error: 61.589874, mean_q: 9.565908\n",
      " 5562/6000: episode: 2189, duration: 0.048s, episode steps: 2, steps per second: 41, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.711 [0.000, 32.860], loss: 1.312212, mean_squared_error: 59.176987, mean_q: 9.566473\n",
      " 5572/6000: episode: 2190, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.100 [0.000, 3.000], mean observation: 1.435 [0.000, 30.030], loss: 1.874199, mean_squared_error: 60.381836, mean_q: 9.519120\n",
      " 5574/6000: episode: 2191, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.890 [0.000, 12.310], loss: 0.605491, mean_squared_error: 58.151329, mean_q: 9.600368\n",
      " 5576/6000: episode: 2192, duration: 0.033s, episode steps: 2, steps per second: 60, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.208 [0.000, 19.903], loss: 0.723173, mean_squared_error: 63.354668, mean_q: 9.741091\n",
      " 5577/6000: episode: 2193, duration: 0.023s, episode steps: 1, steps per second: 43, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.205 [0.000, 19.300], loss: 2.243676, mean_squared_error: 59.606476, mean_q: 9.318167\n",
      " 5587/6000: episode: 2194, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.600 [0.000, 3.000], mean observation: 1.469 [0.000, 23.860], loss: 1.731331, mean_squared_error: 60.295288, mean_q: 9.507685\n",
      " 5597/6000: episode: 2195, duration: 0.136s, episode steps: 10, steps per second: 74, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.900 [1.000, 2.000], mean observation: 1.512 [0.000, 22.700], loss: 1.247158, mean_squared_error: 61.272400, mean_q: 9.654468\n",
      " 5598/6000: episode: 2196, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.541 [0.000, 24.570], loss: 2.022813, mean_squared_error: 57.035351, mean_q: 9.509544\n",
      " 5608/6000: episode: 2197, duration: 0.144s, episode steps: 10, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.156 [0.000, 16.729], loss: 1.542603, mean_squared_error: 60.214794, mean_q: 9.560963\n",
      " 5616/6000: episode: 2198, duration: 0.109s, episode steps: 8, steps per second: 73, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.375 [1.000, 3.000], mean observation: 1.107 [0.000, 12.840], loss: 1.280696, mean_squared_error: 61.105766, mean_q: 9.615888\n",
      " 5621/6000: episode: 2199, duration: 0.069s, episode steps: 5, steps per second: 72, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [1.000, 2.000], mean observation: 1.172 [0.000, 19.480], loss: 1.935306, mean_squared_error: 59.001740, mean_q: 9.481530\n",
      " 5631/6000: episode: 2200, duration: 0.137s, episode steps: 10, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.600 [0.000, 3.000], mean observation: 1.613 [0.000, 39.150], loss: 1.559861, mean_squared_error: 61.241741, mean_q: 9.614699\n",
      " 5632/6000: episode: 2201, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.677 [0.000, 23.780], loss: 1.456205, mean_squared_error: 66.282410, mean_q: 9.832039\n",
      " 5642/6000: episode: 2202, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 10.000, mean reward: 1.000 [0.000, 10.000], mean action: 1.900 [0.000, 3.000], mean observation: 1.367 [0.000, 17.890], loss: 1.291157, mean_squared_error: 61.704510, mean_q: 9.653635\n",
      " 5643/6000: episode: 2203, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.776 [0.000, 37.660], loss: 0.164089, mean_squared_error: 64.837784, mean_q: 9.752029\n",
      " 5645/6000: episode: 2204, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.409 [0.000, 23.620], loss: 1.002815, mean_squared_error: 65.072296, mean_q: 9.799934\n",
      " 5655/6000: episode: 2205, duration: 0.137s, episode steps: 10, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.300 [2.000, 3.000], mean observation: 1.601 [0.000, 37.290], loss: 1.312776, mean_squared_error: 60.737843, mean_q: 9.622784\n",
      " 5659/6000: episode: 2206, duration: 0.070s, episode steps: 4, steps per second: 57, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.250 [0.000, 3.000], mean observation: 1.815 [0.000, 31.530], loss: 1.778055, mean_squared_error: 57.463070, mean_q: 9.508137\n",
      " 5660/6000: episode: 2207, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.454 [0.000, 31.850], loss: 0.087658, mean_squared_error: 64.441978, mean_q: 9.800003\n",
      " 5662/6000: episode: 2208, duration: 0.044s, episode steps: 2, steps per second: 45, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.500 [2.000, 3.000], mean observation: 1.392 [0.000, 18.100], loss: 2.868721, mean_squared_error: 62.093960, mean_q: 9.582363\n",
      " 5667/6000: episode: 2209, duration: 0.081s, episode steps: 5, steps per second: 62, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.800 [0.000, 1.000], mean observation: 1.374 [0.000, 22.990], loss: 2.256140, mean_squared_error: 53.730438, mean_q: 9.039041\n",
      " 5670/6000: episode: 2210, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.025 [0.000, 12.930], loss: 1.379055, mean_squared_error: 60.707745, mean_q: 9.536903\n",
      " 5680/6000: episode: 2211, duration: 0.134s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 3.000], mean observation: 1.222 [0.000, 21.900], loss: 1.477448, mean_squared_error: 59.371784, mean_q: 9.552469\n",
      " 5681/6000: episode: 2212, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.761 [0.000, 29.880], loss: 1.550596, mean_squared_error: 55.845413, mean_q: 9.322784\n",
      " 5682/6000: episode: 2213, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.333 [0.000, 33.950], loss: 0.760350, mean_squared_error: 64.824501, mean_q: 9.867900\n",
      " 5683/6000: episode: 2214, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.157 [0.000, 19.680], loss: 0.472311, mean_squared_error: 57.023125, mean_q: 9.456599\n",
      " 5684/6000: episode: 2215, duration: 0.024s, episode steps: 1, steps per second: 41, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.771 [0.000, 10.982], loss: 0.798070, mean_squared_error: 62.080063, mean_q: 9.534694\n",
      " 5685/6000: episode: 2216, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.372 [0.000, 33.120], loss: 0.203357, mean_squared_error: 64.358261, mean_q: 9.731902\n",
      " 5686/6000: episode: 2217, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.089 [0.000, 18.000], loss: 1.031191, mean_squared_error: 58.543545, mean_q: 9.239382\n",
      " 5696/6000: episode: 2218, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.700 [0.000, 1.000], mean observation: 1.189 [0.000, 16.952], loss: 0.859153, mean_squared_error: 61.147888, mean_q: 9.645009\n",
      " 5706/6000: episode: 2219, duration: 0.148s, episode steps: 10, steps per second: 67, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.613 [0.000, 30.410], loss: 1.427699, mean_squared_error: 60.562031, mean_q: 9.561130\n",
      " 5707/6000: episode: 2220, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.118 [0.000, 17.730], loss: 1.151639, mean_squared_error: 58.377254, mean_q: 9.538556\n",
      " 5709/6000: episode: 2221, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.694 [0.000, 31.540], loss: 1.353514, mean_squared_error: 58.340240, mean_q: 9.371553\n",
      " 5710/6000: episode: 2222, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.191 [0.000, 21.150], loss: 1.424084, mean_squared_error: 53.504868, mean_q: 9.009607\n",
      " 5711/6000: episode: 2223, duration: 0.054s, episode steps: 1, steps per second: 18, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.967 [0.000, 18.906], loss: 0.276911, mean_squared_error: 63.967346, mean_q: 9.912262\n",
      " 5721/6000: episode: 2224, duration: 0.219s, episode steps: 10, steps per second: 46, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.430 [0.000, 25.570], loss: 1.018975, mean_squared_error: 62.182404, mean_q: 9.640300\n",
      " 5724/6000: episode: 2225, duration: 0.074s, episode steps: 3, steps per second: 40, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.337 [0.000, 23.810], loss: 0.856074, mean_squared_error: 63.002117, mean_q: 9.699791\n",
      " 5729/6000: episode: 2226, duration: 0.086s, episode steps: 5, steps per second: 58, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 2.800 [2.000, 3.000], mean observation: 1.666 [0.000, 28.290], loss: 1.233549, mean_squared_error: 61.229515, mean_q: 9.612268\n",
      " 5730/6000: episode: 2227, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.454 [0.000, 31.080], loss: 1.939155, mean_squared_error: 58.564899, mean_q: 9.443242\n",
      " 5732/6000: episode: 2228, duration: 0.060s, episode steps: 2, steps per second: 34, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 1.392 [0.000, 30.460], loss: 0.307788, mean_squared_error: 62.319149, mean_q: 9.605062\n",
      " 5733/6000: episode: 2229, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.954 [0.000, 34.240], loss: 1.304661, mean_squared_error: 50.950336, mean_q: 8.955568\n",
      " 5734/6000: episode: 2230, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 0.927 [0.000, 17.000], loss: 2.272961, mean_squared_error: 56.372749, mean_q: 9.122538\n",
      " 5735/6000: episode: 2231, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.757 [0.000, 34.320], loss: 1.074160, mean_squared_error: 60.685085, mean_q: 9.682053\n",
      " 5736/6000: episode: 2232, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.525 [0.000, 35.970], loss: 1.390291, mean_squared_error: 62.565392, mean_q: 9.664754\n",
      " 5737/6000: episode: 2233, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.731 [0.000, 18.820], loss: 1.241168, mean_squared_error: 64.005051, mean_q: 9.816460\n",
      " 5743/6000: episode: 2234, duration: 0.099s, episode steps: 6, steps per second: 61, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.500 [1.000, 3.000], mean observation: 1.623 [0.000, 31.600], loss: 1.081694, mean_squared_error: 62.080975, mean_q: 9.651637\n",
      " 5744/6000: episode: 2235, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.002 [0.000, 36.780], loss: 0.117761, mean_squared_error: 60.833050, mean_q: 9.571477\n",
      " 5745/6000: episode: 2236, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.472 [0.000, 26.900], loss: 2.887010, mean_squared_error: 59.190529, mean_q: 9.504847\n",
      " 5746/6000: episode: 2237, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.268 [0.000, 18.490], loss: 0.209852, mean_squared_error: 65.437958, mean_q: 9.990011\n",
      " 5748/6000: episode: 2238, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.420 [0.000, 25.550], loss: 2.284492, mean_squared_error: 62.397526, mean_q: 9.533845\n",
      " 5750/6000: episode: 2239, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.217 [0.000, 29.230], loss: 0.283141, mean_squared_error: 61.907898, mean_q: 9.613244\n",
      " 5751/6000: episode: 2240, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.951 [0.000, 33.580], loss: 0.083599, mean_squared_error: 65.719543, mean_q: 9.803461\n",
      " 5752/6000: episode: 2241, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.162 [0.000, 18.880], loss: 2.522110, mean_squared_error: 63.084511, mean_q: 9.600601\n",
      " 5753/6000: episode: 2242, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.265 [0.000, 25.430], loss: 1.526926, mean_squared_error: 68.054062, mean_q: 10.022675\n",
      " 5754/6000: episode: 2243, duration: 0.025s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.372 [0.000, 30.390], loss: 0.994955, mean_squared_error: 67.956116, mean_q: 9.917562\n",
      " 5755/6000: episode: 2244, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.148 [0.000, 16.960], loss: 0.425296, mean_squared_error: 52.886154, mean_q: 8.961556\n",
      " 5761/6000: episode: 2245, duration: 0.092s, episode steps: 6, steps per second: 65, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 1.833 [0.000, 3.000], mean observation: 1.557 [0.000, 21.980], loss: 1.164556, mean_squared_error: 59.671459, mean_q: 9.603810\n",
      " 5771/6000: episode: 2246, duration: 0.135s, episode steps: 10, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.800 [0.000, 2.000], mean observation: 1.507 [0.000, 27.620], loss: 1.407505, mean_squared_error: 61.103596, mean_q: 9.583338\n",
      " 5774/6000: episode: 2247, duration: 0.057s, episode steps: 3, steps per second: 53, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 2.333 [2.000, 3.000], mean observation: 0.976 [0.000, 16.000], loss: 1.091521, mean_squared_error: 62.102215, mean_q: 9.626694\n",
      " 5782/6000: episode: 2248, duration: 0.131s, episode steps: 8, steps per second: 61, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.750 [0.000, 3.000], mean observation: 1.580 [0.000, 31.390], loss: 1.036524, mean_squared_error: 61.984253, mean_q: 9.583781\n",
      " 5783/6000: episode: 2249, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.510 [0.000, 26.750], loss: 0.158869, mean_squared_error: 60.260628, mean_q: 9.739174\n",
      " 5787/6000: episode: 2250, duration: 0.084s, episode steps: 4, steps per second: 47, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.246 [0.000, 26.320], loss: 2.603177, mean_squared_error: 60.244923, mean_q: 9.551380\n",
      " 5788/6000: episode: 2251, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.482 [0.000, 30.790], loss: 2.012781, mean_squared_error: 60.943588, mean_q: 9.498457\n",
      " 5789/6000: episode: 2252, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.108 [0.000, 21.490], loss: 2.087490, mean_squared_error: 62.547913, mean_q: 9.770594\n",
      " 5790/6000: episode: 2253, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.742 [0.000, 28.120], loss: 1.192646, mean_squared_error: 62.754932, mean_q: 9.606451\n",
      " 5791/6000: episode: 2254, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.384 [0.000, 19.155], loss: 0.270942, mean_squared_error: 58.777191, mean_q: 9.556282\n",
      " 5792/6000: episode: 2255, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.012 [0.000, 15.556], loss: 1.067214, mean_squared_error: 58.394039, mean_q: 9.327770\n",
      " 5794/6000: episode: 2256, duration: 0.050s, episode steps: 2, steps per second: 40, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.229 [0.000, 15.051], loss: 0.788976, mean_squared_error: 60.350620, mean_q: 9.523335\n",
      " 5795/6000: episode: 2257, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.521 [0.000, 39.230], loss: 1.334733, mean_squared_error: 64.962036, mean_q: 9.989937\n",
      " 5796/6000: episode: 2258, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.514 [0.000, 25.490], loss: 0.214408, mean_squared_error: 59.204655, mean_q: 9.355103\n",
      " 5797/6000: episode: 2259, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.185 [0.000, 22.080], loss: 0.216652, mean_squared_error: 56.249390, mean_q: 9.291698\n",
      " 5801/6000: episode: 2260, duration: 0.062s, episode steps: 4, steps per second: 65, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.000 [0.000, 3.000], mean observation: 1.064 [0.000, 12.568], loss: 1.426158, mean_squared_error: 59.011368, mean_q: 9.535464\n",
      " 5802/6000: episode: 2261, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.347 [0.000, 27.580], loss: 1.644061, mean_squared_error: 61.221294, mean_q: 9.504433\n",
      " 5807/6000: episode: 2262, duration: 0.076s, episode steps: 5, steps per second: 66, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.200 [0.000, 3.000], mean observation: 1.265 [0.000, 30.890], loss: 1.006143, mean_squared_error: 61.361023, mean_q: 9.663415\n",
      " 5808/6000: episode: 2263, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.016 [0.000, 16.254], loss: 0.478572, mean_squared_error: 55.299747, mean_q: 9.178745\n",
      " 5809/6000: episode: 2264, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.544 [0.000, 35.880], loss: 1.722778, mean_squared_error: 60.591255, mean_q: 9.431183\n",
      " 5817/6000: episode: 2265, duration: 0.139s, episode steps: 8, steps per second: 58, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.875 [0.000, 3.000], mean observation: 1.441 [0.000, 25.750], loss: 1.384926, mean_squared_error: 62.656460, mean_q: 9.685034\n",
      " 5824/6000: episode: 2266, duration: 0.176s, episode steps: 7, steps per second: 40, episode reward: 10.000, mean reward: 1.429 [0.000, 10.000], mean action: 1.857 [0.000, 3.000], mean observation: 1.756 [0.000, 28.740], loss: 1.162511, mean_squared_error: 61.973396, mean_q: 9.662645\n",
      " 5825/6000: episode: 2267, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.183 [0.000, 22.240], loss: 2.302168, mean_squared_error: 66.111244, mean_q: 9.834812\n",
      " 5828/6000: episode: 2268, duration: 0.056s, episode steps: 3, steps per second: 54, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.333 [0.000, 1.000], mean observation: 1.194 [0.000, 19.210], loss: 0.988595, mean_squared_error: 61.525036, mean_q: 9.716674\n",
      " 5830/6000: episode: 2269, duration: 0.051s, episode steps: 2, steps per second: 39, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.737 [0.000, 29.610], loss: 1.927708, mean_squared_error: 63.846180, mean_q: 9.678648\n",
      " 5831/6000: episode: 2270, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.745 [0.000, 36.290], loss: 2.393846, mean_squared_error: 65.247437, mean_q: 9.909037\n",
      " 5832/6000: episode: 2271, duration: 0.024s, episode steps: 1, steps per second: 42, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.226 [0.000, 19.808], loss: 4.284457, mean_squared_error: 57.355839, mean_q: 9.349772\n",
      " 5834/6000: episode: 2272, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.865 [0.000, 35.370], loss: 1.596991, mean_squared_error: 61.989494, mean_q: 9.641642\n",
      " 5835/6000: episode: 2273, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.022 [0.000, 16.000], loss: 0.209682, mean_squared_error: 57.775078, mean_q: 9.533178\n",
      " 5836/6000: episode: 2274, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.332 [0.000, 19.978], loss: 1.387494, mean_squared_error: 63.513306, mean_q: 9.820802\n",
      " 5837/6000: episode: 2275, duration: 0.027s, episode steps: 1, steps per second: 36, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.546 [0.000, 28.980], loss: 1.640817, mean_squared_error: 63.841282, mean_q: 9.653552\n",
      " 5838/6000: episode: 2276, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.563 [0.000, 29.120], loss: 0.378369, mean_squared_error: 62.410797, mean_q: 9.714383\n",
      " 5839/6000: episode: 2277, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.986 [0.000, 17.585], loss: 0.077727, mean_squared_error: 64.542694, mean_q: 9.798711\n",
      " 5840/6000: episode: 2278, duration: 0.025s, episode steps: 1, steps per second: 40, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.654 [0.000, 38.710], loss: 0.803153, mean_squared_error: 51.836391, mean_q: 8.852003\n",
      " 5841/6000: episode: 2279, duration: 0.026s, episode steps: 1, steps per second: 39, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.075 [0.000, 32.410], loss: 1.647464, mean_squared_error: 59.458408, mean_q: 9.326620\n",
      " 5843/6000: episode: 2280, duration: 0.031s, episode steps: 2, steps per second: 64, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.164 [0.000, 20.100], loss: 1.913470, mean_squared_error: 62.892738, mean_q: 9.708279\n",
      " 5845/6000: episode: 2281, duration: 0.033s, episode steps: 2, steps per second: 61, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.726 [0.000, 33.070], loss: 1.647774, mean_squared_error: 60.476078, mean_q: 9.513428\n",
      " 5846/6000: episode: 2282, duration: 0.023s, episode steps: 1, steps per second: 44, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.145 [0.000, 24.970], loss: 0.191612, mean_squared_error: 65.012260, mean_q: 9.853128\n",
      " 5849/6000: episode: 2283, duration: 0.041s, episode steps: 3, steps per second: 73, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 2.000], mean observation: 1.359 [0.000, 23.900], loss: 1.257111, mean_squared_error: 60.474346, mean_q: 9.512901\n",
      " 5857/6000: episode: 2284, duration: 0.102s, episode steps: 8, steps per second: 79, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 1.125 [1.000, 2.000], mean observation: 1.298 [0.000, 18.000], loss: 0.991694, mean_squared_error: 62.089031, mean_q: 9.587615\n",
      " 5859/6000: episode: 2285, duration: 0.046s, episode steps: 2, steps per second: 44, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 0.500 [0.000, 1.000], mean observation: 1.824 [0.000, 36.550], loss: 1.358568, mean_squared_error: 59.857178, mean_q: 9.591751\n",
      " 5865/6000: episode: 2286, duration: 0.226s, episode steps: 6, steps per second: 27, episode reward: 10.000, mean reward: 1.667 [0.000, 10.000], mean action: 2.167 [0.000, 3.000], mean observation: 0.797 [0.000, 10.240], loss: 1.176678, mean_squared_error: 62.032658, mean_q: 9.624083\n",
      " 5875/6000: episode: 2287, duration: 0.283s, episode steps: 10, steps per second: 35, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 2.500 [1.000, 3.000], mean observation: 1.431 [0.000, 22.640], loss: 1.197457, mean_squared_error: 60.967480, mean_q: 9.555347\n",
      " 5880/6000: episode: 2288, duration: 0.244s, episode steps: 5, steps per second: 21, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.400 [0.000, 3.000], mean observation: 1.404 [0.000, 15.610], loss: 1.718645, mean_squared_error: 57.544441, mean_q: 9.449835\n",
      " 5881/6000: episode: 2289, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.137 [0.000, 27.910], loss: 1.013551, mean_squared_error: 55.460079, mean_q: 9.130539\n",
      " 5882/6000: episode: 2290, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.304 [0.000, 17.000], loss: 0.390041, mean_squared_error: 57.554810, mean_q: 9.330271\n",
      " 5883/6000: episode: 2291, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.282 [0.000, 16.769], loss: 0.146787, mean_squared_error: 62.714058, mean_q: 9.763805\n",
      " 5885/6000: episode: 2292, duration: 0.152s, episode steps: 2, steps per second: 13, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 2.000 [1.000, 3.000], mean observation: 1.038 [0.000, 14.000], loss: 1.404083, mean_squared_error: 63.169525, mean_q: 9.840165\n",
      " 5886/6000: episode: 2293, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.284 [0.000, 26.850], loss: 2.886802, mean_squared_error: 56.377052, mean_q: 9.229697\n",
      " 5887/6000: episode: 2294, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.164 [0.000, 17.170], loss: 1.918267, mean_squared_error: 56.051579, mean_q: 9.287824\n",
      " 5890/6000: episode: 2295, duration: 0.368s, episode steps: 3, steps per second: 8, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.333 [0.000, 3.000], mean observation: 1.737 [0.000, 29.610], loss: 0.632320, mean_squared_error: 59.502537, mean_q: 9.630789\n",
      " 5891/6000: episode: 2296, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.865 [0.000, 22.180], loss: 0.113518, mean_squared_error: 64.408142, mean_q: 9.912712\n",
      " 5892/6000: episode: 2297, duration: 0.069s, episode steps: 1, steps per second: 15, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.443 [0.000, 22.940], loss: 1.572550, mean_squared_error: 61.307407, mean_q: 9.551552\n",
      " 5893/6000: episode: 2298, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.060 [0.000, 13.050], loss: 0.096166, mean_squared_error: 61.184711, mean_q: 9.691893\n",
      " 5896/6000: episode: 2299, duration: 0.102s, episode steps: 3, steps per second: 30, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [0.000, 3.000], mean observation: 1.308 [0.000, 18.692], loss: 1.365416, mean_squared_error: 60.288849, mean_q: 9.562755\n",
      " 5897/6000: episode: 2300, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.956 [0.000, 38.710], loss: 1.817701, mean_squared_error: 70.941475, mean_q: 10.208820\n",
      " 5898/6000: episode: 2301, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.087 [0.000, 18.250], loss: 1.374550, mean_squared_error: 62.757851, mean_q: 9.622803\n",
      " 5908/6000: episode: 2302, duration: 0.252s, episode steps: 10, steps per second: 40, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.900 [0.000, 1.000], mean observation: 1.298 [0.000, 19.140], loss: 1.093758, mean_squared_error: 62.847759, mean_q: 9.699645\n",
      " 5918/6000: episode: 2303, duration: 0.233s, episode steps: 10, steps per second: 43, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.700 [0.000, 2.000], mean observation: 1.588 [0.000, 33.360], loss: 0.985167, mean_squared_error: 62.227478, mean_q: 9.661999\n",
      " 5919/6000: episode: 2304, duration: 0.152s, episode steps: 1, steps per second: 7, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.118 [0.000, 22.160], loss: 1.329665, mean_squared_error: 64.225395, mean_q: 9.808206\n",
      " 5929/6000: episode: 2305, duration: 0.226s, episode steps: 10, steps per second: 44, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.400 [1.000, 3.000], mean observation: 1.081 [0.000, 16.879], loss: 1.328815, mean_squared_error: 61.697144, mean_q: 9.678027\n",
      " 5934/6000: episode: 2306, duration: 0.109s, episode steps: 5, steps per second: 46, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 1.800 [0.000, 3.000], mean observation: 1.565 [0.000, 35.620], loss: 0.792798, mean_squared_error: 61.606525, mean_q: 9.696526\n",
      " 5937/6000: episode: 2307, duration: 0.073s, episode steps: 3, steps per second: 41, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.667 [1.000, 3.000], mean observation: 1.053 [0.000, 13.113], loss: 0.657484, mean_squared_error: 62.932419, mean_q: 9.745628\n",
      " 5938/6000: episode: 2308, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.259 [0.000, 24.090], loss: 0.276271, mean_squared_error: 57.543941, mean_q: 9.352392\n",
      " 5941/6000: episode: 2309, duration: 0.067s, episode steps: 3, steps per second: 45, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 0.667 [0.000, 1.000], mean observation: 1.247 [0.000, 17.970], loss: 0.191657, mean_squared_error: 65.338127, mean_q: 9.897916\n",
      " 5942/6000: episode: 2310, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.752 [0.000, 34.940], loss: 0.077830, mean_squared_error: 62.138382, mean_q: 9.713223\n",
      " 5943/6000: episode: 2311, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.897 [0.000, 19.800], loss: 2.452427, mean_squared_error: 51.212029, mean_q: 9.294431\n",
      " 5944/6000: episode: 2312, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.243 [0.000, 18.734], loss: 1.359343, mean_squared_error: 67.107903, mean_q: 9.947591\n",
      " 5945/6000: episode: 2313, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.095 [0.000, 19.000], loss: 2.695326, mean_squared_error: 63.321171, mean_q: 9.630861\n",
      " 5948/6000: episode: 2314, duration: 0.281s, episode steps: 3, steps per second: 11, episode reward: 10.000, mean reward: 3.333 [0.000, 10.000], mean action: 1.000 [0.000, 2.000], mean observation: 1.304 [0.000, 22.240], loss: 0.593684, mean_squared_error: 62.412510, mean_q: 9.759724\n",
      " 5949/6000: episode: 2315, duration: 0.088s, episode steps: 1, steps per second: 11, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.000 [0.000, 16.951], loss: 0.048168, mean_squared_error: 65.234871, mean_q: 9.746711\n",
      " 5953/6000: episode: 2316, duration: 0.098s, episode steps: 4, steps per second: 41, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 1.500 [0.000, 2.000], mean observation: 1.186 [0.000, 19.400], loss: 0.535974, mean_squared_error: 63.230133, mean_q: 9.763516\n",
      " 5954/6000: episode: 2317, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.698 [0.000, 9.000], loss: 1.257840, mean_squared_error: 67.647881, mean_q: 9.997986\n",
      " 5955/6000: episode: 2318, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.046 [0.000, 15.840], loss: 1.629882, mean_squared_error: 66.886887, mean_q: 9.856766\n",
      " 5957/6000: episode: 2319, duration: 0.169s, episode steps: 2, steps per second: 12, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.615 [0.000, 18.000], loss: 3.771723, mean_squared_error: 60.664314, mean_q: 9.562837\n",
      " 5965/6000: episode: 2320, duration: 0.199s, episode steps: 8, steps per second: 40, episode reward: 10.000, mean reward: 1.250 [0.000, 10.000], mean action: 2.500 [0.000, 3.000], mean observation: 1.153 [0.000, 15.710], loss: 1.198205, mean_squared_error: 61.801586, mean_q: 9.604867\n",
      " 5966/6000: episode: 2321, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [0.000, 18.177], loss: 1.815908, mean_squared_error: 64.125420, mean_q: 9.819805\n",
      " 5967/6000: episode: 2322, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.690 [0.000, 23.140], loss: 0.101178, mean_squared_error: 65.716873, mean_q: 9.898436\n",
      " 5968/6000: episode: 2323, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.788 [0.000, 35.280], loss: 4.028582, mean_squared_error: 58.842525, mean_q: 9.400617\n",
      " 5973/6000: episode: 2324, duration: 0.112s, episode steps: 5, steps per second: 45, episode reward: 10.000, mean reward: 2.000 [0.000, 10.000], mean action: 0.800 [0.000, 2.000], mean observation: 1.861 [0.000, 36.750], loss: 1.837593, mean_squared_error: 61.639488, mean_q: 9.629901\n",
      " 5975/6000: episode: 2325, duration: 0.066s, episode steps: 2, steps per second: 30, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [1.000, 2.000], mean observation: 0.939 [0.000, 14.420], loss: 1.992254, mean_squared_error: 56.065342, mean_q: 9.416887\n",
      " 5976/6000: episode: 2326, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.880 [0.000, 32.780], loss: 0.555587, mean_squared_error: 58.591438, mean_q: 9.509016\n",
      " 5977/6000: episode: 2327, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 1.701 [0.000, 32.670], loss: 1.146509, mean_squared_error: 59.426632, mean_q: 9.458698\n",
      " 5978/6000: episode: 2328, duration: 0.070s, episode steps: 1, steps per second: 14, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.795 [0.000, 31.870], loss: 1.166555, mean_squared_error: 57.682983, mean_q: 9.232349\n",
      " 5982/6000: episode: 2329, duration: 0.161s, episode steps: 4, steps per second: 25, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [1.000, 3.000], mean observation: 1.555 [0.000, 29.940], loss: 1.855454, mean_squared_error: 60.211864, mean_q: 9.500147\n",
      " 5983/6000: episode: 2330, duration: 0.064s, episode steps: 1, steps per second: 16, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.379 [0.000, 29.980], loss: 2.555398, mean_squared_error: 58.405499, mean_q: 9.247605\n",
      " 5984/6000: episode: 2331, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.552 [0.000, 37.790], loss: 3.413582, mean_squared_error: 67.313980, mean_q: 9.865051\n",
      " 5985/6000: episode: 2332, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.246 [0.000, 19.000], loss: 0.458810, mean_squared_error: 54.277748, mean_q: 9.152992\n",
      " 5986/6000: episode: 2333, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 0.782 [0.000, 9.142], loss: 0.126693, mean_squared_error: 61.018818, mean_q: 9.752771\n",
      " 5987/6000: episode: 2334, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.285 [0.000, 26.960], loss: 2.549293, mean_squared_error: 63.146358, mean_q: 9.672596\n",
      " 5988/6000: episode: 2335, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 1.000 [1.000, 1.000], mean observation: 1.643 [0.000, 39.250], loss: 1.332988, mean_squared_error: 60.387817, mean_q: 9.545965\n",
      " 5989/6000: episode: 2336, duration: 0.036s, episode steps: 1, steps per second: 27, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.230 [0.000, 16.860], loss: 0.407965, mean_squared_error: 55.661255, mean_q: 9.236095\n",
      " 5990/6000: episode: 2337, duration: 0.041s, episode steps: 1, steps per second: 25, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 0.000 [0.000, 0.000], mean observation: 1.622 [0.000, 19.539], loss: 2.538924, mean_squared_error: 61.050838, mean_q: 9.380608\n",
      " 5991/6000: episode: 2338, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 2.000 [2.000, 2.000], mean observation: 1.182 [0.000, 20.290], loss: 2.220358, mean_squared_error: 61.611202, mean_q: 9.482422\n",
      " 5993/6000: episode: 2339, duration: 0.060s, episode steps: 2, steps per second: 33, episode reward: 10.000, mean reward: 5.000 [0.000, 10.000], mean action: 1.500 [0.000, 3.000], mean observation: 1.598 [0.000, 19.978], loss: 0.895673, mean_squared_error: 59.757648, mean_q: 9.564131\n",
      " 5997/6000: episode: 2340, duration: 0.072s, episode steps: 4, steps per second: 56, episode reward: 10.000, mean reward: 2.500 [0.000, 10.000], mean action: 2.250 [0.000, 3.000], mean observation: 1.482 [0.000, 19.000], loss: 0.823997, mean_squared_error: 59.800667, mean_q: 9.427529\n",
      " 5998/6000: episode: 2341, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: 10.000, mean reward: 10.000 [10.000, 10.000], mean action: 3.000 [3.000, 3.000], mean observation: 0.963 [0.000, 14.000], loss: 0.140596, mean_squared_error: 62.548073, mean_q: 9.748810\n",
      "done, took 105.493 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113211d10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "\n",
    "\n",
    "LOG_TIME = time.strftime(\"%m%d_%H%M%S\")\n",
    "ENV_NAME = 'mc_mat-v1'\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "env.configure(nround=2, esb_log='esb_log_'+LOG_TIME+'.csv') ####  nround 的大小!!!!!!!!!!!!!!!!!!\n",
    "# np.random.seed(123)\n",
    "# env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,40)))\n",
    "model.add(Dense(164, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(150, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4, init='lecun_uniform'))\n",
    "model.add(Activation('linear')) #linear output so we can have range of real-valued outputs\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=5000, window_length=1)\n",
    "policy = EpsGreedyQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=4, memory=memory,target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(RMSprop(), metrics=['mse'])\n",
    "# dqn.compile(Adam(lr=.00025), metrics=['mse'])\n",
    "\n",
    "# checkpoint_weights_filename = 'dqn_' + ENV_NAME + '_weights_{step}.h5f'\n",
    "log_filename = 'dqn_log_'+LOG_TIME+'.json'\n",
    "\n",
    "# callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=500)]\n",
    "# callbacks += [FileLogger(log_filename, interval=100)]\n",
    "callbacks = [FileLogger(log_filename)]\n",
    "NSTEP=60\n",
    "dqn.fit(env, nb_steps=NSTEP, callbacks=callbacks, verbose=2, log_interval=100)\n",
    "env.configure(esb_log='esb_log_'+LOG_TIME+'.csv',save_esb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "env.configure(esb_log='esb_log_'+LOG_TIME+'.csv',save_esb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-15 13:39:11,759] Making new env: mc_mat-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0) <type 'tuple'>\n",
      "Reward: 0, Info: {'ob_dense': [9.2349999999999994, 30.59, 7.2429999999999994, 7]}\n",
      "=====\n",
      "(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0) <type 'tuple'>\n",
      "Reward: 0, Info: {'ob_dense': [0.89200000000000002, 25.98, 12.195, 6]}\n",
      "=====\n",
      "(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0) <type 'tuple'>\n",
      "Reward: 0, Info: {'ob_dense': [10.057, 8.8900000000000006, 16.838000000000001, 10]}\n",
      "=====\n",
      "(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0) <type 'tuple'>\n",
      "Reward: 0, Info: {'ob_dense': [6.3860000000000001, 19.530000000000001, 5.2649999999999997, 17]}\n",
      "=====\n",
      "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0) <type 'tuple'>\n",
      "Reward: 0, Info: {'ob_dense': [19.187000000000001, 14.91, 10.999000000000001, 18]}\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('mc_mat-v1')\n",
    "env.configure(nround=2)\n",
    "\n",
    "for t in range(5):\n",
    "    observation = env.reset()\n",
    "    print observation, type(observation)\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print 'Reward: {}, Info: {}'.format(reward, info)\n",
    "#     print info['esb'][int(action)]\n",
    "    print '='*5  \n",
    "env.configure(close_mat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-06 17:57:20,131] Making new env: mc_mat-v1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.18740161, -0.36930504, -0.21524395,  0.13491149]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('mc_mat-v1')\n",
    "env.configure(nround=2)\n",
    "model = Sequential()\n",
    "model.add(Dense(164, init='lecun_uniform', input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2)) I'm not using dropout, but maybe you wanna give it a try?\n",
    "model.add(Dense(150, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(4, init='lecun_uniform'))\n",
    "model.add(Activation('linear')) #linear output so we can have range of real-valued outputs\n",
    "rms = RMSprop()\n",
    "model.compile(loss='mse', optimizer=rms)\n",
    "model.predict(np.array(env.reset()).reshape(1,40), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1125de1d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFxCAYAAACBRDVoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwMZ9COFBk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1125de1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import json\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "log1 = 'dqn_mc_mat-v1_log.json'\n",
    "log2 = 'dqn_log_0315_150655.json'\n",
    "log3 = 'dqn_log_0315_155105.json'\n",
    "log4 = 'dqn_log_0315_160250.json'\n",
    "log5 = 'dqn_log_0315_162147.json'\n",
    "\n",
    "for i in [log1,log2,log3,log4,log5]:\n",
    "    filename = i\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    episodes = data['episode']\n",
    "    # Get value keys. The x axis is shared and is the number of episodes.\n",
    "    keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "    reward = data['episode_reward']\n",
    "    reward_mean = [sum(reward[:index])/(index+1) for index in range(len(reward))]\n",
    "    fig = plt.plot(episodes[:2000],reward_mean[:2000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABcsAAA2cCAYAAADB8JL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f3c4a2310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "def visualize_log(filename, figsize=None, output=None):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    if 'episode' not in data:\n",
    "        raise ValueError('Log file \"{}\" does not contain the \"episode\" key.'.format(filename))\n",
    "    episodes = data['episode']\n",
    "\n",
    "    # Get value keys. The x axis is shared and is the number of episodes.\n",
    "    keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (15., 5. * len(keys))\n",
    "    f, axarr = plt.subplots(len(keys), sharex=True, figsize=figsize)\n",
    "    for idx, key in enumerate(keys):\n",
    "        axarr[idx].plot(episodes, data[key])\n",
    "        axarr[idx].set_ylabel(key)\n",
    "    plt.xlabel('episodes')\n",
    "    plt.tight_layout()\n",
    "    if output is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(output)\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('filename', type=str, help='The filename of the JSON log generated during training.')\n",
    "# parser.add_argument('--output', type=str, default=None, help='The output file. If not specified, the log will only be displayed.')\n",
    "# parser.add_argument('--figsize', nargs=2, type=float, default=None, help='The size of the figure in `width height` format specified in points.')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# You can use visualize_log to easily view the stats that were recorded during training. Simply\n",
    "# provide the filename of the `FileLogger` that was used in `FileLogger`.\n",
    "visualize_log(log_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'duration', u'episode_reward', u'loss', u'mean_q', u'mean_squared_error', u'nb_episode_steps', u'nb_steps']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10fdd0b10>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFVCAYAAADCLbfjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQAIif8P0nlHUAf/n44AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1119304d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import json\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_style('darkgrid')\n",
    "log_filename='dqn_mc_mat-v1_log.json'\n",
    "filename = log_filename\n",
    "with open(filename, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "episodes = data['episode']\n",
    "\n",
    "# Get value keys. The x axis is shared and is the number of episodes.\n",
    "keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "print keys\n",
    "reward = data['episode_reward']\n",
    "reward_mean = [sum(reward[:index])/(index+1) for index in range(len(reward))]\n",
    "plt.plot(episodes[:10000],reward_mean[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'duration', u'episode_reward', u'loss', u'mean_q', u'mean_squared_error', u'nb_episode_steps', u'nb_steps']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEeCAYAAADFHWEmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUVBgQCIioqDw/wHExKFMx9NVwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11db489d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "# %matplotlib inline\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "filename = log_filename\n",
    "with open(filename, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "episodes = data['episode']\n",
    "\n",
    "# Get value keys. The x axis is shared and is the number of episodes.\n",
    "keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "print keys\n",
    "reward = data['episode_reward']\n",
    "smoothed = np.convolve(reward, np.ones(100)/100)\n",
    "\n",
    "# reward_mean = [sum(reward[:index])/(index+1) for index in range(len(reward))]\n",
    "plt.plot(episodes[:5000],smoothed[:5000]);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'duration', u'episode_reward', u'loss', u'mean_q', u'mean_squared_error', u'nb_episode_steps', u'nb_steps']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11c8dc1d0>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEeCAYAAAC6zHPXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAAIABJREFUeJztnXmYFNXV/7/VPfswM8AMM8MiA7LKJvsiyqoIwsiiRCIx\nolFBjUZNYqL5RYlviHFD9MWY5DWCRiMKIq4QRRYddpR9G3YYYJh9X7u7fn/0VPetqltL9/RWzPk8\nDw/T3dVVp2u5555zzyKIoiiCIAiCIEKELdwCEARBEC0LUjwEQRBESCHFQxAEQYQUUjwEQRBESCHF\nQxAEQYQUUjwEQRBESCHFQxAEQYQUU4pn9erVmDp1KrKzs/Hiiy8GWyaCIAjiCsZQ8dTW1uL555/H\ne++9h08//RS7d+/Gtm3bQiEbQRAEcQViqHgEQUBsbCxqa2vR2NgIh8OBuLi4UMhGEARBXIFEGW0Q\nFxeH+++/H1OmTEF8fDyGDx+OQYMGhUI2giAI4grE0OLZvXs3Vq5ciU2bNuH777+HIAh4++23DXdM\nJeAIgiAIHoYWz969ezFmzBi0adMGADBr1ix88MEHuPfee3W/JwgCiosrYTX9IwhAamqS5WS3qtyA\ndWW3qtyAdWW3qtyAdWWX5A4khoqnf//+WLRoEX75y18iPj4eGzZsQN++fU3tXBRhqRPMYlXZrSo3\nYF3ZrSo3YF3ZrSo3YG3ZA4Wh4hkxYgRmzZqF2267DdHR0ejXrx8eeOCBUMhGEARBXIEYKh4AmDdv\nHubNmxdkUQiCIIiWAFUuIAiCIEIKKR6CIAgipJDiIQiCIEJK0BVPbb0DX+86j/LqhmAfiiAIgrAA\nQVc8H244jhXfHseSlfuCfSiCIAjCAgRd8Zy8UAEAOJtfGexDEQRBEBaA1ngIgiCIkBJ0xXOhqDrY\nhyAIgiAsBFk8BEEQREghxUMQBEGEFFI8BEEQREghxUMQBEGEFFI8BEEQREghxUMQBEGEFFI8BEEQ\nREgJqeJZvvZIKA9HEARBRCAhVTzf7bsUysMRBEEQEQi52giCIIiQElTFI4piMHdPEARBWJAgK55g\n7p0gCIKwIkFVPC7SPARBEISC4CoeFykegiAIQg5ZPARBEERICbLFE8y9EwRBEFaELB6CIAgipARV\n8ew7URTM3RMEQRAWJMpogxUrVmDFihUQBAGiKOLixYsYP348XnjhBcOdbz2YHxAhCYIgiCsHQ8Uz\nZ84czJkzBwBw5swZ3HffffjNb35jaucU1UYQBEEo8cnV9txzz+HRRx9Fu3btTG1/PK/cL6EIgiCI\nKxfTimf37t0oLi7GrbfeanrnToXFk5wYgwtF1aiobjAvIUEQBHFFYehqk/jggw9wzz33NOtgFdUN\n+ONbOwAAy56a0Kx9BQtBkP9vFawqN2Bd2a0qN2Bd2a0qN2Bd2YMhryCaqOTpcDgwZswYrF+/HgkJ\nCaZ3/otF36CgpIb72eevTDcvJUEQBHHFYMriyc3NRVZWlk9KBwD+312D8ehrOdzPiooqfdpXqBAE\nIDU1CcXFlZYqcmpVuQHrym5VuQHrym5VuQHryi7JHUhMKZ5z586hQ4cOPu88KSEGf3tiDB5a/J3q\ns0g/8aIY+TLysKrcgHVlt6rcgHVlt6rcgLVlDxSmggsmT56MV155xa8DxMVE4ddzBvr1XYIgCOLK\nIyQdSPtktQnFYQiCIAgLEBLFI1gtjIMgCIIIGiFRPARBEAQhQYqHIAiCCCmkeAiCIIiQQoqHIAiC\nCCkhUzx9ulBkG0EQBBFCxWOzySPbTFTqIQiCIK5AQqZ47IJS8YTqyARBEEQkETrFY5cfqtHhCtWh\nCYIgiAgibK62ukZnqA5NEARBRBAhUzxRSsXT4AjVoQmCIIgIImwWj4NcbQRBEC2SsCkeFwUXEARB\ntEhCp3gUUW0u0jwEQRAtkpApHmXejoviqQmCIFokIVM8h8+UyF6T4iEIgmiZhEzxVNY2yl6LFFtA\nEATRIgmZ4snKSJK9JouHIAiiZRIyxaPsQUq12giCIFomoWuLQFFtBEEQBMJo8ZDeIQiCaJmETPEk\nxEXJXtMaD0EQRMskZIqnbXKc7DW52giCIFomoXO1KXxtZPEQBEG0TEK4xqMMLgjVkQmCIIhIImwW\nD4VTEwRBtExMKZ4NGzZg1qxZuOWWW7Bo0aKAHJhcbQRBEC0TQ8Vz/vx5LFy4EH//+9/x+eef48iR\nI9i8ebPPB7LbKY+HIAiCAKKMNli/fj2mTp2K9PR0AMCrr76KmJgYnw80eXhnHDpVgstltahvcJLF\nQxAE0UIxVDxnz55FTEwM7rvvPhQWFmL8+PF47LHHTO2cXddJTozBn34xHO99nYtvf8iDKKrXfSIB\nSaZIlE0Pq8oNWFd2q8oNWFd2q8oNWFf2YMhrqHicTidycnLw/vvvIzExEQ8++CDWrFmDGTNmGO48\nNTVJ9V5igttaSkiMRVqa+vNIgSe7FbCq3IB1Zbeq3IB1Zbeq3IC1ZQ8UhoonLS0No0aNQps2bQAA\nEydOxP79+00pnuLiSig9avX17vYIFRW1KCqq9EPk4CII7huDJ3skY1W5AevKblW5AevKblW5AevK\nLskdSAwVz/jx4/Hkk0+isrISCQkJyMnJwYQJE0ztXBShOsFCk93mcokRffJ5slsBq8oNWFd2q8oN\nWFd2q8oNWFv2QGGoeAYMGIAHHngAd955JxwOB6677jrcdtttfh/QJimeFn7iCYIgWiqGigcAZs2a\nhVmzZgXkgGfzKwAA73+Ti4lDOgVknwRBEIR1CF0/niYOnSkN9SEJgiCICCLkiocgCIJo2ZDiIQiC\nIEIKKR6CIAgipIRc8Vw/oH2oD0kQBEFEECFXPDNvuBoAkNEmPtSHJgiCICKAkCseu82dx9PSE6gI\ngiBaKiFXPDablEBKmocgCKIlEnrF01S5wEmlCwiCIFokYXO1USM4giCIlgm52giCIIiQEgbF4/6f\nLB6CIIiWSdjWeBykeAiCIFokIVc8giAgJtqGhgZnqA9NEARBRABhKZljt9kggtZ5CIIgWiJhUTxN\n8QW0zkMQBNECCY/i8VQvIMVDEATR0giTxUNJpARBEC2VsFo8Llc4jk4QBEGEk/Cu8ZCrjSAIosUR\nXouHFA9BEESLI6xrPCKt8RAEQbQ4wmzxhOPoBEEQRDgJq8VDeTwEQRAtj7AoHkGgNR6CIIiWSphc\nbe7/yeIhCIJoeUSZ2eiJJ57A4cOHER8fDwB4+OGHceONN/p9UBtZPARBEC0WU4rn0KFDWLlyJZKT\nkwNyUBt1ISUIgmixGLraysrKUFJSgieffBK33norli5d2vyDChTVRhAE0VIxVDzFxcUYPXo0Xnzx\nRXz00UfYtWsXVq9e3byDUnVqgiCIFouhq61bt25YsmSJ5/Vdd92Fzz77DLNmzTLceZNho8JTnRqi\n5jbhQpIn0uQywqpyA9aV3apyA9aV3apyA9aVPRjyGiqegwcPorCwEOPHjwcAuFwu2O12UztPTU3i\nvh8XGw0ASEqOR1oaf5twoyV7pGNVuQHrym5VuQHrym5VuQFryx4oDBVPY2Mjnn/+eQwfPhzR0dFY\nsWIFbr/9dlM7Ly6uBC9wraauAQBw7kIZ0hKjfZM4yAiC+8bQkj1SsarcgHVlt6rcgHVlt6rcgHVl\nl+QOJIaKZ9CgQbjzzjsxe/ZsOJ1OTJ48GbfccoupnYsiNBSP031wuy1iL4CW7JGOVeUGrCu7VeUG\nrCu7VeUGrC17oDAVTj1v3jzMmzcvYAftkJaAvMIq6kBKEATRAglzyZxwHJ0gCIIIJ2FSPO7/yeIh\nCIJoeYRH8aApnJr0DkEQRIsjLIrn8JkSAMDZ/MpwHJ4gCIIII2FRPOXV7nDqz7eeCcfhCYIgiDAS\nFsVDEARBtFxI8RAEQRAhhRQPQRAEEVJI8RAEQRAhhRQPQRAEEVLCqnhio81VuSYIgiCuHMKieH4y\nvjsAYPzgjuE4PEEQBBFGwqJ44mKaLB2qXEAQBNHiCIvikTqQuqhmDkEQRIsjrEVCXVSemiAIosUR\nHotHIIuHIAiipRJmV1s4jk4QBEGEk/BaPKR5CIIgWhwUXEAQBEGElDA1gnMjksVDEATR4iCLhyAI\ngggpYY5qC8fRCYIgiHASJovH/T8FFxAEQbQ8KI+HIAiCCCnhCS6wUTg1QRBESyWsFg8ZPARBEC2P\nMCke9//kaiMIgmh5+KR4XnjhBTz11FPNP2iT5tl/srjZ+yIIgiCshWnFs23bNqxZsyYwB5XKUxME\nQRAtDlOKp6ysDEuWLMGCBQsCctD6RmdA9kMQBEFYjygzGz377LN44okncPHiRZ92rmXYxETbDbcJ\nF5I8kSaXEVaVG7Cu7FaVG7Cu7FaVG7Cu7MGQ11DxrFy5Eh06dMCIESPwySef+LTz1NQk7vtFVY2e\nv9u2beVZ84kktGSPdKwqN2Bd2a0qN2Bd2a0qN2Bt2QOFoeJZu3YtCgsLsW3bNpSXl6OmpgaLFi3C\nH/7wB8OdFxdXckOmy8pqPH8XFlXAbgtLcB0XQXDfGFqyRypWlRuwruxWlRuwruxWlRuwruyS3IHE\nUPG8/fbbnr8/+eQT7Ny505TSAdx5OrwTzL7ldHrDqyMJLdkjHavKDVhXdqvKDVhXdqvKDVhb9kAR\ndlODcnkIgiBaFqaCCyRmzpyJmTNnNvugdsbEEUnxEARBtCjCYvFkZXr9hS5XOCQgQkmjw4mPNpzA\n6UsV4RaFIIgIIGy12lKT4wCQq60l8NX2c1i38xz+553d4RaFIIgIIGxrPHaTXUgrahrwze7zqKlz\nhEIsIgh8v9+3/C+CIK5swqZ4zLZG+Mu7P+CD9cfx7Ns7QyEWEQScFmx/0UDVNQgiaITf4jEYlArK\nagEAxRV1QZeJpbSyHodOl4T0mDwqahqw70SRpYMwhvVOD7cIPnE8rwwLXtmMT747FW5RCOKKJGyK\nx9OFNEJnw79eugWvfLgXJy+Wh1WO5//9A15btR8b91wIqxzNIb11fLhF8In/7jwPAPh865nwCkIQ\nVyjhUzxNR3b6MJMP5axfOtL5gqqQHZPH5VK3xZd7viyscjQHwWLFqaxsXRKEFYh4VxtLzoFLwRJH\nk0gZg6w2eBMEQWgRRovHPZD6svC84/DlYImjTaRoHovy1heH8f43ueEWwyfokhP+IIoi7v3rBtz7\n1w3hFiXisdQaT3Vt6EOqI3QJyhKIooitB/PDLQZBhIS8wmrP35SfqE/YFc/2Q+atmLOXK4Mljibl\n1Q0hP6YZrLAOYQERuVjh3BKRBzuJdjrlJVlEUaT7iiFsiud0vrt8yrqd50x/Z2iIwnIvFXlnLvYI\nLJ1dXF6HhxZ/hy+3nQm3KLpYddZnxbwjIvyITN195T30+qr9+OO/dkZsFG+oCZviaXR4ZwRn881Z\nMhltQhOW+/HG456/w9mkroTJXWJnS+t/OI/6Ric+3hzZeSYW1Tue3DGC8Belgtl3shgXCqtRU9eo\n8Y2WRdij2gDgT8t3mfpOqAK7YpnW3OE0eC6V1HDft8qAznMtVNREpuuSJdoe9m4hLZ6PNpzASx/s\ngdOiVYS1rGaLPLpBJ2xPmMPpzyUIjRaIYRTP9/suobyqPiTHVVJr8fp0PAVZV+/AwdPFOJEX3sRc\nPez2yHOvtjTW7TyHI2dLcamIP/mKRNj7nbV4vtvnrVXocFpTkQYamtopaHQ4sWqD19VWUFaL974O\nTzjwu/89Fpbj+gvrPgX4azz1jS4s/nAf/vLeD6ESi7AwQgSusZqBNXiWrz3q+Vv5jLRULKV42JlD\nsPgxt0j13g+5hUE/Lo+qWr4/OBJdbf/8/BDmv7wJf/vkgO52DY7IL755uYTWeAjf2X20wPO3FNWm\ndBXOf/5bze+7RBFHzpaitt7ang4zWErxVFQ3BH3hN1JNYXamJEagp1gKi999zKukeWs8Tr9crKGl\nnipTRwxWCkFeu8MbobvnuHsCu+WAPI9Nb3zZsv8SXvpgD179aF9wBIwgwqZ4oqOMD80zS1/+YE8w\nxPGQGBcd1P37C2v9WOVZ5K2vNkaoYpew0kB3pcK6aK0afnz4jLuy/fc+eGkONFXDP3Ehctc/A0XY\nFE+UiQVc3syzqLwuqINDpJZEq7ZgoAEvTD7SfdwNES5fS4C1iq06D5Asm5MXzbd7t+hyll+ETfGM\nuCbDcJvzGpUK9h5Xr8MEinyNEOZwc7EpqTXSB26WVz7cq3rv9VX7PX9HYoJppLvZGh3OK94qY91R\nm0OwrhsMGi3gUg4nYVM8cyb2MNzmk5zT3PcLg7jOs+LbE0Hbty9UcvJdauocmP/yJnz7Q14YJAo8\nkehGcUSwYi+pqMP8lzfjH58dCrcoQYXNgdlkkT5U5xSTZH8miC2pAn3YFA+bK6OFVq5HS7hAbAim\nhFRmKNIx2zY6EgMN2MikSENasN55JHJlDATKOmdWYOEyeRK8XhCBllJqAcOaB0tFtUlE2gUqraxH\nRYCLie7huBPFCLQQeJh1V0ViTbRjFm64d6UQgbeFz3TvlKL52elL6glkfaMz7E0nQ4klFc+6nedQ\nHeKaR1rrEaIo4tdvbMFj/5sTdBkicaCWYKMUzbrQIrEcivIcX+nrKYHiTH4F/rvzXEDW7SLxvvCV\nDqmJmp/xLJ531x3FBaatwpWOJRVPSUU93l0X2qx+rSZ0/pX+8Y9IXBORYB8mswoy0FZiIFC6SIrK\n6zS2bD7bDubj5RV7Ij6gwQyvrdqPDzecwP6Txc3el5nb5/CZEvzPO7tQFKEFXZVrPiw8N9w2H9rD\nXAmYUjwvv/wypk6diuzsbCxfvjzIIpmDZ64Gk8sa0W6hTDgNxGyy0eHCjsOXg2oxmlU8kVgFWjmR\nCGYgx/99cRiHz5QiZ3/oW7oHElEUUV7lnkQUB0BRm5lgvfTBXpy+VBkxpZeU6SHxsVGa2wbSc3Ho\nTIkn4tVKGCqezZs3Y9++ffjiiy+watUq/Pvf/8aZM2eCLlikze6lQV/pegmt4mn+Pr7ZfR7/+OwQ\nlqz0LTv6wKliLF97xNTv5T1YGW0TVO819xoHo7lWu9ZxstdXd0gO6P55WClEnscPTLWKQPSv8uW+\nCIcnlHffdUxrJXv99a7zmt9XPkOnfMj1YSmpqMMrK/bi/721w6/vhxNDxTN27FgsX74cgiCgqKgI\nLpcL8fHB74tz7Fyp5++/zh8Z9ONJDOyexn1fFIHqukY8+eY2fLTRG3LNzpCDnZcSCGWc27R4fvKC\nbzf7qx/tw3f7LiHnAH92npbiHbC5iofTS6m5bspfvLARv3hhY0Ct335dU01t53C6cPJCeUBmr2aD\nZZpz/SV5m7OPorJa7DxyWTVwsuc/EP2rzDxH4QwwWvzhXjz/3o8y5ePLs6+caPz53d1+yVFS6a2a\n76/yChemXG12ux1LlizB1KlTMXLkSGRkGCd/Au6bQ+9fckK05rb1TDHJuBh+6LXR/v35Fx+nHeb9\n/te5KK6ow7od5zzbu5iFUFEUAyaH7Hc2/c+7udnv5J4rbepKqi2Hjdm5P/KUVzVwP2fXQqTzINGn\nSxvu+XS5XLL9+3uOXv1oX8DOu3Im69K4piu+PY4/v/sDVnx9rNnX2Oz27KK7r8d6/5tcLPr3D1i7\n46zf5/zJv2/D3z89hHfWHZWfM+Z82WyBvwa88yZtEqjrbv6aiTh0phQnLpTjUkmNpsyA+3olJ8YA\nAH4zZ6Dn/cultdz7QO83G52nT3NOB/l3BxZtR6SCxx57DAsWLMD8+fOxcuVKzJ492/A7qalJup8/\nc99I/Ob175u2bQU2P6d1gddvmZam3k9tvYP7fnOJjnKfkhF9M7HjkLfAX3RMFLYzAQbSsetFRubW\niYjT8e36i91ug8PpQkJCrPx9myA7B/P+8ikAoGeXNIzq3567r2hGiftz/grK61Tfyy+W+5iTkuLR\ntq3X9ZCYEMN1icQlxMr2ZXS/sLAPXVVtY8DuhcRWpfLXibHcfW/40Z3Y+PWOM5g7uXezjpmQwD+G\nkhimjqC0/btfHUZeQRWeunsY9PLbNu91VwDYebQQ827t73nfl3MuseVAPn4/b4TntWDzzl9FwY6U\n1oncWozrtp3Bht3n8acHRumugZTVyoMt9M5NWVUDjl+qxMpvj2P2xJ6y+77R4URtvdMz+AeCk3ne\ncPtXVuzFuwsnA5CfA4nklATPfX/doKuAFe5KHhlprQyvt5n74fB5b55ju7YJut8praxD61axuvdI\nKDEcJU+cOAGXy4WePXsiLi4OkyZNwrFj5iLKiosrdX2wqYnRiIuxo67BifzL5YiO8g6KVZXeGXRZ\nqXrxrLrOgaIicy2zfaGmzr1IOrJPukzx5F2Wm7LSsQsKvbH3BYWVSIgLvOJpmxyLgtJaHD8rjxhy\nuUSPHOz9dOJcCXq0l/ucJY4zLkx/zp/T4VR974KiJltxSRUSmVqrjY1Orosnv7ASRUWVEAT3AGh0\nv7Aorb9A3QvlFfKAhy++P4UBHIvNbhPgdIlwOEWf5OZRUlZjSv6ycq9s0vYrv3X3jso9VYTUlDju\n91jOX/b/nLOw8q7ddsbz97IvDmHN5hOYe1NPDOnVTvadN1a51xU/+TYXk4Zfpbnv4hJ5Pgt7LElu\nlr80dTD+y/KdWPbUBM/7T/1jO/JLavC3J8boKjpfWPh/2zx/J8RFeWRzcNp9nMsr9VippSVVmH59\nF3yacwaVVXWG19vM/VBU4h0XN+w+j7tu4leDOXCyGIs/2oexAztg3hTfJ0m8c95cDF1tJ0+exMKF\nC+FwONDQ0ID169dj6NChpnYuisb/6hrcF6yuwSV7nx1YeFq6W4dkU/v39d/uo+6F0iiFr1q59iNt\nz/q7SyvrAyYHS0Gpe8D5avs52fsigH98dghn8yux9GNvH5w1353S3C+rAPyRx+USdWUF3Gs3DY3M\n9VNvAgCorG6U7cMXeZRVDwJ13pUpJMfzylXbHDtX5lnbqahu8Os41bXeoq8FpbWmvtPQ6BVOug6e\n16L6umhdI3/POcvLK/bC6RRR36AecEsr67F09QEUltVyv19V26h7HGUIu3J7PdjtpLqLeQXVzb4v\nnE73+S2r8qYA9O3SlvtcSew4UoAapriv5OZWPkNK4mLs5q6H4ru7jhRwt5Os8817L/r9+wONoeK5\n+eabMWzYMEyfPh233347RowYgcmTJwdMgPTW7kVn5SItu/AcyymvE0jzmccpgwVrSeGwcr68Irgt\nG3hsP3QZC5ftkvXB0aqwXNfgQEUN217B9zvKzFdcLlEWrj1hcCdMGNxJtV2UidYYZuUIVHShcgC5\ndXQX1TZ/ff/HZh+nrsE7IJmNBGOVbU2Im4Up75VDp0tw7HyZbjXvunp+fpLRtXr7yyOy1+cv+57R\nz17HTXubV+/t2x/yMP/lTarcHPYYHdLUCaOrNp30/C0IgifwImARu4rb5m9rDqo2OXauFHtPBK+o\nsr+YevIff/xxfPnll/jss8+wYMGCwAqgcTGkm3P4Nemw2QT89qeDZJ8H0ldZUFaLD9YfR1mVN0pE\naeGoFWOT4mEePHY2FIl8tPGk7PWBU74n+5mJ3nGJoud8tUmKRd+ubTGgWyr+eLfcUm5OQU7lQHip\nODBVxZW/z4xS8GcgcTDfkXq3GMEGF4Qycdl9bPXxGhqdfkVyGsmuVGa8AdUItu9T3y5tff4+y/vf\n5MLpEvHZljOy99nfLgVAaUXFAt4xi/0eb/Jn9n4SNH0JXl74T+gnw2YI/IKEjxgpnsR492LBNVly\nP7tS77hcIkor6035uSX2HC/Eyo0nUVvvQHl1A2rrHejULhF5hdVIUPiE1TNs9xuOIJT3YGeEV6W3\n8rmGk5Y1qKz0e+BkCQZ0035QyqrqERttl/nHeeOMchLgcomeQo9tk7wBESkKudbtPIefTOiueXw9\n1O6jwAzE0gAb1RTQYWYMqKptRFKCbxY4WwizuKIeLlGURRzyqGPcWspCmuVVDUhLCV6aw2/e2KJ6\nTxCgWz9QK9Tc10oNWi3g9WBDls00nTQDOzEF5Hl1nvtG51jSWMfeqkfOlqq2a3C40Ohwyta8eRjd\n85GWC8kS9pI5Ns4sAPAO7FGcaBEAuFwiXwReuvoAfvvmVhwxOXsEgLe+OIL8khqUN5VuOXGh3HMz\n8QZTFunGVs7eisvr8O0Pec1y/bCK5qGZ/Xz+/oBu5nJR9HIuauoc+N3ft+ElRcfXy6Vqy6JGUQVB\nWnQH3BF5EoG0UpWVFwI1uEgDaXSUW1YzeTr+5PIo16jMZPyzUZUOl3x95dsftSssKAeoRs5CuBGs\ni5ZF77drTcq+a2aPHTOKi7UiA1UpoGen1rLXPx7zVgmXDqFnIEufsWNJpcZ5zS8xruph9KtCmdzu\nK+FXPE0SaFk8Wp1K8wrlVoDkx9zFrHUYUavwk+eX1HjKTygHZaVibOS42gDgT8t34f1vcvHbv201\nLYcSthdPjMGshwc726uua8Tij/ZyM6n13EglFXVodLhwJt+4z4hy4uUSRZRUuAfSk0wbXzNuK7NZ\n/Mq2EWbGlvoGJ15ftR/bmWhFJdLgLu3PjCXlj7VVqpg9+6qTl368HyVM5Gdqsralr4oADGD9OT1X\nW6DaXgxVRMdVm7CA2I69gUrsjouVW/8VNY0eJShNWPSsVq6rTaE+ejZVtTZjrRhtE8lFhcOueKTB\niD1JBaU12JPrViDsLHnqqCzuPrYe9GbTB2pSbROA5+4djq7tk1XyAYzFo5jVSW6B8mYUwGzuc7Lj\n8GVP/a/v9l3EwVMlWNEUdsuiZ/E0asyW4mLU3lnlzMrlErFqs3s9iT1vRlnta74/hfkvbzLVc/7g\nabllW64YyHnsOHIZe08U4Z+fH9bcRlK0kjVh5uH153o1twZcXmE1DjHn4MttZ3FQY81OaZX7sz7E\nnzQIugo/UDNupaVsRqGxg3KgXE6CIKD/1fL1IkkWSZnoWfVe7473PTa6EWCWHgIw4SGLR08Azizg\npQ/24tAZt++TdSHcNrYb2qe6a36xaz6rvzvl+VuAu0T7e18fk0UO+YpgE9ApvRX6dXXfaEpftuSu\nCEYzs0Bpvuj/AAAgAElEQVTMVJZ95Y4MOpuvnQ/AUwSb917A+t3nuWGybtSyKQcyp0tEUny0ajve\n4CXPvj4DAPh65znVdka8vGKv4YOotHDNYGbQUs5azTCoh37wCo/OGfLcLOXk4C1FNJiEquK2H8VZ\neY0bjdZ4AhUAoTw3ZtomyBRPgCwem6Ati9Q/S9fV1jTasudMWYLKl8g3o03I4tETQHGi6xudKK7w\nugKUA+D92X1k2wNy94wAAc8t340NP17Al9vOqo63J7cQv/3bFuQZLNhLClGSz6m4eWubTHkty0CL\nf3x2CK9+tE93kGQHikROQurscd0MjxPbFGWj597iffTOumP4z/rjmv75vMJq1WKvyuIRRQy7xl1W\niY3y4bkhSirUlore47Juxzk89c/t3M+Oa3Ss9ezXj+fQlOLxY792xdqluVm8/DWb1wO4XbROl7v6\nOLuOo1QAH270vb271mCv72rzb8bdvWOK7P8fc+Xuc71jSs8VO+gGKg+Fl6+jHNzLOJ4OKR2EN8lW\nTgzZbapqGz0uax6GrrYI7PArEX7F03Si/7vzHC4UVeOfBv3kpRBCduDWWqDjDWr/u/oAiivq8c5/\n1a2l5XLJ///vTvkaieRD9uXillbWY8fhyzhwqtiUb3xQjzTERNsRo1g4t9kE1YxZibR75QDHwlPM\nEg6HV74vtp6RffZ4U9O7+gYn1u44q2pvUFpZ73koOqV7Z+k8C+urHRwZdE7pRxtPaLao8MeiYVEG\nSQDqCQcPf9Z4lIrdTIsI5XE+zTktez1xSCe8+J89+MdnhzD/5c2e95W/S0pI9gXeIHfsXJlm0VhA\nHjJu9hydvlThcbXWangs9J65LQfyVccL1MzfJYqqYpxKWZTrUQDwk/HuiaLkhtM6FfGxdtlE/NHX\nvsdv/rZVs7eP0Tk1sgzzCqrw9a7zQS9uzCP8iqfpRG87dBl/fGsHt+Uzb/vcvHJumCXrmtNzgRid\na0Fh8SibltXUO1DX4MD73+Tq74jhb594qwvo3RPSoCQtGCsjtmw2wbA0jxRWrrfmpbVuBQANzIyZ\ndWWy31uTcworN56UJcoBwMqNJ/H9fnfkEmsN8ayvxkZOsAIgy/g2i95vXfHtcVlVcR5snsbo/pkA\nAuPy4KEcsF5ftV/2eu/xIrz0wR7ZPW40QKzfnce1+pQBG7xkRyUrN57AvX/dgLebXLa8cPGvtp/F\n2u3ablH22l8w2TNm1xFvpNjofvx6g3rnYcdht+JxBmiNR1aB2iWqjq0c3Ef3b4+n7xoie887lujL\nI4ry6gYSr37Eb2HSXFfbM2/vxIpvjwekeZ+vhF3x+Nq/g9380de+l7VPUKFz3o1mx0pXm5L6Bice\nWvyd7j5YyqvqcZKZLek9DNKgFGXnXx4z50yKztMbjCcOkVcT2H3U+9BvPagd+SWRp9GqNzkxxvPZ\nBmYRXRDcFcnZfB7edfgxtxC/ev1704OVF+0fq9cfReIQE4Ir5cSYc7X5PrApI7O6tpfXwnr94/04\ncrZUZm36O4AqB6ABV6vD7YvKaj2RoW5L1q1QcvZfQkOjE62a1uxG98s0fVxWXq0qBoBbyRY11aGL\nivJeQ2lyJa3r8varxNY0ugdqjUfZ9kT5TF5ush4l13aU3aZ+5jzeE/3AgeSEGCa4wPu+VqCS0e/i\nrbFJ+2Lv2XC0dw+74vG1f4dy+417tMthKE8ne4KNwnYFxc2ixNeb+dllu2SvdfMfmmaK9qZQcmWk\njN0m6D7IZlH+NDY/wswsSEsBstYhm4UuCAJe+eVovPLL0Z73tM6j0yWqwp6bm/9hBGt9SWH8Zgb7\n9bt9j1CTBoD4WPeA1UORIyLR4HChqrYR//rysGeQ8xXeGpySJ/++Da+v2o8z+RUqN7TT5a1E0TuL\n3+KCB3uci0wF896dvb8193wZXv94P558cxuUSKHLymdV79mR7skvt3tduHoBEEaw587pElWySGs0\nLpd2ArBUFsxI8Txy+wDvmnIAJjy81vLSRJ39Ki9wZP/JYry77qipQA5/CL/i8TH+Wbk976RJyP28\nLvz2za3Ma/2L5jGPtRSPyZu5ps6BvIIq1U2g17xMkk1rYLfZBGSmqjt6KnEnWWqfX1FxT/k68/H1\n2gHuNSf2e2yxTSOUuTtKmhtKz66zSGtjykGCd92lIoy+IM3mE5taHejdT6s2nfSsXfiD0q2nd++f\nL6jC9kOXZe9dLKrGpSbrkxdOr8U2xmpmr93l0lqUNjUxU7ZtZk+3FMWnzDvSO1dRdgEOp0umIOp8\nrJTAwiqeuganSolLHWpdLtGjNJTPhRSBK61Fb9rDn0B1TEv0JpmaKU3FOQ+XS2q8qQWc50GqBONS\nuBCVLFm5D5v2XsROxvUZSMKveAwsnrsn95K9FhTbR9ttqsV3HqcvVsqCDUor9fM+pHtHazAzk+h4\n+lIF/vB/2/HM2ztVn73y4V6Za4fFmzxr48pgtwmmBtnj58u5Cbgzb+gKQL1wrqfElUgN0oww2kR6\nAH727FrTx9ZC617iKdSHX/0OX+86j9XfnUIhZ2FfUvpSx1YJrdwIrYAHLaTBXypvpDfOKEu1mKEN\nU6pIGcjwwzHtweRzRT0yAFj07x883oOkBHWYvBZHz5Vx3y+trMevOSV4APl5kCwF5fNdqhPp1T41\nUaXM1nx/WmNrY9hcqY0/XlBdfweTx6MVxyNNYpXlcXgVJKT7jmelrd99HtsP5eORJd9h19EC7j3z\n1D+34/Gl7nPLC8KQlCI7+dCbiKzefFKWBB4owq54LhTqhzV3aifPXVAK7BJFzQq57IXJVwwMqcmx\nsodTCy2ro95E2ZHc82W6iaTrGHcAi1Rs1K5RtcEdRms86sdE27gLkCmt3L/bpRiQ0nyoc6cVaaPE\naGLRsWmhm18DzrQ4ANyTEB682WNtvQMrvj2OL7aewbv/VfeXkkquFCsiI7VyU7QiK7WQZplRHp++\n9sPf3Kgjpcx6xWz1qhrERNl8Kk1kFHnJs3LZgCBBEGC3Carfr5x8siTGRaGiJnDFepXJxqqcNacL\noiiaCtm+aZh7TVUad9jJ6+/nDgbAVwyAOwLtP+uP45+fH0Z1nQNvrjloeF/w3GRSiLusPYqO4imu\nqMef3/1B9zj+EHbFU6uZqOjmqnSF4lHcdFJnRR7s6VSGq7ZJjkNGG+2iipLCSVQkQkoDpZmQVMMB\ngzOy5hVUebLapTp1bZPkCiGtdZwJteO+sZXKBfDOINXJcOYHuCi7TTMCkZ0saCme65oWqTPa6rkM\nfdM8Wq7CCxpBEBKHTqstzzEDO6jec7lE5Ozn32++5nNJD75Uy469V9gZZl29Q7VYqdVKnIfD6cLn\nW9Qzfn9CzxscLs3JwKRhV+H1X92Ap342GI/Mcnc43XO8SFVTj+Wx/83BSkVEZOtE+WTQZhPUBXp1\nvA0uUZ37Fyj6c4IyGp0uj8Us5VVpnSPJTZnZdM+zP6vnVe51L0mpfr1bHgxTyYngNVQ8nEmSFOLO\nfrc5VVb8JeyKx8hNpnT/+FJoUnSJEEURTpdLlYtyIq9c11csHUfZRVGa8R3lVJVVHd9I73De23Pc\nmywnWTwPzugr28Zs/bai8jp8t0+dZyGdU5fL/ZD+bc1B7D9ZZLhuZbcJnugrvfUd1lLT2i6lVUyT\nDKLmcc3EnVw/wBty+9HGE01NtuT722cyXHTMtd59SROMju28occ5By5hxQZ+SLavyZLSgy/dT+w5\nYP3qheW1qiCZrEzjbpCllfW4968b8MBLm3D6kto69dU1KNFWoyZcYnw0WsVHo0en1rLr/846tzWp\ndSlVCrBpw2nXZQFw3z9aBXp5uETR5+rXzcHpFHH4jHws0GpXIE3CjpwthcslqqrFA9774IQiLJ43\nqZLe0gqP500kD50qkR0HgMziP3GhHK+t5IdvB5KwKx5fFisB36LgfsgtxIOvbMZjr+dwP68ykSui\nTMCUFGW1ie8aBiDwfgozUEszqPQ2CbK1LrPnQGs76f2GRiceee077D5agCUr9xvOoGw2bzMr3sN/\nQ5MSYLOxterrSRble1/n4lca18cMbBWH05cqcd+LG7F09QHZNq045Xt4JMR6t5PW19hrqOde9Nvi\n4bja2rX2Du5Xt09RzWCUEw9luLEWXRiF5RLd1tTWg/lci0+LZI32D6xLml1L3Xu80D0ZMLl/ZbFN\nm81tGTicLhw9W4pGh0u3BtmqTSeD1quItyaTc+CS6rela3hS2Mfx0JkSfLz5lGobrWeQ9650D43l\nWOcAsO+k2iMh5TlqjU3L1x41PVFrDmHvxxMbo637pFBTFh+jr9HgcGmuAUmLkL+fOxgXCqvw76+N\nk0F98XEbDuQca4B9h51ts4rO6VS7PFq3ikFGaiKOMZYYb5Y0qEeaZ5D4QVGKxMjVZrcJsDcdWJk1\nD7hdEd83FSdNSohGZU2jx6WmxvsDtPqtSFbnyYvl+FGj6nir+GgM7Z0uy0FSugDNrF2VV9VjHVMj\nji1eW9fgwOdbzsjWCdunJsiazxlVsCirqsfbXx6BIAiYfn1XjsXj3Za18mNj7LioaHKn9BKM6JNh\nagFd2adp+ZeH8SXHDaeFXg4Pey+zZ8LhFGXJyEZIAS82RVTpmu9P46vtZ3F9/0xc2ytDfx9BKo4p\nTbbaJsd6lOuRs6Wq88pWsJ5+fVfP3+xE0JcmiMmJMVzNI+VdRXEGRVEUVdGJADvR4R9LGZgRLMJu\n8WiZzbPHdcNjs69VvR+MuUxSQjTGc1ozS0we3tnzd6PGACNF4LAYZd9Ljb0qaxrwzL924Nsf8mSD\nDjuLZAdnyR/McseE7njpkRtk7/FmNXa7ze8QcTtj8fDa6bZjzoG02K4ZEu5DRNz/fnzAk9Ao34cA\nQRBQWqlf5l9SwMN6p2tuI0UCefbNlC75NOc01u44J3OpKCtHGFk8b645iIOnS3DgVDH+9eVhj6KR\nLGrWJmCvw5EzJaoITLsiiEKvJQILe8rX7Tznk9IBgM4Z2i4+dlBVXvP3TEzoJKTfLq11SJOPbU05\nXTkH8j1jRmy0Hbdz6hZKFo9keXRrCnluLtJxo+w2T2TogG6p2HFYPcBLsJM/9rnTetROX1SnWaQk\nxnCrsEgTH+X94N6/iEnDrlK9L00ulcr5pQ/2hLRxXNgVz4Lp/EZnU0ZmcZPqgpFka2Sad2sqVgio\nw2slnvrZYNV7RopH2teWA/nIK6zG+9/konUr7+yJfYDjGIUkCIKqhEnb5DjD5nWAe8DnueDsNsHQ\n4mFdbTz3Tky0+nbSikAa0Ud/1sqileMjrSWcvKCdEwV4rQlf3LSsC4wXSKJsUGhUgp4tZXOpuMab\nq9X0G1j3JHsdTioGoj/ePVQVIm/WlTi6v3cNa1cz8jN4x2NPrVLx+LJ4Lf10aR/erp3ecyKd68kj\nOuOWkVlYeM8wWTFa6fxJFTJam4he5aG878qbouXqGpxIa5pkGSVas+MVe13f+oLfmoOXJHy+oAp5\nBdqWiCDwOzLznke3HC58qFirPHK21I9KIf4TdsWT2TYBt4zkrwPwiPMh18QskktPmpG0bqWIrDEx\nXqW0Ut/cegUUJURRlM2W2YgcvRnImGs7YBzj22UVloRTFFUtvAG+FdIlM8lwxsMqnow2asXDC2fW\nsnjapxrXC9MKJ/fIYzLQxOVx35ja3L2tQQa5cvB3OEWf+p9IA6mkkFi3nd51yGgTLyvbMrpfJuJi\nvM9E904pvK8BgE9t4fXgnccTOg3/OrUzvtYSqjWepl2xZ8Rrebg/7JyRJHOBS1Fm0nnyd7KqbDlf\n3hSGXlHdYLrUFxs8wf7NBkD0ZK6ZVvdgvTqDNkEd+Vff6PLcu4N7tsO4gR08Y4HTKarc7EDgepmZ\nIeyKB9BegOYRG2PHkJ7qCrDNQdWrXnEBWEuCt+5kJh9Ii4vFNbIHme3ZrmeBREfZ8PPJvfHsvGF4\n9PYBSOcoApdL5FZXbsdxCwqCYFig1W4TPAMCb5BNiOPNhP2/m6PtNlXUE6tIzUYvuRSDmRGTR3T2\nDCzlVQ0elyiL3W7DnTf28Lz+93+P4YGXNpnuASVdW6nfE+8zHna7TTbojR3UUWbJ8SYaEs25FgBz\nb3L2w9aeu0ZRVkf6PbzJkRKnSz5J8Dx7zClRJlgD8vVUqYyWV/GY0zxlVfWyJE9pbaojR3H6o3j0\nKpFImCngqvo+53o89Y9tngrz/bq2xc8n9/bUk9Py8Cij84JJRCgeX+u19ezMr2vVXHo17feaLorB\ngBHvzht7qr5339RrZK/18oOU/PGtHbLXOxl/saysvMb3szKTZG6Gn0zo7vnb5RLhdIqyG14QBK6i\ndLpET98QLWxNCX0Av9pwdJT6OmoVOjWDUxRVVZvNBncUM4mQnu6QJu+zbh2SZZMNZca5BC+0+Nxl\n/YRopUxSpBkbCaUXlBJlF2TnVBDkkZdaSbSAel3KCKn7roRecAG7zqC0/qVadnqJqxLKayUNqnyL\nx3tM9pRJPaykfZm1eJ5YugUvfbDHo7ikQrcNnAmOr2OW3nfYc+fP1IA3n6iuc6CmvlF2XG/ADN8y\n53UpDhYRoXh8rVDt6/ZmmT+9L34yoTse+clA2ftsQh/PRaRUVFE6g+ONQ9VBDOwgx4Yysi6Xvk3H\nMMoGnzKiM+5oUj6nL1XC4XSZSgx1uUTN5m8SrMXDKznEe7B8iQLkyXRMsaZmVpGVVdV7Gmm5RN8s\nHpsgGA4s+08WIyuzle42ekiNCKVgkoLSWhzPK5N9piUb6+YTIMieB617LysjiWvp6pHAWPcDu6d5\nZL1xiPoeDsQzueHHPNW1knQq+5tXbTiuem9UX++aoWShtm9K1Kz0sZLBv5vyWj5pagdSWKYOXjH6\nvZLLbEgvb0CL1vnXjvw0h80mcHO7lPX9JAUXrHBzX4gIxaN8yO+95RqNLYNLckIMpozorFq4Z2tl\nKW+4kZxFcuXCM4ty/QiApqXBumG6d0rBn+8bgfm39uVuy8KLPLs/uw/SW8dj1pirud9xiaJhSLDd\nbtMdkJvrylHJxFGY8TquJBYn00hLyofyJf/JzG9JS4lH9g3y8ym5dcqrG/DrN7bgwCn+4rO0iMwq\n5jc+OQhAXS2DRRDkQSDRUfJrwgutBYBRfgxugsxS9r4/dVQW/nzfCNm2/lgASt77Ohf5UqSWwuLp\nnK4eWNlJyOCe7TwVHaTzI6UgnLxYEfDS/0b3xy9n9cei+0dgIDNR1AoCkblb/TiNNkHQTcSX3KCS\novZlLTJYRIbiYS5ix3aJsmx0Hlrhi/dP66OKqTfC1+2Vi8o8WX19CHmdL6eOylJVbeiQlmiqkCfv\noRjVNxN/XTBKc9blchkvjrOWAO8hEgQBfTlrFv7y7Q/qdgPRUYLKlTl+cEfVduxvkSKPzF4Wrbwi\nHh0VPnlpfHv8f3NQWllv2OacHTAk8Xj3AwDcNcnt5mUDUNomx8ruNy2lmbPfONBFiZ3Zj9Jdq1yL\nCNSkQ7nO6HETcQJN5C5HAV0y5a7BFGZNyUx/KZYX3v9RfwODnxtlt5kKoAHk40X3DvLgkO4dtYNF\nJFyiqOtZkDwqkgI6EYSin74SEYqHxUzVZ61yH6P6ZWKaD4EKgLkLq1ddgWdyny/QznDnDUKfcJL/\nmrM24o/bg+25wpLJ1FIrKKvxDDBagzO7xqAs8KpE2fxMSQWn8KbdZlOtd90+thvmTOwhe+/lFXs9\nf//YFMHDDo5all9SQjSu7a7vzgS8ASXKagY8FfPWF0c0xym2CoFUvr+e05UVgCfXjD1GYly07Hp/\nv/8Sd+Jzqdj3UFl2P4U6xUMB4GYm1y0QSMVKPUUzOda48hlR1mjr3dkb5KDsoqtE6TpWuniDCVti\n51qFK92Mq9rhdOmOF9JllLwtbLJ1uIg4xXO1iWQvnh/76Z+5281q1XIbN0g9KwbMWbbsukxdoxM9\nmPBHnusnED7U5vjMldFeRgM84LZ4Dp5Sl07pwnx3QLc0zdLvEuzMNKOt/pqCP96PKLugyquJj43S\nTQ6VEAQBj942AIN6pHHX2gDgtUdvMJUXI21zXiOYgA2L3XYoX/O+ZHMtRNFtdf7ICXVlk5iVEwSl\nS5JnuXYzMcFSwh7HKAnTzHPrC9KajXTeeAm6Su9Dt45yGdhnaLzG8y/xb06Fcgllp14tBpqYsNzH\nyVtknyml5WhO8Yj6uVJN+5Ryj3gFR0ONKcWzbNkyZGdnIzs7G08//TQcDt8r25rFzELb9f3V7i0p\nf0HrQtltAl55eDR6XdWam+ypB5s7FGWzyZK8lNWzAW+/Gx5mLDrAOIdFD6WLavr16tm9soxMQVkt\nN5qKXa86nldm6FJhLR6jbf1RPLwsbfexjL9rswEDe6ThkdsGIC4mqll5C9Ls8Q5llGPTj1ImFmpF\nlHVi7h+XS9uN3O9qrwtT6uApRZ2x64ZaCnhGU+kWo1QE1sJlLdbmWOAS4zg1xbKv68LdVkpxkEKa\nefXklBNQ5eBrswmeHMH42CjUNzpxNr+S63XgVeKQUCo0gL8uO++W3pr7kFBFzEK/8HG5yUjAtjop\nHdLupfU/qdOuWbf47+4cZGo7XzC8m/bv349PPvkEq1atwueffw6Hw4H3338/4IJImKm8nD26i2b9\nraG90tGZowxsTWHEv5s7WLPNsBmuSm8lG+TYm+YfvxmHp+8aguzROorH5MKeXoCCEVNGyN0eiZxB\n7+m7hmh+/7l7h3vlYB7u8qoGw/UrdoAy2vasyZ4+LFqWoJmq5UpF+MbjY/Dao9d7XvPKHmkhDdDx\ninMrgu9Ozcrgux1lNc5EUfP3sQqhfWoiXnl4tGcCxSo1rSKe0trggzP4lUIk2Hp0ndK9axTNiU6U\n4FUQuGnYVdwEU2nipdd+RBlIoZw4sR8fzyvDg69sxp+W79JVMjyU982C6X1VFl5aSpzmuWfh3Rt6\nj4nyGfnLAyNVRUgH92gnm8QNv0Y++ZB2L51TaQwy61Xxpd25WQzvppSUFDzzzDOIjXXfNL1798al\nS74vVJrFTIE/u82GFx+8jvtZQlwUFt47HC8+OEqW7Nmc2W1Kq1jMmdgDj9zWXzaYKncZHWXTXTP6\n073DVe2mtWiOxaNco+ANyuzDxC4UR9kF2Syc/ea8Kb0NrRjW/cGWgTFL22T9ZFyt/i5mrq9SEcbF\nRMkiGO+8SZ2jxaPXVa0xo8mqVQ7IogjsO6GOZDNj3LlcIuI0ovaUOUNtkmK5VojL4EjKc8C6oO6b\nJo8mZSc/gbB42PswKzMJc2/qiVbx0dzySWYGRaXFoxzT7Tabp8Yb22pi91G1K5OXJCqhTCCOibLD\nbrNh4T3DPO+ZjbbkNzzU/q1spXJAPgGRUAZIKa2xXk1rXVK+l1RlO1QFQXkY3k1ZWVkYOnQoAKC4\nuBjvvfcebrzxRlM7l2oImfnnEcgm+Pwd3rHatY6XJXueuFDO/67GfpXv3Tz8Kgzu2c7wuDzZJDpn\ntOIW++MRZTd/HpRyp6bEoXeW16pziS7VtqxB1Y6xHnt0ag1BAG4d3QUAMGGId2Dq1jFZNXCx6yGC\nIB8M8ktqTF8/wF1bS68QJaCuyybty8zA6C4qqi1Hm6QYw2sIAHdM7I6EuCjucdd8fwpf71YXNNVK\nCmWPI4K/5jjjhq7mnwWN20vrd/18svcZGdTD64ZLbx0vm/zw7ket/QuCu/oD4P0fkM/sh/ZqhxuH\ndoIgAFNGyi10qRit0WQi2m6THVNpTdjtAjffbOeRyyp59QbhzXvlfXPsTeeCzZ05X1Bl6hnlBfDY\nFWPeI7f193ym3FwQgJ/f3Ev1nlI+ls4ZrSAIXmUu5SWZnUwYXQd/MJ3KnJeXhwULFmDOnDkeRWRE\naqrxoraS1q0TkJZm7nszxnbDms0nMahnO+53Wqd4I1NOXayQbdM+NRGXiqsxoAf/u3qyD70mE+t3\nncPwvpmasi6Y2R9//8TbF+aRnwxEWloSYmO1F657dm6N3KY+9a1TzJ8Hntx9uqbh6Fn3vqJjY1T7\nimZyk1LbJABwz9IvFdcgLS0J98+6FvfOGCCzQK/tnYldx+RuiuF9M7GhqVtiWloSklp5ldiwPhk+\n/YY/PzgadpuAP7y5hTtgKBEEyPY/dlAnbN6jDsGWOHKulCvPAzP6o6C0BoP78vuaKOnYPgVpaU1W\nYbncFaQs6ilht/NdyKw8V2UkITlZ7e4b2qe96fNYrrFwzHuuru6QgrQ0r8soM8P7d2rreLRu7Z1d\n5+ZVqL6fmZrgybtRfvbwTwZhwe0DsWXfBaxrqizeirk3rrk6TfadmGi7p0KA0yWa+r1XdWiNNMYC\niI1TFM5tk4hunVJwUtFUjbd/vfVGu92GZ+8biT+9tb1pv/xn04zMl8rkz0/7tESkp8vddpPSkjBh\nRBdE2W2453++Vh1jbFqSLGozLS0JUYyV0yrB6zVomxznkStJkUOodBOzdGmfjDOX3PeyP+O4EaYU\nz5EjRzB//nzMnz8fc+fONb3z4uJKnxeQKypqUVRkzkUzeWgnpLaKweCeadzv5BfK32O3+d3cQTh0\nqhjD+6TL3hcE94nWk/22MV2QlZ6IwT3bacpaoAhfHdytLYqKKlGtk0Udy1gLNTX1ps8DT+7aWu9x\nSkqrVfuSIp+SE6JRx7ivyqrkx2UblhUXV6G+Xj6wzRidhZraBs+5aGzwft4lo5VPvyHW5kK03Y6H\nZ/Yz1ed9iOL8z5vcEz+f1AO/eGEjd/u8giquPKOucc/0zcpaXVmHIoiecz6iTzp2HNYPUT2kkUha\nVFSJ6dd3xac5p3H+ciWOn/Vu98CtfeB0imjfJtZQtpF9M7D90GWMv7Y9fuSEy5aV1aAoQf64D+6d\njuLiSvzx7qGorXegoty7viNARDXTbiIrI1Elw1NzB+PDDScwblAHTfmqmQlObU09XnpwFE5cKMfV\niv09NKMvlqz0lkeSPrsmqw23ZNGQnu1gczll+6iqkod8V1TU4PYxV+OF/+yRvZ/ZNkElr00QNK1S\nl3gyV4YAABW4SURBVEtEUbE3erGqqo77e42ukSAAWUwZor5d2+I3cwbqfo+d+HVmnqcenVI8BWaL\niiqxN9d7zRuYeoECRM93MlLkikevGO19067B//s/dzmv4uLKgCsfQ8VTUlKC+++/HwsXLjTtYpMQ\nRd8jlxLjok1/Jyba7in1zvuOcjBgt0lOiMGoftrf1ZM9NjpK97gAkMb4Zu+5pbdnO60EzqmjsjxV\ndQG3f92fqC+e3Lz37DYblj42BtFRNiz+cK9qewlBEPDG42Ngt7kr4Cr90a3iY/BAdl/P92RJfVBX\nzdXDLrh/s17+T+/OrXH0nNeSVe5fz18u/YbmoqwGPLSXseKRGNY7HbsYxSCKcr/9im+9VYi7ZCZ7\nPjOS+/5pfXDHhB6eVgBK4mOjNO9zKTpOFIFfzxmI1ZtP4a6be3lyaQC3G075/aSEGNw3rY+ufPLr\nISA1JR6pTRFr7HfYQr3tWsd5PmufmsBVPMOuSVcdU6k4BEHg5uAlJ8bIvutwunTr47VvK2/6V1fv\n1DyXRrBrimbuR1auZ+4e5tl+3pTeeOuLw5g9rjtEUZ7CwbrDM1MTPd9R1irkLaPFxtjx+qM3yMoM\nBaMVjaGT75133kF1dTXeeOMNzJgxAzNnzsSSJUsCLshv5wzE3Jt6+lWdVYv+GiXGQ8GIa7wLplnM\nusWEwR0x44au+J9fDJdtL4ryiD6zi5WaMDeVVln6hLgoREfZPFVrtYiPjfJERbHBBbwS7soClnoo\ny3xID4xedYauJvJFtHJOtEKxfUXpQ/elUkWUrJimexDSqhjhy34FQeAqnd/MGYifTerJXZTm0bdL\nW/zx7qHIaJOgWbnAF9i1RL19yMr+aITks9/mBbko8+fsNoF7TJdLRHF5HYrKa91tSQxSHCYN7yyz\nDio5ic3+YKbaw9hr3e7fG4d0kp2j9qmJ+OPdwzwRZ688PBpRdgGPzb5WXruPrWohKBWP+vjPPzAS\n0VE2tE2Ow89v7oUn7lA34wwEhqPb448/jscffzwoB2e5pktbbox7cxjcs52n0N8js/obbB1YBEHA\n0N7pOHOpQhb+GGW34VZOuLXLJcoiwsyUkDcLr2WCFv2v1lfW7L3Ke6iVZUz0+MW0Plj21RHUNTgx\nRZHPsfiXo7FpzwV8tuWM/Pjs8KOxf611FmXCob8ofzf7+tpuqZ5CrxltE1RVNlgZfj93MHd/Es1V\nkz06paBPl7boo3iuZo/vhi+3ncXU0V0BnZw8VsH6q7TZ36Y3wZF3MPUe68g5r7UTE2P3VCcQOOLc\nOKSTZz0JcN+LLk4Y6YkL5fjtm1s935ECIFISY7iJmHExdowd2AFrmtq9D+5pnChqBjOL9reO7opr\nu6ehs0Y4vkSbpFj887fjAQBHmXNWxbjRlfcZGxj0+q/cVg6bE6aVdB8ImjmtjmwamV7vZsqgBJqH\nZvSDKIqGAzAAQJBHsDR3dv4DJ2RUC9aU7n+1vvJnZ0ncatR2doalf9xhvdMxtJc7UrBdu2SZr7t1\nq1hMGZGF4vI6ZKYm4OPN7gkEGxXoqxppjhX5y1n9sXS1O1jErsix0jonV6W34ige73cTm/oXDdSq\nON5MPcm2yGCZMiILU0Z0RlrreN31BTPFR42wmbSaWOuKba9xodC7VsqWxBE4J6dtchxuHNIJ65sS\nqKPsNsPK7Ot/yPPU+tPsdGsTkNIqFv/6nXtg5z3PQ3qZ7xHWqV0i8gqrTeXH2GyCqj2FEazyZaNA\nlRbOsGvS0TY5DgO6paJVfLTpTraBIOJK5gQS9qYLRPVcfzCldOC2eFjff3Pl7XGV+RIpbBjq2IH6\nsxz5zFQtI6swzQz0giBonqPYGDt+Ma0Pbhzq7R0/qm8mbh7ufj2BUxxUj3bKhn8+wN5Lqhwr5iX7\ncMdyki7ZYVCq8qBVC5A3uPpCvE6NQTP3pd3gWptBWcBUi1YJ3kGPvYe02oDUazTcY/Od7Hbj9hYA\nUFvvVmhaZYUkefTuVa2Edh5P3jkID83o5/P9axatLqbKcxFlt+Gum3uFZVJ+RVs8XdsnY0ivdujh\nR52qUJOaEifrVujvDFNiWO90VT8OLWSDoUGGuk1jkPV8nxk0mpMEyxIbbcffnhgDp0tEYlw07pjQ\nA7eO7qqp2Lp1TFbl+wBuF5MvsK6y+Fg7pozojLpGp+p3y5bPmRMUw3EtsW2qoziN8yTSUuIMk2mD\njUyJGqwDmtmHnvKKlZWl8m538/DO3M64ZRrWCevKjLbb0Ch4XW1pKXGygAmJbz0WEl8+M0rXl0lC\nUkIMhpqoLegvw3qne0o2sSWJlIon0G1MfOGKVjw2QcDDM0O7tuML1w9o7ylXP2ZAB3yw3tsBsLkW\nT/+rUzH3pp6ygqaa+BC2YjSDZRNIzZQ/MovSKtCzpn45sz+2HszH2IEdsXT1fk8UnNky9RIPz+yH\ntdvPolN6K/TJaot+XfkzSXYWzJ6SREUr8Iw28bKZsdJlx/LQzH6mrWUteL2ffCElMcYTZqzsUWUW\nIwuZR5SJyYtWq4kMJogiSmHxaFmWFwqrdOUzNUCHbwxXIVuHtWs/r829v5rDFa14Ip2umUnI2X8J\ndpuA2Bg7+l3d1lMhurmKRxAE01V1fYmWZB9CXvMpdrbKlqUPJSmtYjGlqTjk7eO648/v7vZrP53a\ntcL92caN99jnV2YlRMvPz9iBHTUHMWUeSXNmo0sfuwG19U6fW10rSWkVi0UPjFApUF8w62pjYRWP\nrzUL2dMWpWhcqKVYJCuIdfGxz6Kewvz5zb2wbsc53DzsKs1tQo2gYWWqo9pCJpKKK3qNJ9IZ1S8T\n4wZ2wKO3DwDgDkaQaK6rzRd8idMXZIvAaouGtXiaO/AFgkBFsukfgx/JpyxJYhO0lby67In/j2ZC\nXDRSfVhz0COjTUKzFp3Zga9Qp+Cn7DuyaDrv35NN9Pypb/C61gRBHk6tFcQh1WKLstvw9F1DMHFI\nJ9w4xKtI9FzG4wZ1xF8XjEJKM63LQMIGYbCh4koFqszrCSWkeMJIXEwUfj65tyeEmfVzhzIYwpe2\nwEYzyFAqTDOEwp0gRR1175giy1tRKR6boJktrpQzENWgIwF2ll1Tb66dSh2zXWqybwq0d5a71qDU\nHiI+1u5RnFKLBCWSpRkXY0f3jimYe1NPmbXanN5Y4aCASUTXC7CiNR4CgNJEDt3Aw1YCMIK9d5UN\n5wB+k75w4otS9ZfoKBv++dtxsNkEvLP2qOd95UzZbhM0mwQqk0jjTLQ4twJaiaF6DGCirNi1PHl1\nAf6gmRgXjb//epzH0rXbbFj8y9FNRTJteHBGP7y55iD3u1pRgOFcC/GHm4d39oRUa7mBAXlyb6iJ\nrFGC8BDOm0IPdiDZuOeC6nNphpoa5ogsidSUOERH2XzOhfCVKLsNNkFQ5L7IL6JgEzTzSqYqWrYH\nKiIw3LATFbO/ibd2CACHzpR4mrLp5ZtFR9lULk9pIqfXSTUp0etSNEj/iWjYChZstJ3SciOLh/Bw\nw4D2qK13hNTiycpMMt07x+hmbZschxcfHIWE5pb8CRCJcdF4YcEoWRhzMGHPTlSU4CkACrjPndPF\nL88ya8zVaJMUi/e+zvVseyXAKgCzbjMtN/P1/dvjxqGdYI+JgeB0+FVDjC3H1P/qVBxgireyjdz0\nCmhaCfY2Ut5SpHgID/fcco3xRgHm0dsG4Otd53DTUOPIHDNrT2nNSNQMBs0NK/YFuTPIrXg27rmA\niuoGJCfEoLyK3+5BEARVKPCVAOsqG9rLXO6K1oDYIS0RUXYb0troV1zQg531K5ussYfVKxpqVVTB\nBWG8xUjxEGiTFIs7JvQwte0VMhEPGux4VVDqTj79w11DkF9Sg75d2uJMPr+OHGBcjsiK+BNOraV4\nAmGFyHKEFF4FtgK11QIKtNC7p0JZIkcJKR7CJ9gbWc9f3nLxDo6SBdOudbynHYZe7TC9nAurkpIY\ng0nDrtJsB8JDq0tvIKwQWVdVReUINvS4d+c2uL5/e/TpGp5ctIDB/ESl5R/OEHBSPIRPsLOmqaO6\nhE+QCIVdwuGVRTE7a7daJJUecyaas6YltNoUaCyP+QSr0FMU1RjYCEibTcC9U0Pv9g407F2kDNGn\nNR7CMvTolIJO7RIRHWVDz6tah1uciON0vnY1YAC6iZ1XinvNX+be1BPbD+VjZJ9M7udJCYF1DSUr\nWo9cies6WlUMeK9DCSkewifSUuLx3C9GhFuMiKXKoEnYmGs7oKq2EYN6qMvod+uQjNvGXo3uFihq\nGwwmDunELfP0+7mDcepihbm6gyb43Z2DcPpSJXp0lE+crpBANhnyqDZ3JQfJ3RvOiQ4pHoIIIFmZ\nSdh/shh9uvDXBrQaAQLugYHcl2p6XtU6oNZ1r85t0KtzGxSVy0v4TBlhXJLH6tjtXsVDFg9BXCHc\nMaE7EuKiMF1DuRCRg7J6eoYPnXojnSi7u0pGF0XidEMjW8su1FJ5IcVDEAGkfWoiHjBR0ZoIP8mJ\nMfj55F54d90xAFfWGtvzD4zCucuV6NtFu8IDtUUgCIIIA31MtJ+2IqkpcQGrUB4MIrQiGEEQBHGl\nQoqHIAiCCCmkeAiCIIiQQoqHIIgWS5sk9zpI5/RWYZakZUHBBQRBtFjYJn4tiV/dPiCsxyfFQxBE\ni8ZsZ9Qrgf+5bwRO5JVhQLfUsMph+oxXVVUhOzsbFy9eDKY8BEEQRJDomJaIsQM7hr0IrSnFs3fv\nXvz0pz/FmTNngiwOQRAEcaVjSvF89NFHWLhwIdLTzXUQJAiCIAgtTK3x/OUvfwEg71dhBiu2FJFk\ntprsVpUbsK7sVpUbsK7sVpUbsK7swZA3qMEFqalJwdx9ULGq7FaVG7Cu7FaVG7Cu7FaVG7C27IGi\n5YRzEARBEBEBKR6CIAgipPikeMIdgkcQBEFYH0H0NWKAIAiCIJoBudoIgiCIkEKKhyAIgggppHgI\ngiCIkEKKhyAIgggpAVc8a9euxbRp03DzzTfjjTfeCPTu/UZZ5PT48eO44447cMstt+BXv/oV6urq\nPNs99NBDmDp1KmbPno2zZ8969rF48WJMmTIFU6ZMwcaNG0Mi97Jly5CdnY3s7Gw8/fTTcDgcyM3N\njXjZX375ZUydOhXZ2dlYvnw5AFhCbpYXXngBTz31lKVkf+KJJzB58mTMnDkTM2fOxPr16y1xr2/Y\nsAGzZs3CLbfcgkWLFgGwxjlfsWIFZsyYgZkzZ2LGjBkYPnw4fve731ninK9evdrzjL744osAQnjO\nxQBSWFgojh8/XiwtLRUdDoc4b948MScnJ5CH8Is9e/aI06ZNE/v16ydeuHBBFEVRnD59urhr1y5R\nFEXxtddeE1955RVRFEVx0aJF4tKlS0VRFMVt27aJd9xxhyiKovjNN9+I9957r+hyucSCggJx4sSJ\nYkVFRVDl3rdvn5idnS3W1dWJoiiKTz75pLhs2bKIl33Tpk3iz372M9Hlcol1dXXihAkTxFOnTkW8\n3Cxbt24VR44cKf7+978XRdEa94soiuKkSZPE8vJy2XuRLvu5c+fEG264Qbx8+bLocDjEuXPnihs3\nbox4uZWcPn1anDhxonj58uWIl72mpkYcOnSoWFJSIjqdTnH27Nni1q1bQyZ3QC2eLVu2YOTIkWjd\nujXsdjumT5+Or776KpCH8AtlkdP8/HxUVVVh6NChAIDZs2dj7dq1AICNGzdi1qxZAICRI0eiuLgY\n+fn52LhxI7KzsyEIAtq1a4cRI0Zgw4YNQZU7JSUFzzzzDGJjYwEAvXr1wrFjxyJe9rFjx2L58uUQ\nBAFFRUVwuVyIj4+PeLklysrKsGTJEixYsACAde6XsrIylJSU4Mknn8Stt96KpUuXWkL29evXY+rU\nqUhPT4fdbserr76Knj17RrzcSp577jk8+uijcLlcES+7IAiIjY1FbW0tGhsb4XQ6ERUVFTK5A1qr\n7fLly8jIyPC8zsjIQH5+fiAP4RfKIqdKOdPT0z1y8j67dOmS6v127drh8uXLQZU7KysLWVlZAIDi\n4mK89957+OlPf4pz585FvOx2ux1LlizBO++8g8mTJyM/P98S5xwAnn32WTzxxBMet6xV7pfi4mKM\nHj0azz33HGJiYjB//nxER0dHvOxnz55FTEwM7rvvPhQWFmL8+PEYN25cxMvNsnv3bhQXF+PWW2/F\nvn37Il72uLg43H///ZgyZQri4+MxfPjwkN4rAbV4RE4uqs0WefELLpdL9Z4kp/IzURRht9u5vy1U\nlRzy8vJw9913Y86cOZ7ZCEukyv7YY49h27ZtuHjxIrZs2aL6PBLlXrlyJTp06IARI0Z43rPK/dKt\nWzcsWbIEycnJiIuLw1133YWtW7eqtos02Z1OJ3JycvDSSy9h5cqVOHDgAHbs2KHaLtLkZvnggw9w\nzz33cOUDIk/23bt3Y+XKldi0aRO+//572Gw25OTkqLYLltwB1QoZGRkoKCjwvC4oKEBmZmYgDxEQ\nMjMzZXIWFhZ65MzMzERhYaHss4yMDGRkZKjeD8VvO3LkCO6880789Kc/xQMPPGAJ2U+cOIHc3FwA\n7pnVpEmTcOHCBU0ZIkVuwB0ck5OTgxkzZuD111/Hhg0bsGrVKkvIfvDgQdnirjRYRLrsaWlpGDVq\nFNq0aYOYmBhMnDgRZ8+ejXi5JRwOB7Zt24ZJkyZ55Iv0Z3Tv3r0YM2YM2rRpg+joaMycORM7d+4M\n2TkPqOK57rrrsH37dpSUlKCxsRGfffYZxo4dG8hDBIT27dsjPj4eu3fvBgCsWrXKI+e4ceOwatUq\nAMCOHTuQmJiIjIwMjBs3Dp9++imcTieKioqwfft2XHfddUGVs6SkBPfffz+eeeYZzJ071zKynzx5\nEgsXLoTD4UBDQwPWr1+PMWPGIC4uLqLlBoC3334bn3/+OdasWYNHH30UEyZMwKJFiywhe2NjI55/\n/nlUV1ejoaEBK1aswB133BHxso8fPx5btmxBZWWlx/oZPHhwxMstkZubi6ysLCQkJACwxjPav39/\n5OTkoKamBqIoYsOGDRg2bFjoznkgIiRY1q1bJ06bNk28+eabxZdeeinQu28WEyZM8ES1HT9+XLzj\njjvEqVOnivPnzxcrKytFURTFiooK8ZFHHhGnTZsmzpo1Szx69Kjn+4sXLxanTp0qTpkyRfzyyy+D\nLu/ixYvFgQMHijNmzBCnT58uzpgxQ3z11VctI/stt9wiZmdni2+++aYoiqKYm5sb8XKzrF692hPV\nZhXZly1bJk6ZMkWcNGmSuHjxYsvI/vHHH4vTpk0TJ0+eLD733HOiy+WyhNyiKIpr164Vn3jiCdl7\nVnhGly1bJk6ePFnMzs4Wn3rqKbGuri5k55yKhBIEQRAhJfJW/gmCIIgrGlI8BEEQREghxUMQBEGE\nFFI8BEEQREghxUMQBEGEFFI8BEEQREghxUMQBEGEFFI8BEEQREj5/3313ytw8a/kAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fbabd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "filename = log_filename\n",
    "with open(filename, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "episodes = data['episode']\n",
    "\n",
    "# Get value keys. The x axis is shared and is the number of episodes.\n",
    "keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "print keys\n",
    "reward = data['nb_episode_steps']\n",
    "# reward_mean = [sum(reward[:index])/(index+1) for index in range(len(reward))]\n",
    "reward_mean = np.convolve(reward, np.ones(50)/50)\n",
    "\n",
    "plt.plot(episodes[50:8000],reward_mean[50:8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'duration', u'episode_reward', u'loss', u'mean_q', u'mean_squared_error', u'nb_episode_steps', u'nb_steps']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11df62b90>]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAEeCAYAAAA0FjqrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAAIABJREFUeJzt3Xt0U2W+N/Dvzj1p0qb3UoWKOgUGGDwOBQQUCrwy2FYB\nX15F5gAjAqKu8Xg5vF4QOCzAQUEcBz2vZznCKDPjcLcOshwVUFsExRkEFQVUQC69hl7S3JP9/pFm\n07SFFGibJ8n3sxaLvZOd9veDNN8+O0+eLcmyLIOIiEhgqmgXQEREFAnDioiIhMewIiIi4TGsiIhI\neAwrIiISHsOKiIiEx7AiIiLhaTpy0Nq1a7FlyxYAwMCBA7FkyRJoNOcfWlZWhscffxw9evQAAPTr\n1w/Lly/vgnKJiCgRSZE+FHzw4EEsWLAAGzduhF6vx/z589G/f3/MmDFDOeaVV15BUlJS2G1ERESd\nJeLIKiUlBQsXLoRerwcA9O3bF2fPng075tChQ3C73di2bRtyc3OxcOFCZGdnd03FRESUcCK+Z5WX\nl4fBgwcDAGpra7F+/XqMGzcu7Bir1YpZs2Zh69atGDlyJB577LGuqZaIiBJSxNOAIadOncL999+P\n22+/HXPmzLnosQUFBdi1axfMZvNFj5NlGZIkdbxaIiJKSB2aYHH48GHMnTsXc+fOxbRp08Lu83g8\nWLduXZsA02q1Eb+uJEmorW1EIi2lK0lAerqFfScI9s2+E0Go764UMaxsNhtmz56NxYsXtzn9BwA6\nnQ5btmxBfn4+Ro8ejc2bN2PQoEHKe1yRyDIu+T+1yeXF7zcdxKyifshONV3agwVxOX3HA/adWNg3\ndZaIpwFXr16NN954A9dcc41y2m7UqFGora3FmDFjUFhYiMOHD2PRokVwOp1IT0/HihUrOjzBoqbm\n0n8Dufd3O5Xt1/5vIVQxdCpRkoCMDMtl9R3L2Df7TgSJ3ndXijiyeuSRR/DII49c9Jh+/fphw4YN\nnVbUpThT3YSrsy7+3hgREcW2mFvB4uD3tWH7f/ngSJQqISKi7hJTYSXLMl7c+GXYbd+erMOBYzXw\n+QNweXxRqoyIiLpSh2YDimLWil3t3v7SpoPK9pr/uAUmQ0y1RUREEcTMyKr8UPiqGZNuubbd4z76\n8nR3lENERN0oZsLqj9sPh+3fmJ+J6eP7tDlu467veTqQiCjOxERYebz+NrdlpBhw86Ae7R7/wAsf\nw+FiYBERxYuYCKtNH30ftv+7+2+CXquGWqXCkH5Z7T7moRc/7o7SiIioG8TETIQP9p8K28+yGpXt\nubf3h63Bjf6902B3evHhF8FjNeqYyGEiIuqAmAirlnTa8BCSJAlP/fsvAQCBgIz+16Thpc0H4fMH\nlJUuMlIM+K97h8Coj7l2iYgIMXIasOVqSs/NG37B41QqCQOuTWtze029CyvfOtAVpRERUTeIibBq\nucZWskl30WMvdPqvzu7uzJKIiKgbCX9erOU6u7cW9OzQY154aAQqbQ4c/KEWJyvt+PpHG841uvFT\nlR09uY4gEVHMEX5k9d3JOmU7PcXQocdYzXr06ZWKKaOvx2N33aDcvuj1zzq9PiIi6nrCh9Vzf/2X\nsp2SdPFTgBfSckR27+92ooMXRyYiIkEIH1Yt9ctLvazH3T32Z2H7s1bswr2/24kAQ4uIKCbEVFhZ\nIkyuuJgF0we3ue2pV/deSTlERNRNYiqsrsS1uclYNLMg7LaqOic+OXgmShUREVFHCR9WWanB1Sqe\nnTPsir9WXo4Frz8xBq8+Plq5be2732LbJz9c8dcmIqKuI3xYhRaxTb7MyRXt0WpUWP3QCGW/tPw4\n/nvbV5329YmIqHMJHVY+fwB1dg+AtsssXakUsx4vP3KLsv/5t1X455HqTv0eRETUOYQOq3fKjyvb\nalXnl2rUa/DKo+cDa82WQ3C6eWkRIiLRCB1We7+p6PLvYdBpcF9xP2X/wdUfo+qco8u/LxERdZzQ\nYVVd5+qW7zN8QA9MuuVaZf+JV/fitb9/0y3fm4iIIhM6rLpT0U156N0jWdnf81UFPtj/UxQrIiKi\nEIZVM5Uk4ZkZgzG75OfKbX/54ChPCRIRCUDosBr682wAwMwJfbvte97UPwcv/naksv/Eq3u75b0z\nIiK6MKHD6lxD8D2rzp62HkmySYdVD57/HNb/lH6Dc428HhYRUbQIHVZHTtUDAPYc6v6RTapFH7Y8\n03++sqfbayAioiChwyrkdE1TVL5vXo4Fv7v/JgBAQJax6q1/RXgEERF1hZgIq3GDr47a986yGpXt\nr4+fw469J6JWCxFRohI6rEKXoL/h+oyo1tFyWaaNu79HIMDrYBERdSehwyp0RV+tOrplGvUarPmP\nm5X9j7/kZUWIiLqT0GHl9QfDSh3lsAIAk0GLX1yXDgB4473volwNEVFiiX4KXITPFwAQvKSHCO75\nX/nK9oGjNVGshIgosYiRAhfgCwTDSqOWolxJUJbViOtyg0sy/fn9I1GuhogocQgdVm5P8MKLGgFO\nA4bMv+dGAEBtgwv/+OxklKshIkoM4qRAK0d+qoOrOazUKjFGVkDwlOTdY38GIDgz0OcPRLkiIqL4\nJ2xYbfvkB2VbksQJKwC4taAnzEYt/AEZD79UFu1yiIjinrBhJVpAtTbn9uDq7E63D8eal4UiIqKu\nIWxYhT5jJaoBvdNxdWbwQ8vL138Bt9cf5YqIiOKXwGEV7Qoim3/Pvynb81Z9FMVKiIjiW4fCau3a\ntSgpKUFJSQmeeuop+Hy+sPsrKysxffp0FBUVYebMmbDZbFdcWCAG0sps1GLSzb2V/Xo7LyNCRNQV\nIobVwYMHsXXrVmzatAnvvPMOfD4f/vznP4cds2TJEtx5553Yvn07SkpKsGzZsisuTPT3rEJKRpwP\nq5V/OxDFSoiI4lfEsEpJScHChQuh1+sBAH379sXZs2eV+30+H/bt24fi4mIAwMSJE7F79274/Vf2\nHs7Aa9MAAHqd+oq+TncIXUbkdHUTvj5+5aNKIiIKp4l0QF5eHvLy8gAAtbW1WL9+PVasWKHcX1dX\nB7PZDLU6GCpqtRoWiwU2mw2ZmZkRC7jQACp0Zd4RA3IueIwoslON+PWt+Vj/jyNY9dYBvPLoLTDq\n2/+nDfUiek+djX1Ht47uxr6jW0d3645+I4ZVyKlTp3D//ffj7rvvRkHB+SvoBgJtPxQryzJUqo7N\n3UhPt7R7+85/nlb+fmTa4I6WGTWTx/bBXz44ikBAxs4DZzGj6OcXPf5Cfcc79p1Y2Dd1lg6F1eHD\nhzF37lzMnTsX06ZNC7svLS0NdrsdgUAAKpUKfr8fDocDVqu1QwXU1jZedOaf2ahFTU1jh75WtC25\ntwAL//g5Nu08ihuuTcVVzVPbW5Kk4BM5Ut/xhn2z70SQ6H13pYjDH5vNhtmzZ2PhwoVtggoANBoN\nCgoKUFpaCgAoLS3FkCFDlNOCkchy+39G/qIHAGBK4XUXPEa0P7kZZowf2hMAsOC1z+Dx+ts97mJ9\nx/Mf9p1Yf9h3Yv3pahFHVn/605/Q1NSEl19+GWvWrIEkSRg1ahRqa2sxZswYFBYWYtGiRXjyySfx\n2muvwWq1YuXKlVdcWOgUqF4r/gSLliYMzcOOvcEFbl8t/QYPTR4Y5YqIiGKfJEd5qYiamvaHy6/9\n/Rvs+aoCD04aiF/2iTxRQyT7vqnEq6VfAwBG35CL6b/qq9wnSUBGhuWCfccr9s2+E0Gi992VhF3B\nIrSauSjXsroUQ3+erWzvPnAGP1XZo1gNEVHsEzas/IHgryXqGAwrAHj9iTHolRWcYLHszf28lAgR\n0RUQN6z8zWHVwSnwInp6+i+RlqyHxxvAS5sPRrscIqKYJWwSiHZJ+8uh1agxZfT1AICvfrDhREVs\nTMEnIhKNsGEVDyMrIPj+1S2DcgEA/7Xuc9Q2uKJcERFR7BE2CQ6fOAdArEvaX667x16vbD/+8h6I\nfq0uIiLRCBtWIb52lnOKNQadBstmD1X2n3ylnIFFRHQJhA8rxMlreo/0JEy+5VoAwNc/1OKdPcej\nWxARUQwRPqwMF1i9PBYVD78Gd44KBtbWj3/Em//4LsoVERHFBiHDytZiEkJuuimKlXS+opvyMOTn\nOQCAXf88jfJDZyM8goiIBA2r85eHj5UrBneUJEl4ZtZQjP634AzBP24/jOMVDVGuiohIbEKG1cEf\naqJdQpeb8au+GD8kuEL7knX7w0aTREQUTsiwsph00S6hW9wxsrey/fxbB2B3eqNYDRGRuIQMq+uv\nSol2Cd3CoNPgxd+ORE6aCZU2B377+09QVeeMdllERMIRMqxCi9j2750W5Uq6XrJJhyd/faOy/8T/\n+xT1TZ4oVkREJB4hwyoQWnE9Dlav6AiLSYdnZgxW9pf+6XNUnnNEsSIiIrEIGVahkZUqzmYCXkzv\nHsl46eGb0beXFbUNbiz9034ufEtE1EzIsEq0kVWI2ajFw/97ECwmLZpcPix9Yz8OHI3/mZFERJEI\nGVbKyCrBwgoA9Do1nps3HH17WeEPyHhp80Fs//Q41xIkooQmZFgl6sgqRK9VY/49N+LWguDnsDZ/\n9APe338qylUREUWPkGGVyCOrlu4e+zNlLcG3PjyKzR99D38crEJPRHSphFwlNvSCnOhhBQBFN10D\ntUqFDbuOYfunJ7D90xMY3DcL/35rfsJ8eJqISMiweu3vhwEAR36qi3IlYhg/pCf8gQA2f/QDAGD/\nt1XY/20VfpmfiQcnD4xydUREXU/I04A+f3BkVXWOqzkAwcVvi266Bv/96CiMufEqaNTBEecXR6rx\n+ruH4fL4olwhEVHXEjKsqH16nRq/vrUP/uc/CzGl8DoAQNnBs1j2xhc4dro+ytUREXUdIU8DUmQT\nhubhxvxMrPzrAZyuacLyN78AANwyqAem/6pvQn2gmojiH0dWMSw71YQnpt2IXtlm5baPvzyLx9aU\n43uOtIgojnBkFePSUwxY/JshsDu9WLz2M9ga3Khv8mDZm19ArZLgD8i44foM3FfcDyaDNtrlEhFd\nFqHDqk9Pa7RLiBlmoxYrHxgBfyCAf3z2Ezbu/l75vNqBYzV46MVPYDZqccfI3sjLtuDqrCToNGp+\nPICIYoKQYfWL69Jx8PtajB/aK9qlxBy1SoUJw/JQ0C8Lb7z3HWwNbpypaQIA2J1e/Pn9I2HH3z7i\nGqQlG9CnpxXZaaZolExEFJGQYaXTBN9KS9TlljpDRooRj/6fG5T9k5WN+Pue49j/XXXYcaXlxwEE\n/6379rJiwLXpyO9phcPtQ7bViAyrsTvLJiJql5BhFVqylRPaOk+vbAsemBT8ALE/EMC5Rjf+8flP\n+PpHG87WOuAPyPj6+Dl8ffxcu4/Py7GgR7oJV2Uk4fqrUpCVaoLZqIVWwzk6RNT1xAyr5rSSwLTq\nCmqVChkpRtwzLl+5raHJgz1fVeCHM/WoqXfhrM0Bt8ev3H+iorHN9bU0aglajRoWkxa/uC4duRlJ\n6NPTipw0EyT+pkFEnUjQsFLSirpJcpIOv2r1HmFAllFpc8Dh8qHO7kZABr7+sRZV55yornOhtsEF\nn98Hp9uHD1qsCm8165Bs0iGz+RSiXqdGWrIe027r3609EVH8EDKsQniCKbpUkoQe6UlhtxX0zVK2\nnW4fZFlGTb0Lh0+cw/GKRvxwph7VdS7U2T04WWUPe+wH+09hQO80DLg2HRq1hKsyzFCrJBj1GqQm\n68M+yOz2+KHVqDhbkYgACBpWMt+0iglGffDp08ugRa9si3J7dZ0TdqcXNfUu/FRlh0Gnxt6vK3C6\npgn7v6tuM8kjRKdVIdmkg9vrR6PDCwlAbkYSBl6XjqsykpCbkYSsVCOS+HkxooQjaFgF04pRFZsy\nrUZkWo3o3SNZGYkV3ZQHtV6Lt977FrYGF3QaFY6eqsfZWofyOI83gJp6FwAoH2g+XdOE081T70OS\nDBpYzXrkpJmgUkmwmLSwO71QSRLONbpxzu7GiAE56N87HRaTFhkpBr6HRhTjxAyr5r/5+hJfUi0G\nTBl93fmRcwteXwCNDg8cLh8yrAYYdBrU1Dlx1ubA2VoHztTYcabGgep6J+rtHjS5fG1CrKWtn/yI\nrZ/8CACwmLTo09OK/r3TcHWmGSaDBnqtGslJOmjUPNlMFAuEDKsQ/jacOLQaFdKSDUhLPn9bRvPn\nvAZemx52rNvjx/GKBtidXjS5fPD6AjAZNPD6AlCrJMgy8M0JG05XN8Hp9qGm3nXB048pZh2MOg0C\nARlqtYTc9CQYdGrYGt1ocnmRZjHA1ujCgN7p0GpU6JllRrJJh+QkLVKS9NBoJKgkic9Voi4mZFgF\n2vvVm6iZXqdGn16pFz1m5C96KNv1TR58/WMtjp6qR9U5JxxuH+wOL+rsbtTbPaiHRzm25WlJADhZ\naQ/7uz0SALVaBb1WBbNRi8xUI5JNOpiNWui1avgB+Lx+uL1+mAwapCcb4PPL0GmDozqPN4AmpxdX\nZSahZ5YZFpMORr0aahVHfUQhHQ4ru92OqVOn4tVXX0Vubm7YfWVlZXj88cfRo0fwBaJfv35Yvnz5\n5VcVmrnOX1apE6Qk6TB8QA8MH9Aj7HZZluFw+9Dk9EKnVcPp9qGieap+kkGLrFQjaupdqG9yo+qc\nE1qNCqerm2B3etHg8KDR4YXfH4DPL8PnD6DJ5UOTy4fKTrpoqE6rgsWoRXKSDj2zzEhJ0kOtkmA2\naZtHd81/TFoY9RqO7iiudSisDhw4gGeeeQbHjx9v9/6DBw9i3rx5mDFjRqcUdf49K/7wUdeRJAlJ\nBq0yu9Bq1reZqp+bkdTeQ9vl9QVQZ3fD1uBCo8OLRqcXLo8PFrMBLqcHSUYtGh1eVJ9zQqORYHd4\nYTJoodFI0GvVze/NNcHh8sLh9sPl9qHW60Ztgxs/nm286PfWqCWkJOmg0wZHZHqdChqVCjKCy5fV\nN3kgAQjIgMfnR5pFD6NegyanF35ZRpIhGIopSTpYjFoY9MH39dKTDUgxB0eJBp2aP5MUNR0Kqw0b\nNmDx4sWYP39+u/cfOnQIbrcb27ZtQ25uLhYuXIjs7OzLLoqzASkWaTUqZSZkiCQBGRkW1NQ0tjux\n5GICsoxGhxe2BhdOVwdDzB8I3tbg8KChyaP83ejworbB3eGvXXUZo7/QqM5i1MJi0iEjxaCEoEat\ngiQBWo0aWo2EJKMWSSY9PG4v1CoJKpWETKsROo0aAKDXqmC16GEx6aBWSbA1uKDVqpFs0kKnUcPl\n8UOrkZq/Ll8JqINhFTqlJ1/gp81qtaK4uBgjRozAX//6Vzz22GNYv359hwq42PNQkuLvVGCon3jr\nKxL2femPVUsSrGYdrGYdrs1NvuixsizD7vQqpyRdHj/8ARkerx+BgIwUsw6SFPw4gFGnxrlGN+xO\nL1KSdFCrVWhyelHfdD4A3R4/nG4fahvcaHB40OT0wu70Bt/js3sAXHgmZmdKMmhgteiRkWKAxaSD\nQRcMMpUEGHQaGHRqGHRqqFvM6uzdIxlXZyZFZSSY6M/zrtQpEyyeffZZZXvq1Kl44YUXYLfbYTab\nL/KooPR0S5vbNM2/faWmJiEjo+398aC9vhMB++46mV389WVZhtPtQ0OTB7YGFyptDqSY9dCoJfh8\nMvyBAHz+AJxuP1weHwIBWQlMny+AqnNOeH3BYzw+P2rrXGh0euD1BZCeYoDfL6PO7obb44dRr4bX\nJ6PR0fwxherLC0dJAkwGLSwmLczNk14sJl1whGjSwWIKngY2GbXNn8kzIsmohdmoDQvAS5Woz/Ou\ndMVh5fF4sG7dOsyZMyfsdq22Y6sM1Na2PT3i8fgAAPX1DtTUCDlh8bJJUvCJ3F7f8Yx9x0/fGgBZ\nFh2yLLoLHtNZfbs8PtTZPTjX6FaCy6TXQJZluL2B4AjQ44PPH4AECW6vH9+fqUdtvQsuT3BU2eT0\nosnpBVrN9IzEoAv+0mzUa6DTBE9HShKg16qhVkvQNp+iDMhy8KMPKgk6rRpGgxaQA9Bp1YAM5fSo\nSa/BmF9eBatZf/n/IIIK/X93pStOAp1Ohy1btiA/Px+jR4/G5s2bMWjQIOj1HfsPkWW0eTK33I+X\nH/DW2us7EbDvxHKlfeu1GmSnapCdevkXBvX5A3C4fGhyedHkbP47bNsHl8eHxuaPM4SOdbqDVx1w\ntbj6wJVKMmhw6xBeVPZyXFJYtTz/u2DBAowdOxaFhYVYvXo1Fi1ahFWrViE9PR0rVqy4oqKU2YCc\nYkFEV0ijVinT/C9FQJYhAXC6/fD6/JABBAIy3F4//H4ZXn8AQHBUoWp+P9Dj88NiNqK61g6393zI\neX0BSBJwY35Xn6yNX5cUVh9++KGyvXTpUmW7X79+2LBhQ6cVpcwGZFYRUZSErgJgMmjQ0ZfK87M/\nDQk5ku5KQn5Env/HRETUkpBhFUorFYdWREQEQcOKVwomIqKWxAyr5r+ZVUREBIgaVrygFRERtSBk\nWIXGVipmFRERQdCwCnA6IBERtSBkWJ2/nhWHVkREJGhYyeCHgomI6Dwhw0q5hDhPBxIREQQNq5DO\nXECSiIhil9BhZbXE31L6RER06YQLq5+q7Mo2p64TEREgYFg1Ob3KNmcDEhERIGBYHThWo2xzZEVE\nRICAYdXk4siKiIjCCRdWe76qULZ5iRAiIgIEDKuemWZlm1lFRESAgGGVm5mkbPM0IBERAQKGVctT\nf8wqIiICRAyrFlMA+Z4VEREBIoYVR1ZERNSKcGGVm8H3rIiIKJxwYZWTZop2CUREJBjhwoqIiKg1\nYcPKpNdEuwQiIhKEsGHVv3datEsgIiJBCBhWvDwwERGFEzCsgjgRkIiIQoQNKyIiohCGFRERCY9h\nRUREwhMurGTOryAiolaECysiIqLWGFZERCQ8hhUREQmPYUVERMITLqw4v4KIiFoTLqxCeC0rIiIK\nETasiIiIQhhWREQkvA6Hld1uR0lJCc6cOdPmvsrKSkyfPh1FRUWYOXMmbDZbpxZJRESJrUNhdeDA\nAUydOhXHjx9v9/4lS5bgzjvvxPbt21FSUoJly5ZdfkWcYUFERK10KKw2bNiAxYsXIysrq819Pp8P\n+/btQ3FxMQBg4sSJ2L17N/x+/xUVxukVREQU0qFrxy9fvhwAILezcF9dXR3MZjPUajUAQK1Ww2Kx\nwGazITMzM+LXbj3pr+V+PE4IDPUUj71dDPuObh3djX1Ht47u1h39diisLiYQCLS5TZZlqFQdezss\nPd0Stp9c2QQA0Ou1yMiwtPeQuNC670TBvhML+6bOcsVhlZaWBrvdjkAgAJVKBb/fD4fDAavV2qHH\n19Y2hq203tDgBAC43V7U1DReaXnCkaTgE7l13/GOfbPvRJDofXelKw4rjUaDgoIClJaWYuLEiSgt\nLcWQIUOU04KRyHL4ZUEutB1vWvedKNh3YmHf1Fku6XNWLVeVWLBgAXbt2gUAWLRoEd5++20UFxdj\n8+bNeOaZZy67IJnTAYmIqJVLGll9+OGHyvbSpUuV7ZycHKxdu7bzqgI4HZCIiBRcwYKIiITHsCIi\nIuExrIiISHjihRXnVxARUSvihVUzzq8gIqIQYcOKiIgohGFFRETCY1gREZHwhAsrzq8gIqLWhAur\n8zjFgoiIggQOKyIioiCGFRERCY9hRUREwmNYERGR8IQLK16wjIiIWhMurEIkTgYkIqJmwoYVERFR\nCMOKiIiEx7AiIiLhCRhWnGFBREThBAyrIM6vICKiEGHDioiIKIRhRUREwmNYERGR8IQLK65gQURE\nrQkXVgrOsCAiombihhUREVEzhhUREQmPYUVERMJjWBERkfAYVkREJDxhw0ridEAiImombFgRERGF\nMKyIiEh4DCsiIhKecGHF1ZaIiKg14cJKwfkVRETUTNywIiIiasawIiIi4TGsiIhIeB0Kqx07dqC4\nuBjjx4/Hyy+/3Ob+srIyDBs2DJMmTcKkSZPw1FNPXXZBMi9oRURErWgiHVBTU4Pnn38eW7ZsgcVi\nwX333Yfy8nKMGDFCOebgwYOYN28eZsyY0WmFcX4FERGFRBxZlZeXY9iwYbBarVCr1bjjjjvw7rvv\nhh1z6NAhfPTRR5g0aRIefPBBVFZWdlnBRESUeCKGVWVlJbKzs5X97OxsVFRUhB1jtVoxa9YsbN26\nFSNHjsRjjz3W+ZUSEVHCingasL33kFSq8Ix79tlnle2pU6fihRdegN1uh9lsjliAJF1gX2p7XzwI\n9RSPvV0M+45uHd2NfUe3ju7WHf1GDKvs7Gx8/vnnyn5VVRVycnKUfY/Hg3Xr1mHOnDlhj9NqtR0q\nID3dErZvsTQAAAx6LTIyLO09JC607jtRsO/Ewr6ps0QMq+HDh+MPf/gDbDYbLBYLSktLMXXqVOV+\nnU6HLVu2ID8/H6NHj8bmzZsxaNAg6PX6DhVQW9uIloO3hgYnAMDl9qKmpvES2xGfJAWfyK37jnfs\nm30ngkTvuytFDKusrCzMnz8fM2bMgNfrxbhx4zBu3DgsWLAAY8eORWFhIVavXo1FixZh1apVSE9P\nx4oVKzpcgCyj3f9UCe3fHi8u1He8Y9+JhX1TZ4kYVgAwfvx4jB8/Puy2pUuXKtv9+vXDhg0bOrcy\nIiKiZlzBgoiIhMewIiIi4QkXVjzPS0RErQkXVucl2AcViIjoggQOKyIioiCGFRERCY9hRUREwhMu\nrGRwhgUREYUTLqxCEm0hSCIiujBhw4qIiCiEYUVERMJjWBERkfAYVkREJDzxwoqTAYmIqBXxwqoZ\nJwMSEVGIsGFFREQUwrAiIiLhMayIiEh4woUV51cQEVFrwoWVgustERFRM3HDioiIqBnDioiIhMew\nIiIi4YkXVpxhQURErYgXVs04vYKIiEKEDSsiIqIQhhUREQmPYUVERMJjWBERkfCECyuZ0wGJiKgV\n4cJKwemARETUTNywIiIiasawIiIi4TGsiIhIeMKFlcz5FURE1IpwYRXC+RVERBQibFgRERGFMKyI\niEh4DCsiIhIew4qIiIQnbFhJnGJBRETNOhRWO3bsQHFxMcaPH4+XX365zf2VlZWYPn06ioqKMHPm\nTNhstk77A9U8AAAHq0lEQVQvlIiIElfEsKqpqcHzzz+P9evX491338X+/ftRXl4edsySJUtw5513\nYvv27SgpKcGyZcu6rGAiIko8EcOqvLwcw4YNg9VqhVqtxh133IF3331Xud/n82Hfvn0oLi4GAEyc\nOBG7d++G3+/vuqqJiCihaCIdUFlZiezsbGU/OzsbFRUVyn5dXR3MZjPUajUAQK1Ww2KxwGazITMz\nM2IB0oXempIucl8MC/UUj71dDPuObh3djX1Ht47u1h39RgwruZ31j1Sq8wOyQCDQ7mNaHnMx6emW\nsP2JYyyYOCa/Q4+NZa37ThTsO7Gwb+osERMlOzsbVVVVyn5VVRVycnKU/bS0NNjtdiW0/H4/HA4H\nrFZrF5RLRESJKGJYDR8+HHv37oXNZoPX60VpaSlGjRql3K/RaFBQUIDS0lIAQGlpKYYMGaKcFiQi\nIrpSktzeeb5W3nvvPaxZswZerxfjxo3D448/jgULFmDs2LEoLCxERUUFnnzySVRXV8NqtWLlypVh\noy8iIqIr0aGwIiIiiiZhV7AgIiIKYVgREZHwGFZERCQ8hhUREQkvamEVaXHcWLN27VqUlJSgpKQE\nTz31FHw+H44cOYK77roLt912Gx5++GG4XC4AgN1uxwMPPICioiJMmTIFJ06cUL7OCy+8gAkTJmDC\nhAnYtWtXtNq5ZCtWrMCTTz4JAAnR986dOzF58mTcdtttylqYidD3li1bUFRUhJKSEjz33HMA4rtv\nu92OkpISnDlzBgBw9OjRTutV5NfA1n2Xl5dj8uTJmDhxIn7zm9/g7NmzynHd1rccBdXV1XJhYaF8\n7tw52efzyTNnzpTLysqiUUqn+PLLL+WSkhLZ5XLJsizL8+fPl9euXSvfcccd8ueffy7Lsiz//ve/\nl1etWiXLsiwvW7ZMXrNmjSzLsvzpp5/Kd911lyzLsvz+++/L9957rxwIBOSqqip57NixckNDQxQ6\nujR79uyRhw0bJj/xxBOyLMtx3/fJkyflm2++Wa6srJR9Pp88bdo0edeuXXHft8PhkAcPHizbbDbZ\n7/fLU6ZMkffs2RO3ff/rX/+Si4uL5QEDBsinT5+WZbnzntsivwa27tvj8cgjRoyQT5w4IcuyLG/Y\nsEGeN2+eLMvd23dURlaRFseNNSkpKVi4cCH0ej0AoE+fPvjuu+9gt9sxePBgAMCUKVOwY8cOAMCu\nXbswefJkAMCwYcNQW1uLiooK7Nq1CyUlJZAkCZmZmRg6dCh27twZnaY6qK6uDi+++CLuv/9+AEBF\nRUXc9/3BBx+gqKgIWVlZUKvVWL16NfLz8+O+b0mSoNfr4XQ64fV64ff7odFo4rbvDRs2YPHixcjK\nygLQuc9tkV8DW/ft8Xjw9NNPo1evXgCAfv36KevDdmffEdcG7AqRFseNNXl5ecjLywMA1NbWYv36\n9Zg6dSpOnjypHJOVlaX02Lr/rKwsnD17ts3tmZmZqKys7KYuLs+iRYvw6KOPKqcL2ust3vo+ceIE\ndDod7rvvPlRXV6OwsBCjR4+O+74NBgNmz56NCRMmwGg0YsiQIdBqtXHb9/LlywGcXx+1s5/bor4G\ntu47KSkJEyZMABBcC3bNmjUYN24cgO7tOyojKznC4rix6tSpU5gxYwbuvvtu5bevlkI9tl78V5Zl\nqNXqdv9dJIGXb964cSNyc3MxdOhQ5bb2FjaOt779fj/Kysrw/PPPY+PGjTh06BD27dvX5rh463v/\n/v3YuHEjdu/ejU8++QQqlQplZWVtjou3vkM687kdi6+BbrcbDz/8MGRZxty5cwG0fS3vyr6j8q8T\naXHcWHT48GHcc889mDp1KubMmYOcnJywHqurq5Uec3JyUF1dHXZfdnY2srOz29wu8r/Ljh07UFZW\nhokTJ+Kll17Czp07sWnTpgv2EC99Z2Rk4KabbkJqaip0Oh3Gjh2LEydOxH3fBw4cwC233ILU1FRo\ntVpMmjQJn332Wdz3HdKZP9Ox9hrY0NCAGTNmwGQy4ZVXXlHWfu3OvqMSVpEWx401NpsNs2fPxsKF\nCzFt2jQAQI8ePWA0GrF//34AwKZNm5QeR48ejU2bNgEA9u3bh6SkJGRnZ2P06NF4++234ff7UVNT\ng71792L48OHRaaoDXn/9dbzzzjvYtm0bfvvb32LMmDFYtmwZDAZDXPddWFiI8vJyNDY2KqOsG2+8\nMe77HjhwIMrKyuBwOCDLMnbu3ImCgoK47zukM3+mY+018MEHH8QNN9yAFStWhC1SPmrUqG7rO2pr\nA7a3OG6sWr16Nd544w1cc801kGUZkiRh1KhRKC4uxoIFC2C323H11Vdj5cqVMJvNaGxsxNNPP40f\nf/wROp0Oy5cvR58+fZSv9eGHHyIQCOChhx7CbbfdFuXuOmbr1q347LPP8Oyzz+Lo0aN45pln4rrv\nLVu2YO3atfD5fBg+fDgWLFiAY8eOxX3f69atw9/+9jdotVoMGDAAixYtwsmTJ+O677Fjx+LNN99E\nbm4ujh071mk/06K/Bob6Pn78OGbNmoX8/HzldG1GRgZee+21bu2bC9kSEZHwxH5Hj4iICAwrIiKK\nAQwrIiISHsOKiIiEx7AiIiLhMayIiEh4DCsiIhIew4qIiIT3/wHeXkDGaFkzXAAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ef93710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = log_filename\n",
    "with open(filename, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "episodes = data['episode'][200:]\n",
    "\n",
    "# Get value keys. The x axis is shared and is the number of episodes.\n",
    "keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "print keys\n",
    "reward = data['loss'][200:]\n",
    "reward_mean = [sum(reward[:index])/(index+1) for index in range(len(reward))]\n",
    "plt.plot(episodes[:10000],reward_mean[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'duration', u'episode_reward', u'loss', u'mean_q', u'mean_squared_error', u'nb_episode_steps', u'nb_steps']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11c6ceed0>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAEeCAYAAADSP/HvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ef93090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "filename = log_filename\n",
    "with open(filename, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "episodes = data['episode']\n",
    "\n",
    "# Get value keys. The x axis is shared and is the number of episodes.\n",
    "keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "print keys\n",
    "reward = data['duration']\n",
    "reward_mean = [sum(reward[:index])/(index+1) for index in range(len(reward))]\n",
    "# reward_mean = np.convolve(reward, np.ones(20)/20)\n",
    "\n",
    "plt.plot(episodes[:5000],reward_mean[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEeCAYAAADFHWEmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYCEREZESWEhERKQEFhIRESnh/wGbJ21H63U8BwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e046190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward = data['episode_reward']\n",
    "smoothed = np.convolve(reward, np.ones(100)/100)\n",
    "# reward_mean = [sum(reward[:index])/(index+1) for index in range(len(reward))]\n",
    "plt.plot(episodes[:8000],smoothed[:8000]);\n",
    "\n",
    "reward = data['episode_reward']\n",
    "steps = data['nb_episode_steps']\n",
    "re_stp = np.array(reward)/np.array(steps)\n",
    "re_stp = np.convolve(re_stp, np.ones(50)/50)\n",
    "plt.plot(episodes[:8000],re_stp[:8000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.55918, 8.38011, 9.76248, 10.1422]\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "a = pd.read_csv('train5000.csv')\n",
    "nrow = random.randint(0,a.shape[0])\n",
    "b = a.loc[nrow,'esb']\n",
    "print b\n",
    "# for i in b[1:-1]:\n",
    "#     print i\n",
    "    \n",
    "    \n",
    "\n",
    "b=map(float, b[1:-1].split(\", \"))\n",
    "print type(b)\n",
    "# map(int, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[6.55918, 8.38011, 9.76248, 10.1422]'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.loc[nrow,'esb']#[1:-1].split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.55918, 8.38011, 9.76248, 10.1422]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(float, a.loc[nrow,'esb'][1:-1].split(\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def onehot(observation,min,max,n=10):\n",
    "    my_onehot = np.zeros((n))\n",
    "    value = observation//((max-min)/float(n))\n",
    "    my_onehot[int(value)] = 1.0\n",
    "    \n",
    "    return my_onehot\n",
    "\n",
    "aaa = onehot(64,0.1,72)\n",
    "bbb = onehot(14,0.1,72)\n",
    "aaa\n",
    "bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "gg = np.concatenate((aaa,bbb,aaa),axis=0)\n",
    "print gg\n",
    "print tuple(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "b=[2,1,4]\n",
    "xyz = [a,b]\n",
    "xyz = zip(*[a,b])\n",
    "map(max, zip(*[a,b]))\n",
    "# np.array(a)/np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
