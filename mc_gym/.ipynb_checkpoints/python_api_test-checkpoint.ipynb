{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATLAB closed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MATLAB\n",
      "...still starting up...\n",
      "...still starting up...\n",
      "...still starting up...\n",
      "...still starting up...\n",
      "...still starting up...\n",
      "...still starting up...\n",
      "MATLAB started and connected!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0; Lambda: 7.357; Distance: 11.35; N0:5.449; Number of Nodes: 19\n",
      "[6.4438, 4.1208, 3.5909, 3.5536, 0.27267, 0.56582, 0.66481, 0.71462]\n",
      "[4]\n",
      "==========\n",
      "Step: 1; Lambda: 15.386; Distance: 26.75; N0:10.496; Number of Nodes: 15\n",
      "[5.7971, 6.9591, 6.7574, 6.5022, 1.6198e-10, 0.079251, 0.28113, 0.38334]\n",
      "[1]\n",
      "==========\n",
      "MATLAB closed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymatbridge import Matlab\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "\n",
    "mlab = Matlab(matlab='/Applications/MATLAB_R2014a.app/bin/matlab')\n",
    "mlab.stop()\n",
    "mlab.start()\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    LAM = round(random.uniform(0.1, 20),3)\n",
    "    D = round(np.random.uniform(5,40),2)\n",
    "    N_n = np.random.randint(5,20)\n",
    "    N_0 = round(random.uniform(5, 20),3)\n",
    "        \n",
    "    print 'Step: {}; Lambda: {}; Distance: {}; N0:{}; Number of Nodes: {}'\\\n",
    "            .format(i, LAM, D, N_0, N_n)\n",
    "\n",
    "    res = mlab.run('/Users/zonemercy/Documents/MATLAB/mc_gym/Copy_of_oraginal.m', \n",
    "                       {'arg1': 1, 'arg2': LAM, 'arg3': D, 'arg4':N_0, 'arg5':N_n})\n",
    "    print res['result']\n",
    "    esb = res['result'][:4]\n",
    "    print np.where(esb == np.min(esb))[0]\n",
    "\n",
    "\n",
    "#     a = round(a * np.random.normal(1,0.05,1)[0],3)\n",
    "#     b = round(b * np.random.normal(1,0.05,1)[0], 3)\n",
    "\n",
    "#     print 'Step: {}; Lambda: {}; Distance: {}'.format(i, a, b)\n",
    "#     res = mlab.run('/Users/zonemercy/Documents/MATLAB/mc_gym/Copy_of_oraginal.m', \n",
    "#                    {'arg1': a, 'arg2':b})\n",
    "#     print res['result']\n",
    "    print '='*10\n",
    "\n",
    "mlab.stop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum value: 1\n",
      "min value index: [3 4]\n"
     ]
    }
   ],
   "source": [
    "# find index of minimum values\n",
    "x = [2,3,1,1,5]\n",
    "print 'minimum value: {}'.format(np.min(x))\n",
    "print 'min value index: {}'.format(np.where(x == np.min(x))[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-04 10:13:48,580] Making new env: mc_mat-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATLAB closed\n",
      "Starting MATLAB\n",
      "...still starting up...\n",
      "...still starting up...\n",
      "...still starting up...\n",
      "...still starting up...\n",
      "...still starting up...\n",
      "MATLAB started and connected!\n",
      "[10.245, 19.99, 13, 14.471]\n",
      "Reward: 0, Info: {'action': 0, 'result': array([2]), 'esb': [4.78, 3.3, 2.96, 2.98]}\n",
      "4.78\n",
      "=====\n",
      "[17.855, 19.4, 14, 12.14]\n",
      "Reward: 0, Info: {'action': 3, 'result': array([0]), 'esb': [5.28, 6.43, 6.63, 6.36]}\n",
      "6.36\n",
      "=====\n",
      "[13.448, 20.42, 11, 19.316]\n",
      "Reward: 0, Info: {'action': 1, 'result': array([2]), 'esb': [4.12, 4.02, 3.66, 3.68]}\n",
      "4.02\n",
      "=====\n",
      "[12.515, 12.89, 9, 9.667]\n",
      "Reward: 0, Info: {'action': 0, 'result': array([2]), 'esb': [1.99, 1.56, 1.4, 1.42]}\n",
      "1.99\n",
      "=====\n",
      "[17.298, 10.19, 8, 9.759]\n",
      "Reward: 0, Info: {'action': 3, 'result': array([0]), 'esb': [1.46, 1.78, 1.54, 1.49]}\n",
      "1.49\n",
      "=====\n",
      "[4.569, 36.82, 19, 6.263]\n",
      "Reward: 0, Info: {'action': 3, 'result': array([1]), 'esb': [3.97, 2.9, 2.91, 3.11]}\n",
      "3.11\n",
      "=====\n",
      "[14.668, 38.32, 16, 5.185]\n",
      "Reward: 0, Info: {'action': 3, 'result': array([0]), 'esb': [6.1, 7.39, 7.26, 7.01]}\n",
      "7.01\n",
      "=====\n",
      "[15.499, 15.61, 12, 10.01]\n",
      "Reward: 10, Info: {'action': 3, 'result': array([3]), 'esb': [3.91, 4.32, 3.53, 3.29]}\n",
      "3.29\n",
      "=====\n",
      "[12.847, 25.75, 11, 7.116]\n",
      "Reward: 0, Info: {'action': 1, 'result': array([3]), 'esb': [3.42, 2.85, 2.45, 2.41]}\n",
      "2.85\n",
      "=====\n",
      "[4.697, 5.51, 12, 16.751]\n",
      "Reward: 0, Info: {'action': 3, 'result': array([1]), 'esb': [1.39, 1.19, 1.25, 1.34]}\n",
      "1.34\n",
      "=====\n",
      "MATLAB closed\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('mc_mat-v0')\n",
    "env.configure(nround=2)\n",
    "\n",
    "for t in range(10):\n",
    "    observation = env.reset()\n",
    "    print observation\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print 'Reward: {}, Info: {}'.format(reward, info)\n",
    "    print info['esb'][int(action)]\n",
    "    print '='*5\n",
    "    \n",
    "env.configure(close_mat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-03 14:53:03,336] Making new env: CartPole-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 0/1 finished after 18 timesteps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<script language=\"javascript\">\n",
       "  /* Define the Animation class */\n",
       "  function Animation(frames, img_id, slider_id, interval, loop_select_id){\n",
       "    this.img_id = img_id;\n",
       "    this.slider_id = slider_id;\n",
       "    this.loop_select_id = loop_select_id;\n",
       "    this.interval = interval;\n",
       "    this.current_frame = 0;\n",
       "    this.direction = 0;\n",
       "    this.timer = null;\n",
       "    this.frames = new Array(frames.length);\n",
       "\n",
       "    for (var i=0; i<frames.length; i++)\n",
       "    {\n",
       "     this.frames[i] = new Image();\n",
       "     this.frames[i].src = frames[i];\n",
       "    }\n",
       "    document.getElementById(this.slider_id).max = this.frames.length - 1;\n",
       "    this.set_frame(this.current_frame);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.get_loop_state = function(){\n",
       "    var button_group = document[this.loop_select_id].state;\n",
       "    for (var i = 0; i < button_group.length; i++) {\n",
       "        var button = button_group[i];\n",
       "        if (button.checked) {\n",
       "            return button.value;\n",
       "        }\n",
       "    }\n",
       "    return undefined;\n",
       "  }\n",
       "\n",
       "  Animation.prototype.set_frame = function(frame){\n",
       "    this.current_frame = frame;\n",
       "    document.getElementById(this.img_id).src = this.frames[this.current_frame].src;\n",
       "    document.getElementById(this.slider_id).value = this.current_frame;\n",
       "  }\n",
       "\n",
       "  Animation.prototype.next_frame = function()\n",
       "  {\n",
       "    this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));\n",
       "  }\n",
       "\n",
       "  Animation.prototype.previous_frame = function()\n",
       "  {\n",
       "    this.set_frame(Math.max(0, this.current_frame - 1));\n",
       "  }\n",
       "\n",
       "  Animation.prototype.first_frame = function()\n",
       "  {\n",
       "    this.set_frame(0);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.last_frame = function()\n",
       "  {\n",
       "    this.set_frame(this.frames.length - 1);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.slower = function()\n",
       "  {\n",
       "    this.interval /= 0.7;\n",
       "    if(this.direction > 0){this.play_animation();}\n",
       "    else if(this.direction < 0){this.reverse_animation();}\n",
       "  }\n",
       "\n",
       "  Animation.prototype.faster = function()\n",
       "  {\n",
       "    this.interval *= 0.7;\n",
       "    if(this.direction > 0){this.play_animation();}\n",
       "    else if(this.direction < 0){this.reverse_animation();}\n",
       "  }\n",
       "\n",
       "  Animation.prototype.anim_step_forward = function()\n",
       "  {\n",
       "    this.current_frame += 1;\n",
       "    if(this.current_frame < this.frames.length){\n",
       "      this.set_frame(this.current_frame);\n",
       "    }else{\n",
       "      var loop_state = this.get_loop_state();\n",
       "      if(loop_state == \"loop\"){\n",
       "        this.first_frame();\n",
       "      }else if(loop_state == \"reflect\"){\n",
       "        this.last_frame();\n",
       "        this.reverse_animation();\n",
       "      }else{\n",
       "        this.pause_animation();\n",
       "        this.last_frame();\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.anim_step_reverse = function()\n",
       "  {\n",
       "    this.current_frame -= 1;\n",
       "    if(this.current_frame >= 0){\n",
       "      this.set_frame(this.current_frame);\n",
       "    }else{\n",
       "      var loop_state = this.get_loop_state();\n",
       "      if(loop_state == \"loop\"){\n",
       "        this.last_frame();\n",
       "      }else if(loop_state == \"reflect\"){\n",
       "        this.first_frame();\n",
       "        this.play_animation();\n",
       "      }else{\n",
       "        this.pause_animation();\n",
       "        this.first_frame();\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.pause_animation = function()\n",
       "  {\n",
       "    this.direction = 0;\n",
       "    if (this.timer){\n",
       "      clearInterval(this.timer);\n",
       "      this.timer = null;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.play_animation = function()\n",
       "  {\n",
       "    this.pause_animation();\n",
       "    this.direction = 1;\n",
       "    var t = this;\n",
       "    if (!this.timer) this.timer = setInterval(function(){t.anim_step_forward();}, this.interval);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.reverse_animation = function()\n",
       "  {\n",
       "    this.pause_animation();\n",
       "    this.direction = -1;\n",
       "    var t = this;\n",
       "    if (!this.timer) this.timer = setInterval(function(){t.anim_step_reverse();}, this.interval);\n",
       "  }\n",
       "</script>\n",
       "\n",
       "<div class=\"animation\" align=\"center\">\n",
       "    <img id=\"_anim_imgUEMYKFHDOPYAKJDN\">\n",
       "    <br>\n",
       "    <input id=\"_anim_sliderUEMYKFHDOPYAKJDN\" type=\"range\" style=\"width:350px\" name=\"points\" min=\"0\" max=\"1\" step=\"1\" value=\"0\" onchange=\"animUEMYKFHDOPYAKJDN.set_frame(parseInt(this.value));\"></input>\n",
       "    <br>\n",
       "    <button onclick=\"animUEMYKFHDOPYAKJDN.slower()\">&#8211;</button>\n",
       "    <button onclick=\"animUEMYKFHDOPYAKJDN.first_frame()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAgaeZk4EQAAASlJREFUKM/dkj9LQnEUhp9zr3bpj1uBcKGiJWxzLWivKAIRjIhcCqcgqJbKRagPICiVSVEuNTu0tLYGUg4tkRGUdxLJ0u79Ndxr5FfwTO/L+xzO4XCgO+v2T70AFU+/A/Dhmlzg6Pr0DKAMwOH4zQxAAbAkv2xNeF2RoQUVc1ytgttXUbWVdN1dOPE8pz4j4APQsdFtKA0WY6vpKjqvVciHnvZTS6Ja4HgggJLs7MHxl9nCh8NYcO+iGG0agiaC4h9oa6Vsw2yiK+QHSZT934YoEQABNBcTNDszsrhm1m1B+bFS86PT6QFppx6oeSaeOwlMXRp1h4aK13Y2kuHhUo9ykPboPvFjeEvsrhTMt3ylHyB0r8KZyYdCrbfj4OveoHMANjuyx+76rV+/blxKMZUnLgAAAABJRU5ErkJggg==\"></button>\n",
       "    <button onclick=\"animUEMYKFHDOPYAKJDN.previous_frame()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAgyTCyQ6wAAANRJREFUKM9jYBjO4AiUfgzFGGAp4+yayUvX6jMwMDCsYmBgOCS4OAOrSYmMgcc8/pd5Q3irC+Neh/1AlmeBMVgZmP8yMLD8/c/cqv9r90whzv/MX7Eq/MfAwMDIwCuZdfSV8U8WDgZGRmYGrAoZGRgY/jO8b3sj/J2F6T8j4z80pzEhmIwMjAxsSbqqlkeZGP//Z8SlkJnhPwMjwx/Guoe1NhmRwk+YGH5jV8jOwMPHzcDBysAwh8FrxQwtPU99HrwBXsnAwMDAsJiBgYGBoZ1xmKYqALHhMpn1o7igAAAAAElFTkSuQmCC\"></button>\n",
       "    <button onclick=\"animUEMYKFHDOPYAKJDN.reverse_animation()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAgmVvZElgAAAVFJREFUKM+t0k8ow3EYx/H3s/2aLDUSZctFkgsHEi1XLi5ukpPSWsuJklwclsPSsDKFi7MSJ0I5qF2GHO2m0FY7+BdNv7Y9DpuxDSt5vsfvq+fT9/k+8D8VBxIAWH6H0ead4Qb5BRwCENoceZi5Stl/6BgCBmtWhjzxg4mUQ02rAhil7JgB9tze7aTLxFAKsUUd14B9ZzCyFUk401gQyQJaDNcBHwv7t7ETd0ZVQFEEzcNCdE/1wtj15imGWlEB8qkf2QaAWjbG/bPSamIDyX65/iwDIFx7tWjUvWCoSo5oGbYATN7PORt7W9IZEQXJH8ohuN7C0VVX91KNqYhq4a1lEGJI0j892tazXCWQRUpwAbYDcHczPxXuajq3mbnhfANz5eOJxsuNvs7+jud0UcuyL3QAkuEMx4rnIvBYq1JhEwPAUb3fG7x8tVdc292/7Po7f2VqA+Yz7ZwAAAAASUVORK5CYII=\"></button>\n",
       "    <button onclick=\"animUEMYKFHDOPYAKJDN.pause_animation()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAkR91DQ2AAAAKtJREFUKM9jYCANTEVib2K4jcRbzQihGWEC00JuNjN8Z2Q0Zo3VYWA4lL005venH9+c3ZK5IfIsMIXMBtc12Bj+MMgxMDAwMPzWe2TBzPCf4SLcZCYY4/9/RgZGBiaYFf8gljFhKiQERhUOeoX/Gf8y/GX4y/APmlj+Mfxj+MfwH64Qnnq0zr9fyfLrPzP3eQYGBobvk5x4GX4xMIij23gdib0cRWYHiVmAAQDK5ircshCbHQAAAABJRU5ErkJggg==\"></button>\n",
       "    <button onclick=\"animUEMYKFHDOPYAKJDN.play_animation()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAkEmo00MwAAAS9JREFUKM+tkj1IQmEUhp9j94LQj0FD4RRBLdLQ3ftb26PRcCiQIIiIDFwKC0OhaAiam5wVDBpqCKohQojMLYzaAiUatOtpuQrKVQl64fu+4Xt4OLwc+Fs+nNM16jsPAWS6gZXggoZfXmfhog3hcZ6aTXF87Sp68OmH4/YggAo8bmfyyeh6Z1AAKPVldyO1+Iz2uILq3AriJSe3l+H7aj+cuRnrTsVDxSxay+VYbMDnCtZxxQOU9G4nlU9E1HQBxRkCQMRGRnIbpxMARkvxCIoAorYMMrq0mJ0qu4COUW3xyVDqJC4P+86P0ewDQbQqgevhlc2C8ETApXAEFLzvwa3EXG9BoIE1GQUbv1h7k4fTXxBu6cKgUbX5M3ZzNC+a7rQ936HV56SlRpcle+Mf8wvgJ16zo/4BtQAAAABJRU5ErkJggg==\"></button>\n",
       "    <button onclick=\"animUEMYKFHDOPYAKJDN.next_frame()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAkd/uac8wAAAMhJREFUKM9jYBie4DEUQ8B+fEq3+3UrMzAwMFxjYGBgYJizYubaOUxYFUaXh/6vWfRfEMIL/+//P5gZJoei4/f/7wxnY1PeNUXdE2RgYGZgYoCrY2BBVsjKwMDAwvCS4f3SG/dXxm5gYESSQ1HIwvCPgZmB8f8Pxv+Kxxb/YfiPJIdi9T8GJgaG/38ZFd4Fx0xUYsZt4h8GBgb2D2bLy7KnMTAwMEIxFoVCXIYr1IoDnkF4XAysqNIwUMDAwMDAsADKS2NkGL4AAIARMlfNIfZMAAAAAElFTkSuQmCC\"></button>\n",
       "    <button onclick=\"animUEMYKFHDOPYAKJDN.last_frame()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAknOOpFQQAAAS9JREFUKM/dkrEvQ3EQxz/33mtoQxiYpANbLU26NAabSCcSUouGBVNDjYQaOiDpIEiKjURIw2Kx04hEYmkHEpGoJpSISaXq9Wd4P03/ht5y98197/u9XA4aK4rAWw3lgWddZ3S+/G9mEovtAB8AHE4pgTQAx8PbJweRmsq6GimmNpxaNYXVzMNNCI6A2figimwCGACK786zuWgh3qcsKf/w0pM4X0m/doNVFVzVGlEQsdRj193VxEWpH0RsdRu+zi3tVMqCAsDShoiYqiSV4OouVDFEqS9Pbiyg7vV62lpQ2BJ4Gg0meg0MbNpkYG/e+540NNFyrE1a8qHk5BaAjfnrzUaHfAWImVrLIXbgnx4/9X06s35cweWsVACa3a24PVp0X+rPv1aHFnSONdiL8Qci0lzwpOM5sQAAAABJRU5ErkJggg==\"></button>\n",
       "    <button onclick=\"animUEMYKFHDOPYAKJDN.faster()\">+</button>\n",
       "  <form action=\"#n\" name=\"_anim_loop_selectUEMYKFHDOPYAKJDN\" class=\"anim_control\">\n",
       "    <input type=\"radio\" name=\"state\" value=\"once\" > Once </input>\n",
       "    <input type=\"radio\" name=\"state\" value=\"loop\" checked> Loop </input>\n",
       "    <input type=\"radio\" name=\"state\" value=\"reflect\" > Reflect </input>\n",
       "  </form>\n",
       "</div>\n",
       "\n",
       "\n",
       "<script language=\"javascript\">\n",
       "  /* Instantiate the Animation class. */\n",
       "  /* The IDs given should match those used in the template above. */\n",
       "  (function() {\n",
       "    var img_id = \"_anim_imgUEMYKFHDOPYAKJDN\";\n",
       "    var slider_id = \"_anim_sliderUEMYKFHDOPYAKJDN\";\n",
       "    var loop_select_id = \"_anim_loop_selectUEMYKFHDOPYAKJDN\";\n",
       "    var frames = new Array(0);\n",
       "    \n",
       "  frames[0] = \"data:image/png;base64,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\"\n",
       "  frames[1] = \"data:image/png;base64,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\"\n",
       "  frames[2] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABehJREFUeJzt3T2LXGUYgOGzIYKK7IZASBGJ1oHFFKKlEIXYiaaxs9tUtv4B++3dTgSr/QluIyI2KoQoYvxALYRgXFyS+LkZu4BMinHJzOE+e10wxTwceJ/uZj7OzNpsNpsNABBzYuwFAOAoBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAYEXu/fP38OXu28P+95+PvQpMwsmxF4Ap+3Tn6tzs8M87I2wC0+MVGABJAgZAkoABkCRgACQJGABJAgZAkoDBEp16+uLc7IcP3xthE5geAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAYMlOnPhhQfOb934ZMWbwPQIGCzR+pMXHji//fONFW8C0yNgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoDBkp177tW52S9ffTTCJjAtAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJa7PZbDb2ElCzt7c3HBwcLHTt+t3vhlN3vp6b/3jm5YXPu3Tp0rCxsbHw9XAcCBgcwebm5nD9+vWFrn3j8jPDm689Pzd/9urOwuddu3Zt2NzcXPh6OA5Ojr0AHAe//nV2+Gz/xfvPXzr7/ojbwDT4DAxW4ONbrwx/3Hvi/mPv5utjrwR5AgZL9u2di3Oz3w/XR9gEpkXAYMkePXF77BVgkgQMluzcY98Ma8Phf2ZPPf7FSNvAdPgSB6zA5bPvDncP14e33vlg+Onmb8P6I7fGXgnyJvs1+q2trbFXYMJ2d3eH/f39lZ135cqV4fTp0ys7j+NtZ2fxWzzGNNmAwTL9n/vAHgb3gcE8n4EBkCRgACQJGABJAgZAkoABkCRgACQJGABJfokDjmB7e3vhP7R8GM6fP7+ys6DCjcwAJHkLEYAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMg6V+gJXnL8N6tQQAAAABJRU5ErkJggg==\"\n",
       "  frames[3] = \"data:image/png;base64,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\"\n",
       "  frames[4] = \"data:image/png;base64,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\"\n",
       "  frames[5] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABeBJREFUeJzt3L1rXXUAx+FzS1EK4kvUoVQpgq4qIm1dBCddHCpddHGLk+DkP5D/IrM4RTK4OjgEV6VIKeJrHaRQlQgtvtBct0C8GZLgvYfPyfNAIPy4cL9DDh+Se05m8/l8PgBAzJmxBwDASQgYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgMGK3NjaGG5sbYw9Aybj7NgDYKquf/Th8M+93bFnwGT5DQyWZO3ZS4ee37m5s+IlME0CBkvy1JVrY0+ASRMwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAYMleuTi8wtnt3Y+HmEJTI+AwRLNZouX2Hzv/ghLYHoEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScBgidaeu3zo+e8/fLniJTA9AgZL9NgzLx16/sfPX694CUyPgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYLNmFS1cXzu7c3BlhCUyLgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkDSbD6fz8ceAUXb29tHet3D974fHr37zcL5rSffONb7Xb26+E+B4TQTMDih2Wx2pNe9+/oLw/tvXV44f/m9zWO9n0sVDjo79gA4LT67/c7+9xfOfTsMw/ECBhzkMzBYss+/+nH44tc3hz/3Htr/+u7ui8MH166MPQ3SBAyW7Kfbu8Nvf59fOD9/8bUR1sB0CBiM5Olzizd2AEcnYLACr6x9+p+TvVF2wJS4iQNW4PEHfxlefWJrGIZheHvjk+GBM38Ns/u7I6+CtskGbH19fewJsO+4t8wfxs80q7K52bhD1nNgcEJHfQ7s/+JShYN8BgZAkoABkCRgACQJGABJAgZAkoABkCRgACRN9kFmWLatra2xJ8Cp5kFmAJL8CRGAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIOlfoEhpr2VHV/YAAAAASUVORK5CYII=\"\n",
       "  frames[6] = \"data:image/png;base64,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\"\n",
       "  frames[7] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABghJREFUeJzt3bGLHHUYgOGJRMVELyEYrpGoWJ82gthGIXaCQbAQ7GJlm38gnUV60wlidaWlVwhiZwhHDGKhEEEkJp4J5IzGc+0U2RSbkN3hnXseuOZj4Pd1L3szs3tgNpvNBgCIeWTsBQDgQQgYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgMGKXNk8N1zZPDf2GjAZB8deAKZq+5Ozw93dm2OvAZPlExgASQIGQJKAAZAkYAAkCRgASQIGS/Liux/ec3792y9XvAlMk4ABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoDBEh06/tzc7JcrX6x+EZggAYMleuzw0bnZ7vWrI2wC0yNgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgsETPvPr2Pec/ff3ZijeB6REwWKLHn3r6nvO7t3dWvAlMj4ABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZLdvCJtbnZX3/sjrAJTIuAwZKtb7w2N/vth4sjbALTImAAJAkYAEkHZrPZbOwloGZra2u4devWQteu7X4/HL393dz86vE3Fj7v5MmTw5EjRxa+HvYDAYMHsLGxMVy+fHmha9879dLwwVuvzM1ffv/Cwudtb28PGxsbC18P+8HBsReA/eDXP9eHizv/Pczx+vqnI24D0+AeGCzZz3eeH7668eZw5+8n//3buvbO2GtBnoDBkt3em7939fve/LthwP0RMACSBAyW7IXDl4YDw97/Zs8e+makbWA6PMQBK3Bq/eNhd29tOPvR58OP124Oa4/eGHslyJvsY/RnzpwZewUmbHNzc9jZ2VnZeadPnx6OHTu2svPY3y5cWPwVjzFNNmCwTPfzHtjD4D0wmOceGABJAgZAkoABkCRgACQJGABJAgZAkoABkOSbOOABnD9/fuEftHwYTpw4sbKzoMKLzAAk+RciAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkDSPzoggO8V1sxXAAAAAElFTkSuQmCC\"\n",
       "  frames[8] = \"data:image/png;base64,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\"\n",
       "  frames[9] = \"data:image/png;base64,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\"\n",
       "  frames[10] = \"data:image/png;base64,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\"\n",
       "  frames[11] = \"data:image/png;base64,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\"\n",
       "  frames[12] = \"data:image/png;base64,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\"\n",
       "  frames[13] = \"data:image/png;base64,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\"\n",
       "  frames[14] = \"data:image/png;base64,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\"\n",
       "  frames[15] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAB4JJREFUeJzt3c+L3PUdx/HP7GR1s/lVN5KgFjXVKEijUFp/HRQaSi1CKOJFkB4iDT3oX+FBEKSHHsSIueSQU5GIgh56qEQUCRb10NQIJYU2LSYhmwQ3m2R3ehNkRtjY+X4/fX328YAc8t6BeV2WJ+zO7AxGo9GoAECYmdoDAOD7EDAAIgkYAJEEDIBIAgZAJAEDIJKAARBJwACIJGAARBIwACIJGACRBAyASAIGQCQBAyCSgAEQScAAiCRgAEQSMAAiCRgAkQQMgEgCBkAkAQMgkoABEEnAAIgkYABEEjAAIgkYAJEEDIBIAgZAJAEDIJKAARBJwACIJGAARBIwACIJGACRBAyASAIGQCQBAyCSgAEQScAAiCRgAEQSMAAiCRgAkQQMgEgCBkAkAQMgkoABEEnAAIgkYABEEjAAIgkYAJEEDIBIAgZAJAEDIJKAARBJwACIJGAARBIwACIJGACRBAyASAIGQCQBAyCSgAEQScAAiCRgAEQSMAAiCRgAkQQMgEgCBkAkAQMgkoABEEnAAIgkYABEEjAAIgkYAJEEDIBIAgZAJAEDIJKAARBJwACIJGAARBIwACIJGACRBAyASAIGQCQBAyCSgAEQScAAiCRgAEQSMAAiCRgAkQQMgEgCBkAkAQMgkoABEEnAAIgkYABEEjAAIgkYAJEEDIBIAgZAJAEDIJKAARBJwACIJGAARBIwACIJGACRBAyASAIGQCQBAyCSgAEQScAAiCRgAEQSMAAiCRgAkQQMgEgCBkAkAQMgkoABEEnAAIgkYABEEjAAIgkYAJEEDIBIG2oPgJacev/wt/5/5sSxsvOBX5YfPvRUpUXQLgGDKTpz4ljtCbBu+BEidOza5Uu1J0CTBAymaMeevWO3s3/7oMISaJ+AwRQNZoa1J8C6IWAARBIwmKKNN9068X7x9Mmel0D7BAymaPs9j0y8/+v4Wz0vgfYJGACRBAyASAIGU7btjgfGbpdOf1FhCbRNwGDKtu9+uPYEWBcEDIBIAgZAJAGDKZu/+faJ90/eeL7nJdA2AYMpu3HrzbUnwLogYNCTwaD2AmiLgEFPRqPaC6AtAgYd2LX3t2O30crVsnTunxXWQJsEDDqweeddtSdA8wQMgEgCBj26unSx9gRohoBBB2bnt5UNG7eM3U++8/sKa6BNAgYdGMzMlMHAtxd0yXcYAJEEDHp29evF2hOgCQIGHbn/2Zcn3hf/8XnPS6BNAgZAJAEDIJKAQYdu2Lwwdrt4+mSFJdAeAYMOTfpssHMnP6qwBNojYABEEjAAIgkYdGhh90MT76feP9zzEmiPgEGHbtr1k9oToFkCBkAkAQMgkoBBxxbufnDsdubEsQpLoC0CBh3buHBb7QnQJAEDIJKAQSWrK9dqT4BoAgYd237voxPvJ958qecl0BYBg47NbtxaewI0ScAAiCRgUMnqytUyGo1qz4BYAgY9uPtXL4zdlhf/U0ZeyAHfm4BBD2aGs7UnQHMEDIBIAgYVnT/1ae0JEEvAoAdbbr134v3vf3q95yXQDgEDIJKAARBJwKAnO/bsnXi/culcz0ugDQIGPbntZ7+eeF++cKbnJdAGAQMgkoABEEnAoCeDmWGZnf/B2P2Lt1+psAbyCRj0ZDAzLMMb52vPgGYIGACRBAyASAIGPbrz8d9MvP/70/d6XgL5BAx6tGnHrslf8LmWcN0GIx8JC/+zo0ePltXV1TU99vav3h27nd90T7kw/6M1P9++ffvKcDhc8+OhRQIGUzA3N1eWl5fX9Njjrx0Yu73xzifl1beOr/n5lpaWytzc3JofDy3aUHsArDfvffxl+fGeJ8pfLzz4ze25J8t1BQzwOzDo3dKVa+Uv539eLq9u/ubfn796uvYsiCNg0LPPFh8bu128tlBhCWQTMOjZpuHixPuuW8b/zBTw3QQMenbkzT+UQfn2Kxbv2/Jh+d2+n1ZaBJm8iAMq+MXOw+XyyqZSSinPvPjHsnX2bLn09ZXKqyBLsy+jP3Bg/KXK0JVDhw6VlZWV3p5v//793gdGZw4ePFh7wpo0GzDo0/W8D2wavA8M/A4MgFACBkAkAQMgkoABEEnAAIgkYABEEjAAIvlLHDAFR44cWfMHWk7D7Oxsb88F/6+8kRmASH6ECEAkAQMgkoABEEnAAIgkYABEEjAAIgkYAJEEDIBIAgZAJAEDIJKAARBJwACIJGAARBIwACIJGACRBAyASAIGQCQBAyCSgAEQScAAiCRgAEQSMAAiCRgAkQQMgEgCBkAkAQMgkoABEEnAAIgkYABEEjAAIgkYAJEEDIBIAgZAJAEDIJKAARBJwACIJGAARBIwACIJGACRBAyASAIGQCQBAyCSgAEQScAAiCRgAEQSMAAiCRgAkQQMgEgCBkAkAQMgkoABEEnAAIgkYABEEjAAIgkYAJEEDIBIAgZAJAEDIJKAARBJwACIJGAARBIwACIJGACRBAyASAIGQCQBAyCSgAEQScAAiCRgAEQSMAAiCRgAkQQMgEgCBkAkAQMgkoABEEnAAIgkYABEEjAAIgkYAJEEDIBIAgZAJAEDINJ/Ae0qywbPjUQaAAAAAElFTkSuQmCC\"\n",
       "  frames[16] = \"data:image/png;base64,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\"\n",
       "  frames[17] = \"data:image/png;base64,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\"\n",
       "\n",
       "\n",
       "    /* set a timeout to make sure all the above elements are created before\n",
       "       the object is initialized. */\n",
       "    setTimeout(function() {\n",
       "        animUEMYKFHDOPYAKJDN = new Animation(frames, img_id, slider_id, 50, loop_select_id);\n",
       "    }, 0);\n",
       "  })()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The typical imports\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    display(display_animation(anim, default_mode='loop'))\n",
    "\n",
    "env = gym.make('CartPole-v2')\n",
    "cum_reward = 0\n",
    "frames = []\n",
    "num_episodes=1\n",
    "for i_episode in range(num_episodes):\n",
    "    observation = env.reset()\n",
    "    for t in range(500):\n",
    "        # Render into buffer. \n",
    "        frames.append(env.render(mode = 'rgb_array'))\n",
    "        action = env.action_space.sample() # random action\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"\\rEpisode {}/{} finished after {} timesteps\".format(i_episode, num_episodes, t+1))\n",
    "            break\n",
    "env.render(close=True)\n",
    "display_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEeCAYAAAAuKtolAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nygkAYBzKCQBgHMoJAGAcygkAYJz/D37XZQyGWCR0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a5df0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# plt.hist(np.random.normal(0.9,0.05,500),bins=20);\n",
    "plt.hist(np.random.poisson(5, 2000), normed=True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymatbridge import Matlab\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "class mc_mat():\n",
    "\n",
    "    def __init__(self):\n",
    "#         mlab = Matlab(matlab='/Applications/MATLAB_R2014a.app/bin/matlab')\n",
    "#         mlab.stop()\n",
    "#         mlab.start()\n",
    "        print \"Matlab Bridge Finish...\"\n",
    "        self.range = 1000  # Randomly selected number is within +/- this value\n",
    "        self.bounds = 10000\n",
    "\n",
    "#         self.action_space = spaces.Discrete(4)\n",
    "#         self.observation_space = spaces.Discrete(4)\n",
    "        self.observation = []\n",
    "\n",
    "        self.LAM = round(random.uniform(0.1, 20),3)\n",
    "        self.D = round(np.random.uniform(5,40),2)\n",
    "        self.N_n = np.random.randint(5,20)\n",
    "        self.N_0 = round(random.uniform(5, 20),3)\n",
    "\n",
    "\n",
    "#         self._seed()\n",
    "        print self._reset()\n",
    "        print type(self._reset())\n",
    "    def _step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "\n",
    "        reward = 1\n",
    "\n",
    "        done = True\n",
    "\n",
    "        return self.observation, reward[0], done, {\"number\": self.number, \"guesses\": self.guess_count}\n",
    "\n",
    "\n",
    "    def _reset(self):\n",
    "        self.observation = [self.LAM, self.D, self.N_n, self.N_0]\n",
    "        return np.array(self.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "range(3)\n",
    "pd.qcut([1,20], 10, labels=False)\n",
    "\n",
    "np.zeros((1,4))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[2017-03-06 16:46:43,336] Making new env: CartPole-v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[123L]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_1 (Flatten)              (None, 4)             0           flatten_input_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 16)            80          flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 16)            272         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 16)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 16)            272         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 16)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             34          activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Training for 10000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/rl/memory.py:29: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15/10000: episode: 1, duration: 1.991s, episode steps: 15, steps per second: 8, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.100 [-1.213, 0.585], loss: 0.629382, mean_absolute_error: 0.609395, mean_q: 0.172157\n",
      "   37/10000: episode: 2, duration: 0.199s, episode steps: 22, steps per second: 110, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.591 [0.000, 1.000], mean observation: -0.030 [-1.905, 1.226], loss: 0.468387, mean_absolute_error: 0.610961, mean_q: 0.322136\n",
      "   58/10000: episode: 3, duration: 0.189s, episode steps: 21, steps per second: 111, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: -0.051 [-1.204, 0.650], loss: 0.214771, mean_absolute_error: 0.628850, mean_q: 0.704618\n",
      "   70/10000: episode: 4, duration: 0.113s, episode steps: 12, steps per second: 106, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.125 [-2.578, 1.547], loss: 0.097717, mean_absolute_error: 0.694648, mean_q: 1.122753\n",
      "   96/10000: episode: 5, duration: 0.220s, episode steps: 26, steps per second: 118, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.577 [0.000, 1.000], mean observation: -0.061 [-1.840, 1.027], loss: 0.127962, mean_absolute_error: 0.782913, mean_q: 1.386386\n",
      "  113/10000: episode: 6, duration: 0.156s, episode steps: 17, steps per second: 109, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.647 [0.000, 1.000], mean observation: -0.084 [-1.888, 1.001], loss: 0.084319, mean_absolute_error: 0.812932, mean_q: 1.528354\n",
      "  127/10000: episode: 7, duration: 0.140s, episode steps: 14, steps per second: 100, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.786 [0.000, 1.000], mean observation: -0.084 [-2.539, 1.611], loss: 0.121918, mean_absolute_error: 0.888891, mean_q: 1.794275\n",
      "  138/10000: episode: 8, duration: 0.108s, episode steps: 11, steps per second: 102, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.727 [0.000, 1.000], mean observation: -0.118 [-1.970, 1.174], loss: 0.116882, mean_absolute_error: 0.917147, mean_q: 1.714954\n",
      "  150/10000: episode: 9, duration: 0.111s, episode steps: 12, steps per second: 109, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.104 [-2.560, 1.614], loss: 0.106310, mean_absolute_error: 0.994638, mean_q: 1.938042\n",
      "  189/10000: episode: 10, duration: 0.362s, episode steps: 39, steps per second: 108, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.564 [0.000, 1.000], mean observation: 0.028 [-1.692, 1.334], loss: 0.132775, mean_absolute_error: 1.092662, mean_q: 2.107125\n",
      "  214/10000: episode: 11, duration: 0.200s, episode steps: 25, steps per second: 125, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.055 [-2.167, 1.343], loss: 0.098899, mean_absolute_error: 1.199510, mean_q: 2.289485\n",
      "  233/10000: episode: 12, duration: 0.260s, episode steps: 19, steps per second: 73, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.579 [0.000, 1.000], mean observation: -0.062 [-1.581, 1.021], loss: 0.100467, mean_absolute_error: 1.261183, mean_q: 2.470149\n",
      "  243/10000: episode: 13, duration: 0.268s, episode steps: 10, steps per second: 37, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.121 [-2.054, 1.222], loss: 0.101392, mean_absolute_error: 1.314480, mean_q: 2.575349\n",
      "  255/10000: episode: 14, duration: 0.134s, episode steps: 12, steps per second: 89, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.097 [-2.000, 1.196], loss: 0.128467, mean_absolute_error: 1.382219, mean_q: 2.592017\n",
      "  277/10000: episode: 15, duration: 0.216s, episode steps: 22, steps per second: 102, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.073 [-1.409, 0.785], loss: 0.097028, mean_absolute_error: 1.461222, mean_q: 2.824898\n",
      "  287/10000: episode: 16, duration: 0.106s, episode steps: 10, steps per second: 95, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 1.000 [1.000, 1.000], mean observation: -0.132 [-3.016, 1.962], loss: 0.143098, mean_absolute_error: 1.482105, mean_q: 2.764025\n",
      "  308/10000: episode: 17, duration: 0.223s, episode steps: 21, steps per second: 94, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.619 [0.000, 1.000], mean observation: -0.071 [-1.938, 1.194], loss: 0.146064, mean_absolute_error: 1.568088, mean_q: 3.012871\n",
      "  326/10000: episode: 18, duration: 0.173s, episode steps: 18, steps per second: 104, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.085 [-1.195, 0.589], loss: 0.139122, mean_absolute_error: 1.648257, mean_q: 3.142845\n",
      "  357/10000: episode: 19, duration: 0.286s, episode steps: 31, steps per second: 108, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.419 [0.000, 1.000], mean observation: 0.056 [-1.154, 1.948], loss: 0.131401, mean_absolute_error: 1.720029, mean_q: 3.271352\n",
      "  386/10000: episode: 20, duration: 0.275s, episode steps: 29, steps per second: 105, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: 0.091 [-0.606, 1.457], loss: 0.170674, mean_absolute_error: 1.841477, mean_q: 3.480891\n",
      "  398/10000: episode: 21, duration: 0.125s, episode steps: 12, steps per second: 96, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.833 [0.000, 1.000], mean observation: -0.087 [-2.445, 1.586], loss: 0.151559, mean_absolute_error: 1.905464, mean_q: 3.611984\n",
      "  420/10000: episode: 22, duration: 0.217s, episode steps: 22, steps per second: 101, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.076 [-0.794, 1.237], loss: 0.147949, mean_absolute_error: 1.955695, mean_q: 3.701319\n",
      "  435/10000: episode: 23, duration: 0.127s, episode steps: 15, steps per second: 118, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.112 [-1.145, 2.047], loss: 0.190783, mean_absolute_error: 2.040790, mean_q: 3.886738\n",
      "  446/10000: episode: 24, duration: 0.119s, episode steps: 11, steps per second: 93, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.909 [0.000, 1.000], mean observation: -0.118 [-2.828, 1.776], loss: 0.191248, mean_absolute_error: 2.080879, mean_q: 3.964779\n",
      "  465/10000: episode: 25, duration: 0.183s, episode steps: 19, steps per second: 104, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.263 [0.000, 1.000], mean observation: 0.040 [-1.962, 2.871], loss: 0.178817, mean_absolute_error: 2.147414, mean_q: 4.070877\n",
      "  485/10000: episode: 26, duration: 0.346s, episode steps: 20, steps per second: 58, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.099 [-0.788, 1.765], loss: 0.172590, mean_absolute_error: 2.217135, mean_q: 4.188898\n",
      "  500/10000: episode: 27, duration: 0.224s, episode steps: 15, steps per second: 67, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.133 [0.000, 1.000], mean observation: 0.072 [-2.156, 3.251], loss: 0.212066, mean_absolute_error: 2.227495, mean_q: 4.222727\n",
      "  510/10000: episode: 28, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.124 [-1.617, 2.618], loss: 0.175632, mean_absolute_error: 2.271252, mean_q: 4.358874\n",
      "  521/10000: episode: 29, duration: 0.271s, episode steps: 11, steps per second: 41, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.091 [0.000, 1.000], mean observation: 0.145 [-1.715, 2.805], loss: 0.156386, mean_absolute_error: 2.308053, mean_q: 4.408772\n",
      "  530/10000: episode: 30, duration: 0.165s, episode steps: 9, steps per second: 55, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.146 [-1.717, 2.796], loss: 0.267382, mean_absolute_error: 2.406615, mean_q: 4.573253\n",
      "  562/10000: episode: 31, duration: 0.360s, episode steps: 32, steps per second: 89, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.344 [0.000, 1.000], mean observation: -0.013 [-1.970, 2.701], loss: 0.266001, mean_absolute_error: 2.483739, mean_q: 4.695184\n",
      "  617/10000: episode: 32, duration: 0.487s, episode steps: 55, steps per second: 113, episode reward: 55.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: -0.077 [-2.167, 2.789], loss: 0.327260, mean_absolute_error: 2.617954, mean_q: 4.959061\n",
      "  630/10000: episode: 33, duration: 0.205s, episode steps: 13, steps per second: 63, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.115 [-1.543, 2.486], loss: 0.302885, mean_absolute_error: 2.768577, mean_q: 5.257807\n",
      "  653/10000: episode: 34, duration: 0.330s, episode steps: 23, steps per second: 70, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.391 [0.000, 1.000], mean observation: 0.080 [-1.133, 2.080], loss: 0.280792, mean_absolute_error: 2.831555, mean_q: 5.401133\n",
      "  667/10000: episode: 35, duration: 0.240s, episode steps: 14, steps per second: 58, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.714 [0.000, 1.000], mean observation: -0.091 [-2.084, 1.345], loss: 0.320702, mean_absolute_error: 2.853440, mean_q: 5.391703\n",
      "  699/10000: episode: 36, duration: 0.660s, episode steps: 32, steps per second: 48, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.375 [0.000, 1.000], mean observation: 0.001 [-1.579, 2.305], loss: 0.409796, mean_absolute_error: 2.977649, mean_q: 5.615342\n",
      "  712/10000: episode: 37, duration: 0.182s, episode steps: 13, steps per second: 71, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: 0.096 [-0.959, 1.441], loss: 0.449956, mean_absolute_error: 3.073057, mean_q: 5.823542\n",
      "  725/10000: episode: 38, duration: 0.280s, episode steps: 13, steps per second: 46, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.098 [-2.193, 1.391], loss: 0.473915, mean_absolute_error: 3.090650, mean_q: 5.825618\n",
      "  739/10000: episode: 39, duration: 0.148s, episode steps: 14, steps per second: 95, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.093 [-1.338, 0.784], loss: 0.433833, mean_absolute_error: 3.085199, mean_q: 5.787130\n",
      "  750/10000: episode: 40, duration: 0.109s, episode steps: 11, steps per second: 101, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.134 [-2.472, 1.553], loss: 0.330846, mean_absolute_error: 3.191940, mean_q: 6.124445\n",
      "  769/10000: episode: 41, duration: 0.162s, episode steps: 19, steps per second: 118, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: 0.127 [-0.609, 1.528], loss: 0.391544, mean_absolute_error: 3.237623, mean_q: 6.166776\n",
      "  791/10000: episode: 42, duration: 0.214s, episode steps: 22, steps per second: 103, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.682 [0.000, 1.000], mean observation: -0.088 [-2.651, 1.524], loss: 0.426314, mean_absolute_error: 3.285980, mean_q: 6.242043\n",
      "  808/10000: episode: 43, duration: 0.155s, episode steps: 17, steps per second: 110, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.412 [0.000, 1.000], mean observation: 0.129 [-0.569, 1.446], loss: 0.399623, mean_absolute_error: 3.333444, mean_q: 6.352913\n",
      "  828/10000: episode: 44, duration: 0.340s, episode steps: 20, steps per second: 59, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.073 [-1.047, 0.631], loss: 0.379619, mean_absolute_error: 3.412082, mean_q: 6.546725\n",
      "  852/10000: episode: 45, duration: 0.363s, episode steps: 24, steps per second: 66, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.583 [0.000, 1.000], mean observation: -0.054 [-1.627, 0.841], loss: 0.363005, mean_absolute_error: 3.494900, mean_q: 6.717674\n",
      "  867/10000: episode: 46, duration: 0.211s, episode steps: 15, steps per second: 71, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.054 [-2.013, 1.401], loss: 0.284938, mean_absolute_error: 3.501850, mean_q: 6.813104\n",
      "  892/10000: episode: 47, duration: 0.283s, episode steps: 25, steps per second: 88, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.560 [0.000, 1.000], mean observation: -0.044 [-1.373, 0.829], loss: 0.379909, mean_absolute_error: 3.635055, mean_q: 7.050630\n",
      "  909/10000: episode: 48, duration: 0.172s, episode steps: 17, steps per second: 99, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.706 [0.000, 1.000], mean observation: -0.099 [-2.258, 1.340], loss: 0.341083, mean_absolute_error: 3.752877, mean_q: 7.311446\n",
      "  930/10000: episode: 49, duration: 0.206s, episode steps: 21, steps per second: 102, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.074 [-1.517, 0.788], loss: 0.473266, mean_absolute_error: 3.754846, mean_q: 7.234881\n",
      "  957/10000: episode: 50, duration: 0.230s, episode steps: 27, steps per second: 117, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.101 [-1.318, 0.582], loss: 0.367479, mean_absolute_error: 3.888769, mean_q: 7.532887\n",
      "  982/10000: episode: 51, duration: 0.221s, episode steps: 25, steps per second: 113, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.112 [-1.215, 0.816], loss: 0.454129, mean_absolute_error: 3.903199, mean_q: 7.533201\n",
      " 1034/10000: episode: 52, duration: 0.588s, episode steps: 52, steps per second: 88, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.519 [0.000, 1.000], mean observation: -0.072 [-1.431, 0.923], loss: 0.449439, mean_absolute_error: 4.066566, mean_q: 7.884648\n",
      " 1046/10000: episode: 53, duration: 0.107s, episode steps: 12, steps per second: 112, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.583 [0.000, 1.000], mean observation: -0.102 [-1.386, 0.748], loss: 0.389145, mean_absolute_error: 4.222986, mean_q: 8.215006\n",
      " 1060/10000: episode: 54, duration: 0.177s, episode steps: 14, steps per second: 79, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.093 [-0.794, 1.376], loss: 0.619244, mean_absolute_error: 4.173356, mean_q: 8.090513\n",
      " 1088/10000: episode: 55, duration: 0.342s, episode steps: 28, steps per second: 82, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.536 [0.000, 1.000], mean observation: -0.035 [-1.323, 0.806], loss: 0.366937, mean_absolute_error: 4.321536, mean_q: 8.446950\n",
      " 1129/10000: episode: 56, duration: 0.473s, episode steps: 41, steps per second: 87, episode reward: 41.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.187 [-1.341, 0.616], loss: 0.523110, mean_absolute_error: 4.427779, mean_q: 8.674096\n",
      " 1150/10000: episode: 57, duration: 0.200s, episode steps: 21, steps per second: 105, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.060 [-1.512, 0.964], loss: 0.563571, mean_absolute_error: 4.587584, mean_q: 8.910396\n",
      " 1193/10000: episode: 58, duration: 0.368s, episode steps: 43, steps per second: 117, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.097 [-1.010, 0.621], loss: 0.490659, mean_absolute_error: 4.641616, mean_q: 9.049173\n",
      " 1249/10000: episode: 59, duration: 0.475s, episode steps: 56, steps per second: 118, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.027 [-1.245, 0.748], loss: 0.405483, mean_absolute_error: 4.814185, mean_q: 9.540787\n",
      " 1345/10000: episode: 60, duration: 0.832s, episode steps: 96, steps per second: 115, episode reward: 96.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: 0.077 [-1.019, 1.094], loss: 0.398766, mean_absolute_error: 5.143131, mean_q: 10.278272\n",
      " 1407/10000: episode: 61, duration: 1.324s, episode steps: 62, steps per second: 47, episode reward: 62.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.178 [-1.128, 0.691], loss: 0.388617, mean_absolute_error: 5.474426, mean_q: 10.967832\n",
      " 1430/10000: episode: 62, duration: 0.347s, episode steps: 23, steps per second: 66, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.565 [0.000, 1.000], mean observation: -0.085 [-1.387, 0.612], loss: 0.637057, mean_absolute_error: 5.565034, mean_q: 11.092134\n",
      " 1512/10000: episode: 63, duration: 0.829s, episode steps: 82, steps per second: 99, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.163 [-1.334, 0.570], loss: 0.523151, mean_absolute_error: 5.817568, mean_q: 11.666292\n",
      " 1604/10000: episode: 64, duration: 1.461s, episode steps: 92, steps per second: 63, episode reward: 92.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: -0.297 [-1.602, 0.627], loss: 0.471487, mean_absolute_error: 6.220830, mean_q: 12.504685\n",
      " 1704/10000: episode: 65, duration: 0.936s, episode steps: 100, steps per second: 107, episode reward: 100.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.268 [-1.487, 0.656], loss: 0.460119, mean_absolute_error: 6.638164, mean_q: 13.375172\n",
      " 1828/10000: episode: 66, duration: 1.017s, episode steps: 124, steps per second: 122, episode reward: 124.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.326 [-1.162, 1.706], loss: 0.531670, mean_absolute_error: 7.107296, mean_q: 14.331930\n",
      " 2028/10000: episode: 67, duration: 1.622s, episode steps: 200, steps per second: 123, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.041 [-1.273, 1.326], loss: 0.730663, mean_absolute_error: 7.851404, mean_q: 15.828107\n",
      " 2187/10000: episode: 68, duration: 1.334s, episode steps: 159, steps per second: 119, episode reward: 159.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.259 [-1.015, 1.702], loss: 0.716788, mean_absolute_error: 8.611996, mean_q: 17.471897\n",
      " 2387/10000: episode: 69, duration: 1.619s, episode steps: 200, steps per second: 124, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.003 [-1.016, 0.845], loss: 0.813679, mean_absolute_error: 9.501577, mean_q: 19.251501\n",
      " 2553/10000: episode: 70, duration: 1.384s, episode steps: 166, steps per second: 120, episode reward: 166.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.327 [-2.023, 0.657], loss: 1.364288, mean_absolute_error: 10.426023, mean_q: 21.095282\n",
      " 2673/10000: episode: 71, duration: 1.036s, episode steps: 120, steps per second: 116, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.186 [-0.952, 1.451], loss: 1.323881, mean_absolute_error: 11.020847, mean_q: 22.329475\n",
      " 2873/10000: episode: 72, duration: 1.701s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.044 [-1.086, 0.818], loss: 0.956356, mean_absolute_error: 11.755537, mean_q: 23.890553\n",
      " 3073/10000: episode: 73, duration: 1.693s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.087 [-1.229, 0.921], loss: 1.064139, mean_absolute_error: 12.801969, mean_q: 26.048302\n",
      " 3205/10000: episode: 74, duration: 1.075s, episode steps: 132, steps per second: 123, episode reward: 132.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.523 [0.000, 1.000], mean observation: 0.272 [-0.934, 1.709], loss: 1.738019, mean_absolute_error: 13.669983, mean_q: 27.684555\n",
      " 3346/10000: episode: 75, duration: 1.216s, episode steps: 141, steps per second: 116, episode reward: 141.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.525 [0.000, 1.000], mean observation: 0.284 [-1.122, 1.469], loss: 1.765934, mean_absolute_error: 14.105809, mean_q: 28.524567\n",
      " 3517/10000: episode: 76, duration: 1.413s, episode steps: 171, steps per second: 121, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.192 [-1.086, 1.521], loss: 1.234388, mean_absolute_error: 14.710963, mean_q: 29.893068\n",
      " 3709/10000: episode: 77, duration: 1.589s, episode steps: 192, steps per second: 121, episode reward: 192.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.344 [-2.414, 1.078], loss: 1.456845, mean_absolute_error: 15.659493, mean_q: 31.711451\n",
      " 3893/10000: episode: 78, duration: 1.514s, episode steps: 184, steps per second: 122, episode reward: 184.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.269 [-1.053, 1.886], loss: 1.705904, mean_absolute_error: 16.382067, mean_q: 33.220566\n",
      " 4069/10000: episode: 79, duration: 1.459s, episode steps: 176, steps per second: 121, episode reward: 176.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.235 [-0.952, 1.495], loss: 1.815784, mean_absolute_error: 17.044058, mean_q: 34.506268\n",
      " 4269/10000: episode: 80, duration: 2.230s, episode steps: 200, steps per second: 90, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.249 [-1.799, 0.725], loss: 2.469773, mean_absolute_error: 17.786091, mean_q: 35.962406\n",
      " 4469/10000: episode: 81, duration: 1.708s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.047 [-0.963, 0.884], loss: 2.986192, mean_absolute_error: 18.607277, mean_q: 37.617661\n",
      " 4654/10000: episode: 82, duration: 1.612s, episode steps: 185, steps per second: 115, episode reward: 185.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.351 [-2.417, 0.703], loss: 2.796078, mean_absolute_error: 19.392960, mean_q: 39.149796\n",
      " 4854/10000: episode: 83, duration: 2.141s, episode steps: 200, steps per second: 93, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.087 [-1.149, 0.784], loss: 3.172957, mean_absolute_error: 20.037346, mean_q: 40.386749\n",
      " 5054/10000: episode: 84, duration: 2.390s, episode steps: 200, steps per second: 84, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.057 [-0.890, 0.739], loss: 2.141032, mean_absolute_error: 20.832310, mean_q: 42.086548\n",
      " 5254/10000: episode: 85, duration: 2.193s, episode steps: 200, steps per second: 91, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.074 [-0.999, 1.126], loss: 3.654717, mean_absolute_error: 21.638390, mean_q: 43.718948\n",
      " 5454/10000: episode: 86, duration: 2.198s, episode steps: 200, steps per second: 91, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.095 [-1.106, 0.850], loss: 3.265336, mean_absolute_error: 22.385143, mean_q: 45.264004\n",
      " 5654/10000: episode: 87, duration: 2.078s, episode steps: 200, steps per second: 96, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.311 [-2.289, 0.692], loss: 3.837892, mean_absolute_error: 23.140461, mean_q: 46.659859\n",
      " 5854/10000: episode: 88, duration: 1.825s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.195 [-1.508, 0.620], loss: 3.535916, mean_absolute_error: 23.900188, mean_q: 48.248192\n",
      " 6054/10000: episode: 89, duration: 1.636s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.014 [-0.794, 0.734], loss: 4.133122, mean_absolute_error: 24.505798, mean_q: 49.445068\n",
      " 6254/10000: episode: 90, duration: 1.683s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.163 [-1.430, 0.930], loss: 3.650844, mean_absolute_error: 25.196213, mean_q: 50.814991\n",
      " 6410/10000: episode: 91, duration: 1.303s, episode steps: 156, steps per second: 120, episode reward: 156.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.400 [-2.411, 0.528], loss: 3.937975, mean_absolute_error: 25.851254, mean_q: 52.142796\n",
      " 6610/10000: episode: 92, duration: 1.645s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.252 [-1.940, 0.895], loss: 4.180747, mean_absolute_error: 26.226490, mean_q: 52.836689\n",
      " 6810/10000: episode: 93, duration: 1.614s, episode steps: 200, steps per second: 124, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.293 [-2.143, 0.587], loss: 2.810643, mean_absolute_error: 26.907106, mean_q: 54.324963\n",
      " 7010/10000: episode: 94, duration: 1.607s, episode steps: 200, steps per second: 124, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.101 [-1.127, 0.748], loss: 3.593735, mean_absolute_error: 27.438936, mean_q: 55.312450\n",
      " 7210/10000: episode: 95, duration: 1.723s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.208 [-1.291, 1.449], loss: 4.411484, mean_absolute_error: 27.992041, mean_q: 56.378895\n",
      " 7410/10000: episode: 96, duration: 1.660s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.088 [-1.042, 1.002], loss: 4.781749, mean_absolute_error: 28.672180, mean_q: 57.716476\n",
      " 7573/10000: episode: 97, duration: 1.340s, episode steps: 163, steps per second: 122, episode reward: 163.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.375 [-2.413, 0.613], loss: 3.319375, mean_absolute_error: 28.958796, mean_q: 58.302734\n",
      " 7773/10000: episode: 98, duration: 1.634s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.137 [-1.445, 0.810], loss: 4.365863, mean_absolute_error: 29.231813, mean_q: 58.852127\n",
      " 7973/10000: episode: 99, duration: 1.642s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.062 [-1.047, 0.945], loss: 3.750099, mean_absolute_error: 29.899879, mean_q: 60.160870\n",
      " 8153/10000: episode: 100, duration: 1.462s, episode steps: 180, steps per second: 123, episode reward: 180.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.347 [-2.426, 0.571], loss: 3.246666, mean_absolute_error: 30.330881, mean_q: 61.073795\n",
      " 8353/10000: episode: 101, duration: 1.646s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.266 [-2.187, 0.761], loss: 5.622832, mean_absolute_error: 30.698584, mean_q: 61.805489\n",
      " 8544/10000: episode: 102, duration: 1.607s, episode steps: 191, steps per second: 119, episode reward: 191.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.318 [-2.405, 0.772], loss: 3.800375, mean_absolute_error: 31.002869, mean_q: 62.546082\n",
      " 8744/10000: episode: 103, duration: 1.637s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.098 [-1.094, 0.960], loss: 6.007058, mean_absolute_error: 31.455976, mean_q: 63.370899\n",
      " 8944/10000: episode: 104, duration: 1.636s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.199 [-1.826, 0.799], loss: 3.972934, mean_absolute_error: 32.010998, mean_q: 64.514511\n",
      " 9102/10000: episode: 105, duration: 1.309s, episode steps: 158, steps per second: 121, episode reward: 158.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.371 [-2.596, 0.713], loss: 3.930638, mean_absolute_error: 32.485779, mean_q: 65.478546\n",
      " 9280/10000: episode: 106, duration: 1.439s, episode steps: 178, steps per second: 124, episode reward: 178.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.340 [-2.425, 0.748], loss: 4.095829, mean_absolute_error: 32.670551, mean_q: 65.894936\n",
      " 9480/10000: episode: 107, duration: 1.611s, episode steps: 200, steps per second: 124, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.122 [-1.249, 1.527], loss: 4.059691, mean_absolute_error: 32.955372, mean_q: 66.425964\n",
      " 9648/10000: episode: 108, duration: 1.386s, episode steps: 168, steps per second: 121, episode reward: 168.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.352 [-2.530, 0.675], loss: 4.892594, mean_absolute_error: 33.408127, mean_q: 67.322083\n",
      " 9844/10000: episode: 109, duration: 1.666s, episode steps: 196, steps per second: 118, episode reward: 196.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.304 [-2.406, 0.793], loss: 5.214490, mean_absolute_error: 33.687874, mean_q: 68.027084\n",
      "done, took 93.990 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a5365d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 161.000, steps: 161\n",
      "Episode 2: reward: 200.000, steps: 200\n",
      "Episode 3: reward: 200.000, steps: 200\n",
      "Episode 4: reward: 200.000, steps: 200\n",
      "Episode 5: reward: 200.000, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11861d510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "\n",
    "\n",
    "ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "print env.observation_space.shape\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=500000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "checkpoint_weights_filename = 'dqn_' + ENV_NAME + '_weights_{step}.h5f'\n",
    "log_filename = 'dqn_{}_log.json'.format(ENV_NAME)\n",
    "# callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=500)]\n",
    "# callbacks += [FileLogger(log_filename, interval=100)]\n",
    "callbacks = [FileLogger(log_filename)]\n",
    "\n",
    "dqn.fit(env,callbacks=callbacks, nb_steps=10000, visualize=False, verbose=2, log_interval=100)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, nb_episodes=5, visualize=True)\n",
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/tight_layout.py:222: UserWarning: tight_layout : falling back to Agg renderer\n",
      "  warnings.warn(\"tight_layout : falling back to Agg renderer\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "def visualize_log(filename, figsize=None, output=None):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    if 'episode' not in data:\n",
    "        raise ValueError('Log file \"{}\" does not contain the \"episode\" key.'.format(filename))\n",
    "    episodes = data['episode']\n",
    "\n",
    "    # Get value keys. The x axis is shared and is the number of episodes.\n",
    "    keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (15., 5. * len(keys))\n",
    "    f, axarr = plt.subplots(len(keys), sharex=True, figsize=figsize)\n",
    "    for idx, key in enumerate(keys):\n",
    "        axarr[idx].plot(episodes, data[key])\n",
    "        axarr[idx].set_ylabel(key)\n",
    "    plt.xlabel('episodes')\n",
    "    plt.tight_layout()\n",
    "    if output is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(output)\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('filename', type=str, help='The filename of the JSON log generated during training.')\n",
    "# parser.add_argument('--output', type=str, default=None, help='The output file. If not specified, the log will only be displayed.')\n",
    "# parser.add_argument('--figsize', nargs=2, type=float, default=None, help='The size of the figure in `width height` format specified in points.')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# You can use visualize_log to easily view the stats that were recorded during training. Simply\n",
    "# provide the filename of the `FileLogger` that was used in `FileLogger`.\n",
    "visualize_log(log_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 105.000, steps: 105\n",
      "Episode 2: reward: 84.000, steps: 84\n",
      "Episode 3: reward: 169.000, steps: 169\n",
      "Episode 4: reward: 111.000, steps: 111\n",
      "Episode 5: reward: 104.000, steps: 104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x111950410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.test(env, nb_episodes=5, visualize=True)\n",
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
